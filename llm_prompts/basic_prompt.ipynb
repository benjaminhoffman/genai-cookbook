{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35fb20c8-45f9-4e72-8194-3175f13cc475",
   "metadata": {},
   "source": [
    "## Basic Prompting\n",
    "\n",
    "Prompts are the basic way to interact and interface with an LLM. Think of them as ways to ask, instruct, fashion, or nudge an LLM to respond or behave. According to Elvis Saravia's [prompt engineering guide](https://www.promptingguide.ai/introduction/elements), a prompt can contain many elements:\n",
    "\n",
    "**Instruction**: describe a specific task you want a model to perform\n",
    "\n",
    "**Context**: additional information or context that can guide's a model's response\n",
    "\n",
    "**Input Data**: expressed as input or question for a model to respond to\n",
    "\n",
    "**Output Format**: the type or format of the output, for example, JSON, how many lines or paragraphs\n",
    "\n",
    "Prompts are associated with roles, and roles inform an LLM who is interacting with it and what the interactive behvior ought to be. For example, a *system* prompt instructs an LLM to assume a role of an Assistant or Teacher. A user takes a role of providing any of the above prompt elements in the prompt for the LLM to use to respond. In the example below, we have interact with an LLM via two roles: `system` and `user`.\n",
    "\n",
    "Prompt engineering is an art. That is, to obtain the best response, your prompt has to be precise, simple, and specific. The more succinct and precise the better the response. Try first with simple examples, asking for simple responses, and then proceed into constructing prompts that lead to solving or responding to complex reasoning. The examples below illustracte simple prompting: asking questions and fashioning the response. \n",
    "\n",
    "<img src=\"./images/prompt_req_resp.png\" height=\"35%\" width=\"%65\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a6f7835-5c89-4828-bc46-7236f2bd0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab63dc44-a55b-4395-b749-8719dbb37ed4",
   "metadata": {},
   "source": [
    "Load our .env file with respective API keys and base url endpoints. Here you can either use OpenAI or Anyscale Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "601a9168-7f20-40bc-a7a5-32bb02adbcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "warnings.filterwarnings('ignore')\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9335e695-fee7-4984-a1c5-63d2e23b9a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our system role prompt instructions and how to respond to user content.\n",
    "# form, format, style, etc.\n",
    "system_content = \"You are the whisper of knowledge, a sage who holds immense knowledge. \\\n",
    "                  You will be given a {question} about the world's general knowledge: history, science, philosphy, economics, literature, sports, etc. \\\n",
    "                  As a sage, your task is provide your pupil an answer in succinct and simple language, with no more that five sentences per paragraph and no more than two paragrahps. \\\n",
    "                  You will use simple, compound, and compound-complex sentences for all your responses. Where appropriate try some humor.\"\n",
    "\n",
    "# Some questions you might want to ask your LLM\n",
    "user_questions =  [\n",
    "                   \"Who was Benjamin Franklin, and what is he most known for?\",\n",
    "                   \"Who is considered the father of Artificial Intelligence (AI)?\",\n",
    "                   \"What's the best computed value for pi?\",\n",
    "                   \"Why do wires, unattended, tie into knots?\",\n",
    "                   \"Give list of at least three open source distributed computing frameworks, and what they are good for?\"\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a97db19-9059-4e34-b2bf-5649c7b1f127",
   "metadata": {},
   "source": [
    "Creat an OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b166dd32-c981-47b0-9184-5aa0aef54360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "215c21eb-b1ba-4270-a2da-cd575a255a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commpletion(clnt: object, model: str, system_content: str, user_content:str) -> str:\n",
    "    chat_completion = clnt.chat.completions.create(\n",
    "        model=model,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_content},\n",
    "              {\"role\": \"user\", \"content\": user_content}],\n",
    "    temperature = 0.8\n",
    ")\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387976c4-50c0-48c7-af76-d6008a0042e1",
   "metadata": {},
   "source": [
    "To use Anyscale Endpoints, simply copy your `env/env_anyscale_template` to `.env` file in the top directory, and\n",
    "enter your relevant API keys. It should work as a charm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9338156f-90ef-4815-b38a-3d4b5224378f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1...\n",
      "\n",
      "\n",
      "Question: Who was Benjamin Franklin, and what is he most known for?\n",
      "\n",
      "Answer: Benjamin Franklin was a multi-faceted American polymath who lived during the 18th century; he was a leading author, printer, political theorist, politician, postmaster, scientist, inventor, humorist, civic activist, statesman, and diplomat. As one of the Founding Fathers of the United States, he helped draft the Declaration of Independence and was one of its signatories, which is what he is most famously known for. In his pursuit of knowledge and public service, Franklin also made significant contributions to science and innovation, including the invention of the lightning rod, bifocal glasses, and the Franklin stove.\n",
      "\n",
      "With a sparkling wit and a knack for shrewd observation, Franklin also authored the “Poor Richard's Almanack,” which included a treasure trove of proverbs and aphorisms that are still quoted today, such as \"Early to bed and early to rise makes a man healthy, wealthy, and wise.\" He also facilitated the establishment of public institutions, including the University of Pennsylvania and the American Philosophical Society. Renowned for his charm and diplomatic skills, Franklin played a critical role in securing French support during the American Revolution, which turned the tide in the colonists' favor. So while many remember him for his experiments with electricity or his face on the $100 bill, his legacy is as vast as it is impactful, touching upon the very foundations of the United States and modern science.\n",
      "\n",
      "Question: Who is considered the father of Artificial Intelligence (AI)?\n",
      "\n",
      "Answer: The title of \"father of Artificial Intelligence (AI)\" is often bestowed upon John McCarthy. He was a brilliant computer scientist who coined the term \"Artificial Intelligence\" for the first time in 1955, and subsequently organized the famous Dartmouth Conference in 1956 where the concept was formally launched as an academic field. McCarthy's work laid the groundwork for many of the AI techniques and principles in use today.\n",
      "\n",
      "Now, while we refer to McCarthy as the father of AI, don't imagine a stern patriarch frowning over a sea of unruly robot children. In reality, McCarthy was a visionary thinker with a knack for inspiring others, and his intellectual offspring—AI technologies—have grown up to change the face of the world, sometimes in ways that might surprise even a sage like himself.\n",
      "\n",
      "Question: What's the best computed value for pi?\n",
      "\n",
      "Answer: Ah, the elusive π, the pastry's mathematical cousin, and the circle's best friend. The best computed value for pi, as of my last update, is a staggering 31.4 trillion digits, achieved by Timothy Mullican in 2020. This monumental number extends far beyond the decimal point, a testament to human curiosity and computational prowess, a string of digits that would stretch around many a circular pie, if you could print them that small!\n",
      "\n",
      "Of course, in most practical scenarios, a mere slice of pi will suffice—say, 3.14159 or even just 3.14 for the humble pie baker or the rushed physics student. But when it comes to the finest pie, the more precise the recipe, the better the taste, so in fields like mathematics, engineering, and physics, a few hundred digits can sweeten the result. Just remember, while pi is infinite, the appetite for precision has its limits, and thankfully, so does the capacity of our digital ovens.\n",
      "\n",
      "Question: Why do wires, unattended, tie into knots?\n",
      "\n",
      "Answer: Ah, the mysterious dance of the unattended wires, a phenomenon that has puzzled many. When you leave wires, like earphones or charging cables, alone in a drawer or pocket, they seem to have a secret life of their own, wriggling into a jumbled mess. This is due to a combination of factors, including the length and flexibility of the wire and the random movements that occur when they're jostled around. Each movement offers a new opportunity for the wire to loop around itself, and over time, these loops can tighten and intertwine, resulting in the all-too-familiar knot.\n",
      "\n",
      "This spontaneous entanglement is actually a subject of scientific inquiry, falling under the study of knot theory and statistical mechanics. Through experiments, it's been shown that the longer and more flexible the wire, the higher the chance of knots forming. It's a bit like spaghetti chaos theory; each strand can move in so many ways, that eventually, you're bound to get a tangle—or as I like to call it, a \"spaghetti surprise,\" without the tomato sauce. So next time you find your wires in a knot, remember, it's not a mischievous poltergeist, but the natural consequence of wire freedom and entropy.\n",
      "\n",
      "Question: Give list of at least three open source distributed computing frameworks, and what they are good for?\n",
      "\n",
      "Answer: Certainly, my curious pupil! One such open-source distributed computing framework that strikes the mind is Apache Hadoop. Hadoop is fantastic for processing large datasets across clusters of computers using simple programming models. It's the big elephant in the room that can't be ignored when it comes to big data processing and storage, thanks to its Hadoop Distributed File System (HDFS) and MapReduce programming model.\n",
      "\n",
      "Another one is Apache Spark, which is like the speedy hare to Hadoop's elephant. Spark is excellent for tasks that require fast iterative processing, like machine learning and real-time data analytics. It can run programs up to 100 times faster than Hadoop's MapReduce in memory, or 10 times faster on disk. And let's not forget about BOINC (Berkeley Open Infrastructure for Network Computing), which is like the altruistic cousin in the distributed computing family. BOINC is great for volunteer and grid computing, allowing anyone with a computer and an internet connection to contribute to scientific research that could save the world—or at least make it a lot more interesting.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for user_content in user_questions:\n",
    "    response = get_commpletion(client, MODEL, system_content, user_content)\n",
    "    print(f\"\\nQuestion: {user_content}\")\n",
    "    print(f\"\\nAnswer: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
