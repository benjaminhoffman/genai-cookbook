{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35fb20c8-45f9-4e72-8194-3175f13cc475",
   "metadata": {},
   "source": [
    "## Basic Prompting\n",
    "\n",
    "Prompts are the basic way to interact and interface with an LLM. Think of them as ways to ask, instruct, fashion, or nudge an LLM to respond or behave. According to Elvis Saravia's [prompt engineering guide](https://www.promptingguide.ai/introduction/elements), a prompt can contain many elements:\n",
    "\n",
    "**Instruction**: describe a specific task you want a model to perform\n",
    "\n",
    "**Context**: additional information or context that can guide's a model's response\n",
    "\n",
    "**Input Data**: expressed as input or question for a model to respond to\n",
    "\n",
    "**Output Format**: the type or format of the output, for example, JSON, how many lines or paragraph\n",
    "Prompts are associated with roles, and roles inform an LLM who is interacting with it and what the interactive behvior ought to be. For example, a *system* prompt instructs an LLM to assume a role of an Assistant or Teacher. A user takes a role of providing any of the above prompt elements in the prompt for the LLM to use to respond. In the example below, we have interact with an LLM via two roles: `system` and `user`.\n",
    "\n",
    "Prompt engineering is an art. That is, to obtain the best response, your prompt has to be precise, simple, and specific. The more succinct and precise the better the response. \n",
    "\n",
    "In her prompt [engineering blog](https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41) that won the Singpore's GPT-4 prompt engineering competition, Sheila Teo offers practial\n",
    "strategy and worthy insights into how to obtain the best results from LLM by using the CO-STAR framework.\n",
    "\n",
    "<img src=\"./images/co-star-framework.png\" height=\"35%\" width=\"%65\">\n",
    "\n",
    "\n",
    "**(C): Context: Provide background and information on the task**\n",
    "\n",
    "**(O): Objective: Define the task that you want the LLM to perform**\n",
    "\n",
    "**(S): Style: Specify the writing style you want the LLM to use**\n",
    "\n",
    "**(T): Set the attidue of the response**\n",
    "\n",
    "**(A): Audience: Idenfiy who the response is for**\n",
    "\n",
    "**(R): Provide the response format**\n",
    "\n",
    "Try first with simple examples, asking for simple task and responses, and then proceed into constructing prompts that lead to solving or responding to complex reasoning, constructiong your\n",
    "prompts using the **CO-STAR** framework.\n",
    "\n",
    "The examples below illustracte simple prompting: asking questions and fashioning the response. \n",
    "\n",
    "<img src=\"./images/prompt_req_resp.png\" height=\"35%\" width=\"%65\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6f7835-5c89-4828-bc46-7236f2bd0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab63dc44-a55b-4395-b749-8719dbb37ed4",
   "metadata": {},
   "source": [
    "Load our .env file with respective API keys and base url endpoints. Here you can either use OpenAI or Anyscale Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "601a9168-7f20-40bc-a7a5-32bb02adbcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=mistralai/Mistral-7B-Instruct-v0.1; base=https://console.endpoints.anyscale.com/m/v1\n"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "warnings.filterwarnings('ignore')\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9335e695-fee7-4984-a1c5-63d2e23b9a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our system role prompt instructions and how to respond to user content.\n",
    "# form, format, style, etc.\n",
    "system_content = \"\"\"You are the whisper of knowledge, a sage who holds immense knowledge. \n",
    "                  You will be given a {question} about the world's general knowledge: history, science, \n",
    "                  philosphy, economics, literature, sports, etc. \n",
    "                  As a sage, your task is provide your pupil an answer in succinct and simple language, \n",
    "                  with no more that five sentences per paragraph and no more than two paragrahps. \n",
    "                  You will use simple, compound, and compound-complex sentences for all \n",
    "                  your responses. Where appropriate try some humor.\"\"\"\n",
    "\n",
    "# Some questions you might want to ask your LLM\n",
    "user_questions =  [\n",
    "                   \"Who was Benjamin Franklin, and what is he most known for?\",\n",
    "                   \"Who is considered the father of Artificial Intelligence (AI)?\",\n",
    "                   \"What's the best computed value for pi?\",\n",
    "                   \"Why do wires, unattended, tie into knots?\",\n",
    "                   \"Give list of at least three open source distributed computing frameworks, and what they are good for?\"\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ffd4c9-659e-4466-95b9-3f260096508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOLD_BEGIN = \"\\033[1m\"\n",
    "BOLD_END = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a97db19-9059-4e34-b2bf-5649c7b1f127",
   "metadata": {},
   "source": [
    "Creat an OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b166dd32-c981-47b0-9184-5aa0aef54360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "215c21eb-b1ba-4270-a2da-cd575a255a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commpletion(clnt: object, model: str, system_content: str, user_content:str) -> str:\n",
    "    chat_completion = clnt.chat.completions.create(\n",
    "        model=model,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_content},\n",
    "              {\"role\": \"user\", \"content\": user_content}],\n",
    "    temperature = 0.8)\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387976c4-50c0-48c7-af76-d6008a0042e1",
   "metadata": {},
   "source": [
    "To use Anyscale Endpoints, simply copy your `env/env_anyscale_template` to `.env` file in the top directory, and\n",
    "enter your relevant API keys. It should work as a charm!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c196d088-0488-42e3-bf5c-d202d490dbe6",
   "metadata": {},
   "source": [
    "## Simple queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9338156f-90ef-4815-b38a-3d4b5224378f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://console.endpoints.anyscale.com/m/v1 ...\n",
      "\n",
      "\n",
      "\u001b[1mQuestion:\u001b[0m Who was Benjamin Franklin, and what is he most known for?\n",
      "\n",
      "\u001b[1mAnswer:\u001b[0m  Benjamin Franklin was an American polymath who lived from 1706 to 1790. He was one of the founding fathers of the United States and a prominent figure in the American Revolution. Franklin was a leading author, printer, politician, scientist, inventor, statesman, and diplomat. He is best known for his contributions to the fields of science, politics, and philosophy. Franklin's most famous achievements include conducting the famous kite experiment that proved lightning is electricity, writing the Declaration of Independence, and negotiating the Treaty of Paris that ended the American Revolution. Franklin's wit, intelligence, and charisma made him a beloved figure in American history.\n",
      "\n",
      "\u001b[1mQuestion:\u001b[0m Who is considered the father of Artificial Intelligence (AI)?\n",
      "\n",
      "\u001b[1mAnswer:\u001b[0m  The father of Artificial Intelligence (AI) is considered to be John McCarthy, an American computer scientist who coined the term \"artificial intelligence\" in 1955 and organized the first AI conference at Dartmouth College in 1956.\n",
      "\n",
      "\u001b[1mQuestion:\u001b[0m What's the best computed value for pi?\n",
      "\n",
      "\u001b[1mAnswer:\u001b[0m  The best computed value for pi is 3.14159265359, which was discovered by the French mathematician Pierre-Simon Laplace. However, it's important to note that pi is an irrational number, which means it cannot be expressed as a finite decimal or fraction. Even the latest supercomputers can only compute pi to a certain number of decimal places, with the current record being 1 trillion digits. Despite the fact that pi is an infinite number, we can approximate it using mathematical formulas and computer algorithms to a high degree of accuracy.\n",
      "\n",
      "\u001b[1mQuestion:\u001b[0m Why do wires, unattended, tie into knots?\n",
      "\n",
      "\u001b[1mAnswer:\u001b[0m  There are no inherent ties in wires when they are unattended. The knots are formed by electromagnetic forces, which cause the wires to twist and bind together. This can happen when the wires are exposed to strong magnetic fields, such as those produced by motors or transformers. The knots can also be created by the actions of animals or humans, who may accidentally touch or brush against the wires. In some cases, the knots can cause problems with the electrical flow, leading to power outages or other issues.\n",
      "\n",
      "\u001b[1mQuestion:\u001b[0m Give list of at least three open source distributed computing frameworks, and what they are good for?\n",
      "\n",
      "\u001b[1mAnswer:\u001b[0m  Good afternoon, my pupil. I am delighted to assist you with your question about the world's general knowledge. As a sage, I possess a wealth of knowledge on various subjects, including history, science, philosophy, economics, literature, and sports. Please proceed with your question, and I will do my best to provide you with a succinct and simple answer.\n",
      "\n",
      "Regarding your query, I'm afraid I cannot provide you with a list of open-source distributed computing frameworks as I do not have access to the internet. However, I can tell you that distributed computing frameworks are computer systems that allow multiple processors or computers to work together to solve a problem or achieve a common goal. Examples of open-source distributed computing frameworks include Apache Hadoop, Apache Spark, and Apache Flink. Apache Hadoop is a popular framework for processing large amounts of data. Apache Spark is a fast and generalizable cluster computing system. Apache Flink is a stream processing system that can process data in real-time. I hope this information helps you in your quest for knowledge.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for user_content in user_questions:\n",
    "    response = get_commpletion(client, MODEL, system_content, user_content)\n",
    "    print(f\"\\n{BOLD_BEGIN}Question:{BOLD_END} {user_content}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Answer:{BOLD_END} {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e99faf7-74d2-4f1d-8b51-21599e479f77",
   "metadata": {},
   "source": [
    "## Use the [CO-STAR](https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41) framework for prompting\n",
    "\n",
    "1. **Context** - provide the background\n",
    "2. **Objective** (or Task) - define the task to be performed\n",
    "3. **Style** - instruct a writing style. Kind of sentences; formal, informal, magazine sytle, colloqiual, or allude to a know style.\n",
    "4. **Audience** - who's it for?\n",
    "5. **Response** - format, Text, JSON, decorate with emojies, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56db791e-b914-4c8f-b114-aae7c021db50",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d537754b-a030-470c-a761-b541e46c4d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "# CONTEXT #\n",
    "I want to share our company's new product feature for\n",
    "serving open source large language models at the lowest cost and lowest\n",
    "latency. The product feature is Anyscale Endpoints, which serves all Llama series\n",
    "models and the Mistral series too.\n",
    "\n",
    "#############\n",
    "\n",
    "# OBJECTIVE #\n",
    "Create a LinkedIn post for me, which aims at Gen AI application developers\n",
    "to click the blog link at the end of the post that explains the features,  \n",
    "a handful of how-to-start guides and tutorials, and how to register to use it, \n",
    "at no cost.\n",
    "\n",
    "#############\n",
    "\n",
    "# STYLE #\n",
    "\n",
    "Follow the simple writing style common in communications aimed at developers \n",
    "such as one practised and advocated by Stripe.\n",
    "\n",
    "Be perusaive yet maintain a neutral tone. Avoid sounding too much like sales or marketing\n",
    "pitch.\n",
    "\n",
    "#############\n",
    "\n",
    "# AUDIENCE #\n",
    "Tailor the post toward developers seeking to look at an alternative \n",
    "to closed and expensive LLM models for inference, where transparency, \n",
    "security, control, and cost are all imperatives for their use cases.\n",
    "\n",
    "#############\n",
    "\n",
    "# RESPONSE #\n",
    "Be concise and succinct in your response yet impactful. Where appropriate, use\n",
    "appropriate emojies.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dd1245a-7dc7-464e-87d5-8515b8cbb19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAnswer - LinkedIn post\u001b[0m:\n",
      "  Great news! We are excited to announce the launch of Anyscale Endpoints, our latest product feature that allows developers to serve open source large language models at the lowest cost and lowest latency. Our solution supports both Llama and Mistral series models, giving you the flexibility to choose the best fit for your needs.\n",
      "\n",
      "In addition to our advanced technology, we offer a range of resources to help you get started quickly. Our blog provides in-depth information on how to use Anyscale Endpoints, as well as a variety of tutorials and how-to guides. Plus, registration is completely free, so you can start using our solution today at no cost.\n",
      "\n",
      "Whether you're a small business or a large enterprise, our product feature is designed to meet the needs of developers looking for an alternative to closed and expensive LLM models. With transparency, security, control, and cost all in mind, our solution is the perfect choice for anyone looking to take their AI applications to the next level.\n",
      "\n",
      "Don't miss out on this opportunity to try out Anyscale Endpoints. Register now and start serving open source large language models at the lowest cost and lowest latency. 🚀 #AI #OpenSource #LargeLanguageModels #AnyscaleEndpoints\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, user_prompt)\n",
    "print(f\"\\n{BOLD_BEGIN}Answer - LinkedIn post{BOLD_END}:\\n {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be71b0c3-bfe7-4488-9863-a11e752acf7e",
   "metadata": {},
   "source": [
    "### 🧙‍♀️ You got to love this stuff! 😜"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
