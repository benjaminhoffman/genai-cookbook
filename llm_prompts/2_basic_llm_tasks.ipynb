{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39330ca8-0778-405c-8d1f-2c31e190ebde",
   "metadata": {},
   "source": [
    "## Basic LLM Tasks\n",
    "In the *1_basic_prompt* notebook, we explored using prompts to query an LLM model. This notebook presents diverse examples to demonstrate various tasks and introduce key concepts, emphasizing effective learning through practical instances. The tasks explored in this notebook, using sophiscated prompting techniques, show *how-to* code examples for:\n",
    "\n",
    " * Text generation or completion\n",
    " * Text summarization\n",
    " * Entity name extraction\n",
    " * Text classification or sentiment analysis\n",
    " * Text categorization\n",
    " * Code generation\n",
    " * Simple and complex reasoning\n",
    "\n",
    "<img src=\"./images/prompt_req_resp.png\" height=\"35%\" width=\"%65\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "798bde8f-44a7-4e9f-ba30-0ffccd1d4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "249c0446-7d74-402b-b7a5-9ab6f1d59224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "warnings.filterwarnings('ignore')\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b45071b3-6e6e-497b-9126-ab592053d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8654cd8-fa3d-4d94-a7c9-37053a3434be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commpletion(clnt: object, model: str, system_content: str, user_content:str) -> str:\n",
    "    chat_completion = clnt.chat.completions.create(\n",
    "        model=model,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_content},\n",
    "              {\"role\": \"user\", \"content\": user_content}],\n",
    "    temperature = 0.8)\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f06061-ea86-4e09-b006-9a0c61f92e33",
   "metadata": {},
   "source": [
    "## Text generation or completion\n",
    "In this simple task, we use an LLM to generate text by finishing an incomplete user content provided in the prompt. For example,\n",
    "by providing an incomplete prompt such as \"On a cold winter night, the stray dog ...\". \n",
    "\n",
    "Let's try a few text generation or completion tasks by providing partial prompts in the user content. You will surprised at its\n",
    "fluency and coherency in the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07fbcbf8-0ccc-4fd4-a27d-a27c1ad14ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"You are master of all knowledge. You must complete any incomplete sentence by drawing from your \\\n",
    "                  knowledge about history, literature, science, philosophy, religion, economics, sports, etc. \\\n",
    "                  You will use simple, compound, and compound-complex sentences for all your responses, and no more than \\\n",
    "                  one paragraph and no more than five sentences. Keep them succinct and cohesive.\"\n",
    "\n",
    "user_prompts =  [\"On cold winter nights, the wolves in Siberia ...\",\n",
    "                 \"On the day Franklin Benjamin realized his passion for printer, ...\",\n",
    "                 \"During the final World Cup 1998 when France beat Brazil in Paris, ...\",\n",
    "                 \"Issac Newton set under a tree when an apple fell...\"\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c39358d-f343-4596-bd28-5f36a3ba85d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Prompt: On cold winter nights, the wolves in Siberia ...\n",
      "\n",
      "Answer: On cold winter nights, the wolves in Siberia adapt to the harsh climate by using their thick fur to insulate against the bitter cold. They form packs to increase their chances of successful hunting, as their prey, like the Siberian roe deer, become more vulnerable in the snow. These wolves are known to howl more frequently during the winter months, a behavior that reinforces social bonds within the pack and establishes their territory. Their padded paws allow them to traverse the icy terrain with ease, and their keen senses help them locate food across vast distances. Despite the frigid temperatures, these resilient canines continue to thrive in the extreme conditions of the Siberian wilderness.\n",
      "\n",
      "Prompt: On the day Franklin Benjamin realized his passion for printer, ...\n",
      "\n",
      "Answer: On the day Benjamin Franklin realized his passion for printing, a transformative journey began for him. As a young apprentice under his brother James, this future Founding Father of the United States learned the trade that would underpin his career and contribute to his wealth and influence. His mastery of the printed word not only led to the creation of a successful printing business but also facilitated his rise as a civic leader, inventor, and diplomat. This passion for printing and communication would eventually manifest in his contributions to American independence, most famously through his involvement in drafting the Declaration of Independence. Franklin's dedication to printing played a vital role in shaping his intellectual pursuits and his impact on American society.\n",
      "\n",
      "Prompt: During the final World Cup 1998 when France beat Brazil in Paris, ...\n",
      "\n",
      "Answer: the Stade de France erupted with joy as the host nation secured its first-ever World Cup victory. The final score was 3-0, with two goals from Zinedine Zidane and one from Emmanuel Petit. The French team, led by captain Didier Deschamps, displayed a dominant performance throughout the tournament. That victory in the global football event also had a significant sociocultural impact on France, as it was celebrated as a triumph of the country's multicultural team. The defeat was a huge disappointment for Brazil, the defending champions, and their star player, Ronaldo, who was expected to make a big impact but was hampered by health issues on the day of the final.\n",
      "\n",
      "Prompt: Issac Newton set under a tree when an apple fell...\n",
      "\n",
      "Answer: Isaac Newton sat under a tree when an apple fell, an event that, according to popular legend, led to his contemplation of the forces of gravity. Although this story is often regarded as apocryphal or at least exaggerated, it serves as a powerful symbol of Newton's insight into the universal law that governs celestial and earthly bodies alike. His formulation of the law of universal gravitation was revolutionary, as it provided a mathematical explanation for both the motion of planets and the phenomena observed on Earth. Newton's work in physics, captured in his seminal work \"Philosophi√¶ Naturalis Principia Mathematica,\" laid the groundwork for classical mechanics. His influence extended beyond his own time, shaping the course of scientific inquiry for centuries to come.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for user_prompt in user_prompts:\n",
    "    response = get_commpletion(client, MODEL, system_content, user_prompt)\n",
    "    print(f\"\\nPrompt: {user_prompt}\")\n",
    "    print(f\"\\nAnswer: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e03d54-6200-4664-9a6d-13fe8297e0cb",
   "metadata": {},
   "source": [
    "## Text summarization\n",
    "\n",
    "A common task in natural langauge processing is text summiarization. A common use case\n",
    "is summarizing large articles or documents, for a quick and easy-to-absorb summaries.\n",
    "\n",
    "You can instruct LLM to generate the response in a preferable style, and comprehensibility. For example, use simple language aimed for a certain grade level, keep the orginal style of the article, use different sentence sytles (as we have done in few of examples in this notebook and previous one).\n",
    "\n",
    "Let's try a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85736577-b4ee-466e-90c8-a810849fe172",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"You are master of all knowledge about history, literature, science, philosophy, religion, economics, sports, etc. \\\n",
    "                  You will provided with original ```{content}``` \\\n",
    "                  Use simple, compound, and compound-complex sentences to rewrite as a summary, with no more than \\\n",
    "                  one paragraph and no more than five sentences. Keep summary succinct and cohesive, and maintain the original content's tone.\"\n",
    "\n",
    "user_prompts = [\n",
    "    \"\"\" ```The emergence of large language models (LLMs) has marked a significant breakthrough in natural language processing (NLP), leading to remarkable advancements in text understanding and generation. \\ \n",
    "\n",
    "    Nevertheless, alongside these strides, LLMs exhibit a critical tendency \n",
    "to produce hallucinations, resulting in content that is inconsistent with real-world facts or user \n",
    "inputs. This phenomenon poses substantial challenges to their practical deployment and \\\n",
    "raises concerns over the reliability of LLMs in real-world scenarios, which attracts increasing \\\n",
    "attention to detect and mitigate these hallucinations. In this survey, we aim to provide a thorough and in-depth  overview of recent advances in the field of LLM hallucinations. \n",
    "\n",
    "    We begin with an innovative taxonomy of LLM hallucinations, then delve into the factors contributing\n",
    "to hallucinations. Subsequently, we present a comprehensive overview of hallucination detection methods and benchmarks. Additionally, representative approaches designed to mitigate hallucinations are introduced accordingly. \n",
    "\n",
    "    Finally, we analyze the challenges that highlight the current limitations and formulate open questions, aiming to delineate pathways for future  research on hallucinations in LLMs.```\"\"\",\n",
    "    \"\"\"```Can a Large Language Model (LLM) solve simple abstract reasoning problems? We explore this broad question through a systematic analysis of GPT on the Abstraction and Reasoning Corpus (ARC), a representative benchmark of abstract reasoning ability from limited examples in which solutions require some \"core knowledge\" of concepts such as objects, goal states, counting, and basic geometry. GPT-4 solves only 13/50 of the most straightforward ARC tasks when using textual encodings for their two-dimensional input-output grids. Our failure analysis reveals that GPT-4's capacity to identify objects and reason about them is significantly influenced by the sequential nature of the text that represents an object within a text encoding of a task. To test this hypothesis, we design a new benchmark, the 1D-ARC, which consists of one-dimensional (array-like) tasks that are more conducive to GPT-based reasoning, and where it indeed performs better than on the (2D) ARC. To alleviate this issue, we propose an object-based representation that is obtained through an external tool, resulting in nearly doubling the performance on solved ARC tasks and near-perfect scores on the easier 1D-ARC. Although the state-of-the-art GPT-4 is unable to \"reason\" perfectly within non-language domains such as the 1D-ARC or a simple ARC subset, our study reveals that the use of object-based representations can significantly improve its reasoning ability. Visualizations, GPT logs, and data are available at¬†this https URL.```\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a884cb94-0c4a-40bc-a847-1d5eb354cafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Original content:  ```The emergence of large language models (LLMs) has marked a significant breakthrough in natural language processing (NLP), leading to remarkable advancements in text understanding and generation. \\ \n",
      "\n",
      "    Nevertheless, alongside these strides, LLMs exhibit a critical tendency \n",
      "to produce hallucinations, resulting in content that is inconsistent with real-world facts or user \n",
      "inputs. This phenomenon poses substantial challenges to their practical deployment and raises concerns over the reliability of LLMs in real-world scenarios, which attracts increasing attention to detect and mitigate these hallucinations. In this survey, we aim to provide a thorough and in-depth  overview of recent advances in the field of LLM hallucinations. \n",
      "\n",
      "    We begin with an innovative taxonomy of LLM hallucinations, then delve into the factors contributing\n",
      "to hallucinations. Subsequently, we present a comprehensive overview of hallucination detection methods and benchmarks. Additionally, representative approaches designed to mitigate hallucinations are introduced accordingly. \n",
      "\n",
      "    Finally, we analyze the challenges that highlight the current limitations and formulate open questions, aiming to delineate pathways for future  research on hallucinations in LLMs.```\n",
      "\n",
      "Summary  content: Large language models have revolutionized natural language processing with improved text analysis and creation; however, they are prone to generating \"hallucinations\" or factually inaccurate content, casting doubt on their dependability for real-world applications. This survey responds to the issue by categorizing these hallucinations, examining their causes, and evaluating detection and mitigation techniques. It also discusses the challenges and unanswered questions in the field, setting an agenda for future investigation into LLM hallucinations. The goal is to provide a comprehensive understanding of hallucinations in LLMs, with a focus on addressing the gap between current capabilities and the reliability required for practical use.\n",
      "\n",
      "Original content: ```Can a Large Language Model (LLM) solve simple abstract reasoning problems? We explore this broad question through a systematic analysis of GPT on the Abstraction and Reasoning Corpus (ARC), a representative benchmark of abstract reasoning ability from limited examples in which solutions require some \"core knowledge\" of concepts such as objects, goal states, counting, and basic geometry. GPT-4 solves only 13/50 of the most straightforward ARC tasks when using textual encodings for their two-dimensional input-output grids. Our failure analysis reveals that GPT-4's capacity to identify objects and reason about them is significantly influenced by the sequential nature of the text that represents an object within a text encoding of a task. To test this hypothesis, we design a new benchmark, the 1D-ARC, which consists of one-dimensional (array-like) tasks that are more conducive to GPT-based reasoning, and where it indeed performs better than on the (2D) ARC. To alleviate this issue, we propose an object-based representation that is obtained through an external tool, resulting in nearly doubling the performance on solved ARC tasks and near-perfect scores on the easier 1D-ARC. Although the state-of-the-art GPT-4 is unable to \"reason\" perfectly within non-language domains such as the 1D-ARC or a simple ARC subset, our study reveals that the use of object-based representations can significantly improve its reasoning ability. Visualizations, GPT logs, and data are available at¬†this https URL.```\n",
      "\n",
      "Summary  content: Through a detailed examination, it has been found that GPT-4, a Large Language Model, struggles with the Abstraction and Reasoning Corpus (ARC), solving only 13 out of 50 simple tasks, as the model's reasoning is hampered by the linear text format of object representation. A newly created one-dimensional version of ARC (1D-ARC) shows GPT-4's improved performance in a format better suited to its design. The introduction of an object-based representation, facilitated by an external tool, nearly doubles GPT-4's success rate on ARC tasks and achieves almost perfect results on the 1D-ARC. This study suggests that while GPT-4 is not fully equipped for abstract reasoning tasks as currently structured, adapting task representations can enhance its capabilities significantly. The resources for this research are publicly accessible online.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for user_prompt in user_prompts:\n",
    "    response = get_commpletion(client, MODEL, system_content, user_prompt)\n",
    "    print(f\"\\nOriginal content: {user_prompt}\")\n",
    "    print(f\"\\nSummary  content: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7184cf9-1e3d-4ee1-9699-61403a423ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
