{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39330ca8-0778-405c-8d1f-2c31e190ebde",
   "metadata": {},
   "source": [
    "## Basic LLM Tasks\n",
    "In the *1_basic_prompt* notebook, we explored using prompts to query an LLM model. This notebook presents diverse examples to demonstrate various tasks and introduce key concepts, emphasizing effective learning through practical instances. The tasks explored in this notebook, using sophiscated prompting techniques, show *how-to* code examples for:\n",
    "\n",
    " * Text generation or completion\n",
    " * Text summarization\n",
    " * Text extraction\n",
    " * Text classification or sentiment analysis\n",
    " * Text categorization\n",
    " * Text transformation and translation\n",
    " * Simple and complex reasoning\n",
    " *  Code generation\n",
    "\n",
    "<img src=\"./images/prompt_req_resp.png\" height=\"35%\" width=\"%65\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798bde8f-44a7-4e9f-ba30-0ffccd1d4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "249c0446-7d74-402b-b7a5-9ab6f1d59224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "warnings.filterwarnings('ignore')\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b45071b3-6e6e-497b-9126-ab592053d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8654cd8-fa3d-4d94-a7c9-37053a3434be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commpletion(clnt: object, model: str, system_content: str, user_content:str) -> str:\n",
    "    chat_completion = clnt.chat.completions.create(\n",
    "        model=model,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_content},\n",
    "              {\"role\": \"user\", \"content\": user_content}],\n",
    "    temperature = 0.8)\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f06061-ea86-4e09-b006-9a0c61f92e33",
   "metadata": {},
   "source": [
    "## Text generation or completion\n",
    "In this simple task, we use an LLM to generate text by finishing an incomplete user content provided in the prompt. For example,\n",
    "by providing an incomplete prompt such as \"On a cold winter night, the stray dog ...\". \n",
    "\n",
    "Let's try a few text generation or completion tasks by providing partial prompts in the user content. You will surprised at its\n",
    "fluency and coherency in the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07fbcbf8-0ccc-4fd4-a27d-a27c1ad14ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are master of all knowledge, and a helpful sage.\n",
    "                    You must complete any incomplete sentence by drawing from your vast\n",
    "                    knowledge about history, literature, science, social science, philosophy, religion, economics, sports, etc.\n",
    "                  \"\"\"\n",
    "\n",
    "user_prompts =  [\"On cold winter nights, the wolves in Siberia ...\",\n",
    "                 \"On the day Franklin Benjamin realized his passion for printer, ...\",\n",
    "                 \"During the final World Cup 1998 when France beat Brazil in Paris, ...\",\n",
    "                 \"Issac Newton set under a tree when an apple fell...\"\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c39358d-f343-4596-bd28-5f36a3ba85d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Prompt: On cold winter nights, the wolves in Siberia ...\n",
      "\n",
      "Answer: \n",
      "On cold winter nights, the wolves in Siberia howl hauntingly through the frozen forests. Their thick fur shields them from the biting chill as they prowl in search of prey. Packs move with purpose, exhibiting complex social behaviors that ensure their survival. While the cold may deter others, the wolves' keen senses and enduring stamina make them masters of the harsh landscape. In the silence of the snow-covered expanses, their calls echo, a testament to the wild's untamed spirit.\n",
      "\n",
      "\n",
      "Prompt: On the day Franklin Benjamin realized his passion for printer, ...\n",
      "\n",
      "Answer: On the day Franklin Benjamin realized his passion for printing, a new chapter in his life began. He apprenticed under his brother James, learning the intricacies of the trade with an eager mind. As Franklin's skills grew, so did his ambition, leading him to eventually establish his own printing house. His establishment not only produced printed materials but also became a hub for intellectual discourse, reflecting Franklin's diverse interests. Through this medium, he influenced public opinion and contributed significantly to American culture and politics.\n",
      "\n",
      "Prompt: During the final World Cup 1998 when France beat Brazil in Paris, ...\n",
      "\n",
      "Answer: \n",
      "During the final World Cup 1998 when France beat Brazil in Paris, the host nation captured its first-ever FIFA World Cup title. The French team, led by captain Didier Deschamps and featuring star player Zinedine Zidane, triumphed with a convincing 3-0 score. Zidane scored twice with headers from corner kicks in the first half, etching his name into football history. Defender Marcel Desailly was sent off with a red card, yet France maintained its lead and Emmanuel Petit scored a third goal in injury time. The victory sparked jubilant celebrations throughout France, culminating with thousands gathering on the Champs-Élysées in Paris.\n",
      "\n",
      "\n",
      "Prompt: Issac Newton set under a tree when an apple fell...\n",
      "\n",
      "Answer: Isaac Newton sat under a tree when an apple fell and prompted a profound contemplation. This event led him to formulate the law of universal gravitation. While the story is often simplified, it symbolizes the power of observation in scientific discovery. Through his work, Newton revolutionized the understanding of physics. His laws of motion and gravitation became foundational to classical mechanics.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for user_prompt in user_prompts:\n",
    "    prompt = f\"\"\" Compete the text ```{user_prompt}``` between three backticks.\n",
    "    You will use simple, compound, and compound-complex sentences for all your responses, \n",
    "    and no more than one paragraph and no more than five sentences. \n",
    "    Keep your sentences succinct and cohesive.\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    response = response.replace(\"```\", \"\")\n",
    "    print(f\"\\nPrompt: {user_prompt}\")\n",
    "    print(f\"\\nAnswer: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e03d54-6200-4664-9a6d-13fe8297e0cb",
   "metadata": {},
   "source": [
    "## Text summarization\n",
    "\n",
    "A common task in natural langauge processing is text summiarization. A common use case\n",
    "is summarizing large articles or documents, for a quick and easy-to-absorb summaries.\n",
    "\n",
    "You can instruct LLM to generate the response in a preferable style, and comprehensibility. For example, use simple language aimed for a certain grade level, keep the orginal style of the article, use different sentence sytles (as we have done in few of examples in this notebook and previous one).\n",
    "\n",
    "Let's try a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85736577-b4ee-466e-90c8-a810849fe172",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are master of all knowledge about history, literature, science, philosophy, religion, economics, sports, etc.\"\"\" \n",
    "                \n",
    "user_prompts = [\n",
    "    \"\"\" The emergence of large language models (LLMs) has marked a significant \n",
    "         breakthrough in natural language processing (NLP), leading to remarkable \n",
    "         advancements in text understanding and generation. \n",
    "         \n",
    "         Nevertheless, alongside these strides, LLMs exhibit a critical tendency \n",
    "         to produce hallucinations, resulting in content that is inconsistent with \n",
    "         real-world facts or user inputs. This phenomenon poses substantial challenges \n",
    "         to their practical deployment and raises concerns over the reliability of LLMs \n",
    "         in real-world scenarios, which attracts increasing attention to detect and \n",
    "         mitigate these hallucinations. In this survey, we aim to provide a thorough and \n",
    "         in-depth  overview of recent advances in the field of LLM hallucinations. \n",
    "         \n",
    "         We begin with an innovative taxonomy of LLM hallucinations, then delve into the \n",
    "         factors contributing to hallucinations. Subsequently, we present a comprehensive\n",
    "         overview of hallucination detection methods and benchmarks. \n",
    "         Additionally, representative approaches designed to mitigate hallucinations \n",
    "         are introduced accordingly. \n",
    "         \n",
    "         Finally, we analyze the challenges that highlight the current limitations and \n",
    "         formulate open questions, aiming to delineate pathways for future  research on \n",
    "         hallucinations in LLMs.\"\"\",\n",
    "    \"\"\"  Can a Large Language Model (LLM) solve simple abstract reasoning problems?\n",
    "         We explore this broad question through a systematic analysis of GPT on the \n",
    "         Abstraction and Reasoning Corpus (ARC), a representative benchmark of abstract \n",
    "         reasoning ability from limited examples in which solutions require some \n",
    "         \"core knowledge\" of concepts such as objects, goal states, counting, and \n",
    "         basic geometry. GPT-4 solves only 13/50 of the most straightforward ARC \n",
    "         tasks when using textual encodings for their two-dimensional input-output grids. \n",
    "         Our failure analysis reveals that GPT-4's capacity to identify objects and \n",
    "         reason about them is significantly influenced by the sequential nature of \n",
    "         the text that represents an object within a text encoding of a task. \n",
    "         To test this hypothesis, we design a new benchmark, the 1D-ARC, which \n",
    "         consists of one-dimensional (array-like) tasks that are more conducive \n",
    "         to GPT-based reasoning, and where it indeed performs better than on \n",
    "         the (2D) ARC. To alleviate this issue, we propose an object-based \n",
    "         representation that is obtained through an external tool, resulting in \n",
    "         nearly doubling the performance on solved ARC tasks and near-perfect scores \n",
    "         on the easier 1D-ARC. Although the state-of-the-art GPT-4 is unable to \n",
    "         \"reason\" perfectly within non-language domains such as the 1D-ARC or a \n",
    "         simple ARC subset, our study reveals that the use of object-based representations \n",
    "         can significantly improve its reasoning ability. Visualizations, GPT logs, and \n",
    "         data are available at this https URL.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a884cb94-0c4a-40bc-a847-1d5eb354cafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Original content:  The emergence of large language models (LLMs) has marked a significant \n",
      "         breakthrough in natural language processing (NLP), leading to remarkable \n",
      "         advancements in text understanding and generation. \n",
      "         \n",
      "         Nevertheless, alongside these strides, LLMs exhibit a critical tendency \n",
      "         to produce hallucinations, resulting in content that is inconsistent with \n",
      "         real-world facts or user inputs. This phenomenon poses substantial challenges \n",
      "         to their practical deployment and raises concerns over the reliability of LLMs \n",
      "         in real-world scenarios, which attracts increasing attention to detect and \n",
      "         mitigate these hallucinations. In this survey, we aim to provide a thorough and \n",
      "         in-depth  overview of recent advances in the field of LLM hallucinations. \n",
      "         \n",
      "         We begin with an innovative taxonomy of LLM hallucinations, then delve into the \n",
      "         factors contributing to hallucinations. Subsequently, we present a comprehensive\n",
      "         overview of hallucination detection methods and benchmarks. \n",
      "         Additionally, representative approaches designed to mitigate hallucinations \n",
      "         are introduced accordingly. \n",
      "         \n",
      "         Finally, we analyze the challenges that highlight the current limitations and \n",
      "         formulate open questions, aiming to delineate pathways for future  research on \n",
      "         hallucinations in LLMs.\n",
      "\n",
      "Summary  content: The emergence of large language models (LLMs) has revolutionized natural language processing, improving our ability to understand and generate text. However, LLMs often create hallucinations—false or ungrounded content—which poses significant challenges for their practical application and reliability. This survey examines recent progress in understanding and addressing LLM hallucinations, introducing a new classification system, exploring causes, and reviewing detection and mitigation strategies. It also identifies current limitations and proposes questions for future research. The focus on hallucinations underscores the need for more robust and dependable LLMs in practical settings.\n",
      "\n",
      "Original content:   Can a Large Language Model (LLM) solve simple abstract reasoning problems?\n",
      "         We explore this broad question through a systematic analysis of GPT on the \n",
      "         Abstraction and Reasoning Corpus (ARC), a representative benchmark of abstract \n",
      "         reasoning ability from limited examples in which solutions require some \n",
      "         \"core knowledge\" of concepts such as objects, goal states, counting, and \n",
      "         basic geometry. GPT-4 solves only 13/50 of the most straightforward ARC \n",
      "         tasks when using textual encodings for their two-dimensional input-output grids. \n",
      "         Our failure analysis reveals that GPT-4's capacity to identify objects and \n",
      "         reason about them is significantly influenced by the sequential nature of \n",
      "         the text that represents an object within a text encoding of a task. \n",
      "         To test this hypothesis, we design a new benchmark, the 1D-ARC, which \n",
      "         consists of one-dimensional (array-like) tasks that are more conducive \n",
      "         to GPT-based reasoning, and where it indeed performs better than on \n",
      "         the (2D) ARC. To alleviate this issue, we propose an object-based \n",
      "         representation that is obtained through an external tool, resulting in \n",
      "         nearly doubling the performance on solved ARC tasks and near-perfect scores \n",
      "         on the easier 1D-ARC. Although the state-of-the-art GPT-4 is unable to \n",
      "         \"reason\" perfectly within non-language domains such as the 1D-ARC or a \n",
      "         simple ARC subset, our study reveals that the use of object-based representations \n",
      "         can significantly improve its reasoning ability. Visualizations, GPT logs, and \n",
      "         data are available at this https URL.\n",
      "\n",
      "Summary  content: The text examines whether GPT-4, a Large Language Model, can tackle simple abstract reasoning problems as presented in the Abstraction and Reasoning Corpus (ARC), which demands an understanding of fundamental concepts. GPT-4's performance was limited, solving only 13 out of 50 straightforward ARC tasks when the tasks were represented as textual input-output grids. Analysis suggested that GPT-4 struggles with reasoning about objects due to the sequential nature of text representation. An alternative one-dimensional version of the ARC (1D-ARC) and an object-based representation were proposed, both improving GPT-4's performance, with the latter nearly doubling its success rate on ARC tasks and achieving near-perfect results on the 1D-ARC. Despite these improvements, GPT-4 is not yet fully capable of abstract reasoning within non-language domains, but object-based representations offer a significant enhancement.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for user_prompt in user_prompts:\n",
    "    prompt = f\"\"\"Summarize the text delimited by triple backticks \n",
    "              ```{user_prompt}``` Use simple, compound, and compound-complex sentences, with \n",
    "              no more than one paragraph and no more than five sentences. \n",
    "              Keep summary succinct and cohesive, and maintain the original content's tone. \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\nOriginal content: {user_prompt}\")\n",
    "    print(f\"\\nSummary  content: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affe9c30-bf89-49ee-80c8-c5d260b91914",
   "metadata": {},
   "source": [
    "## Text or information extraction\n",
    "\n",
    "Another natural langauge capability, similar to summarization or text completion, is extracting key idea or infromation from an article, blog, or a paragraph. For example,\n",
    "given a set of text, you can ask LLM to extract key ideas or topics or subjects. Or even\n",
    "better enumerate key takeways for you, saving time if you are in a hurry.\n",
    "\n",
    "Let's see *how-to* do it by first looking at a simple example, and then progressing into a more complex one.\n",
    "\n",
    "### Task 1: \n",
    " * summarize the product review\n",
    " * extract any information about shipping and packaging for shipping department\n",
    " * classify the sentiment of the review: positive or negative.\n",
    " * use precise, specific prompt to acheive the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21406dcc-e9b1-4028-8281-297ae762b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"You are master of all knowledge about history, literature, science, social science, philosophy, religion, economics, sports, etc.\"\n",
    "product_review = \"\"\"I got this Australian Bush Baby with soft fur for my niece's birthday, and she absolutely loves it, carrying it around everywhere. The fur is exceptionally soft, and its adorable face gives off a friendly vibe. While I find it a bit smaller than anticipated for the price, my niece's joy makes it worthwhile. What pleasantly surprised me was the early arrival; it came a day earlier than expected. I appreciated the prompt delivery, and the packaging was secure, ensuring the Bush Baby with soft fur arrived in perfect condition. This allowed me to play with it myself before presenting it to my niece.\"\"\"     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "384515f8-a970-421a-86bb-be3ea8800bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \n",
    "review from an Australian e-commerce site to offer feedback to the \n",
    "shipping deparmtment. \n",
    "\n",
    "First, provide a short summary the review below, delimited by triple \n",
    "backticks, in two sentences: a simple and compound sentence. Second focus \n",
    "on any aspects packaging or shipping of the product, and label it as \n",
    "\"Shipping Department:\".  Third, indicate if the review is positive or negative, \n",
    "and label it as \"Sentiment:\"\n",
    "Review: ```{product_review}``` \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0056f55-c3aa-4a4e-bd11-fec330436af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Summary: \n",
      "The customer is pleased with the Australian Bush Baby toy's soft fur and friendly appearance, though it was smaller than expected. The early arrival and secure packaging were particularly appreciated, adding to the overall satisfaction.\n",
      "\n",
      "\n",
      "Shipping Department: The product arrived a day earlier than expected and was securely packaged, ensuring it arrived in perfect condition.\n",
      "\n",
      "Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "print(f\"\"\"\\nSummary: {response.replace(\"```\", \"\")}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb0d62-e2a7-4669-9792-57f20ed95980",
   "metadata": {},
   "source": [
    "### Task 2\n",
    " * Given a passage from an article, extract the main theme of the passage and label it as the `Subjects`, if more than one, separated by comma.\n",
    " * Identify three key takeways and enumerate them in simple sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cdcd4d4-62c7-4dea-b98a-58070552c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"You are master of all knowledge about history, literature, science, social science, philosophy, religion, economics, sports, etc.\"\n",
    "            \n",
    "user_prompts = [\"Isaac Newton sat under a tree when an apple fell, an event that, \\\n",
    "                according to popular legend, led to his contemplation of the forces\\\n",
    "                of gravity. Although this story is often regarded as apocryphal or at \\\n",
    "                least exaggerated, it serves as a powerful symbol of Newton's insight \\\n",
    "                into the universal law that governs celestial and earthly bodies alike. \\\n",
    "                His formulation of the law of universal gravitation was revolutionary, \\\n",
    "                as it provided a mathematical explanation for both the motion of planets \\\n",
    "                and the phenomena observed on Earth. Newton's work in physics, captured \\\n",
    "                in his seminal work Philosophiæ Naturalis Principia Mathematica, laid the \\\n",
    "                groundwork for classical mechanics. His influence extended beyond his own \\\n",
    "                time, shaping the course of scientific inquiry for centuries to come.\"\n",
    "               ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7e16e2f-14ec-4bfd-9687-294683ad5c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Original content: Isaac Newton sat under a tree when an apple fell, an event that,                 according to popular legend, led to his contemplation of the forces                of gravity. Although this story is often regarded as apocryphal or at                 least exaggerated, it serves as a powerful symbol of Newton's insight                 into the universal law that governs celestial and earthly bodies alike.                 His formulation of the law of universal gravitation was revolutionary,                 as it provided a mathematical explanation for both the motion of planets                 and the phenomena observed on Earth. Newton's work in physics, captured                 in his seminal work Philosophiæ Naturalis Principia Mathematica, laid the                 groundwork for classical mechanics. His influence extended beyond his own                 time, shaping the course of scientific inquiry for centuries to come.\n",
      "\n",
      " Subject: Newton's Law of Universal Gravitation\n",
      "\n",
      "Takeaways:\n",
      "1. A legend states that seeing an apple fall inspired Newton to think about gravity.\n",
      "2. Newton's law of universal gravitation explained how gravity works on Earth and in space.\n",
      "3. His work was fundamental to the development of classical mechanics.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for text in user_prompts:\n",
    "    prompt = f\"\"\" Given ```{text}``` delimited with triple backticks, identify a single key idea being discussed, \n",
    "    and label its 'Subject'. Next, enumerate at most three takeways. \n",
    "    Use short, simple sentences. \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\nOriginal content: {text}\")\n",
    "    print(f\"\\n {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113abb50-6a73-4101-8846-e8f26d85bb9c",
   "metadata": {},
   "source": [
    "Let's try another example to extract more than on subject or topic being\n",
    "discussed in the text, and enumerate three takeways.\n",
    "\n",
    "(Incidentally, I'm reading biography of Benjamin Franklin by Issac Stevenson, and all this seems to align with his career path and passion.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f34ceebf-c1b6-495b-8c78-81d2fc45baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stories = [\"\"\"\"Printer.\n",
    "                He that has a Trade has an Office of Profit and Honour’ Poor Richard’s Almanack\n",
    "Benjamin Franklin had an affinity with print and books throughout his life. \n",
    "Apprenticed as a child to his brother James, a printer, he mastered all aspects of\n",
    "the trade, from typesetting to engraving, learning the latest techniques during his\n",
    "first visit to London.  An avid reader, Franklin saved money to buy books by \n",
    "temporarily turning vegetarian and, once settled in Philadelphia, founded the \n",
    "Library Company, the first subscription library in the colonies.  As an elder\n",
    "statesman, he even bought type and kept a press during his stay in France. \n",
    "After working as a printer’s journeyman, he set up his own Philadelphian printing \n",
    "office in 1728.  His success with the Pennslyannia Gazette and Poor Richard’s\n",
    "Almanack helped to provide Franklin with the financial means to retire from\n",
    "business, retaining a stake in his print shop and founding others throughout the \n",
    "colonies.  Print also gave him a public voice: Franklin preferred the printed word, \n",
    "rather than public rhetoric, influencing political and public opinion as a brilliant\n",
    "journalist and pamphleteer.\n",
    "\n",
    "Silence Dogood and the New­England Courant\n",
    "    When James Franklin lost the contract to print the Boston Gazette, he determined\n",
    "to begin his own newspaper, launching the New­England Courant in 1721.\n",
    "Benjamin, who had been indentured secretly to James, helped to print the weekly \n",
    "paper.  One night he slipped a composition under the door, beginning the series\n",
    "of ‘Silence Dogood’ letters, the purported epistles of a vocal widower, with strong \n",
    "opinions on drunks, clergymen, foolish fashions and Boston nightlife. Owing no\n",
    "little debt to the satire of the London Spectator, the letters represented a \n",
    "remarkable literary achievement for the 16­year old.  The British Library’s copy has \n",
    "been uniquely annotated in what appears to be Franklin’s hand. The first \n",
    "‘Dogood’ letter appears on the bottom right.\n",
    "\n",
    "‘The Main Design of the Weekly Paper will be to Entertain the Town’\n",
    "    Benjamin’s brother, James, began the New­England Courant in the face of\n",
    "opposition from the Boston Establishment.  He soon irritated them with his squibs\n",
    "and satires on the great and the good, attacking the influential clergyman Cotton\n",
    "Mather’s pet project of small pox inoculation and the authorities’ weak response \n",
    "to piracy. Twice arrested, James temporally left the paper in Benjamin’s hands, and \n",
    "then continued to publish it under Benjamin’s name to escape a ban on\n",
    "publication.  This issue is the first printed item to carry the imprint ‘B. Franklin’ (on\n",
    "the rear).  Franklin announces his intention to ‘Entertain the Town’ on this page.\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1909a1b5-68fa-449c-9d40-0d4494b75b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Complete Storey: \"Printer.\n",
      "                He that has a Trade has an Office of Profit and Honour’ Poor Richard’s Almanack\n",
      "Benjamin Franklin had an affinity with print and books throughout his life. \n",
      "Apprenticed as a child to his brother James, a printer, he mastered all aspects of\n",
      "the trade, from typesetting to engraving, learning the latest techniques during his\n",
      "first visit to London.  An avid reader, Franklin saved money to buy books by \n",
      "temporarily turning vegetarian and, once settled in Philadelphia, founded the \n",
      "Library Company, the first subscription library in the colonies.  As an elder\n",
      "statesman, he even bought type and kept a press during his stay in France. \n",
      "After working as a printer’s journeyman, he set up his own Philadelphian printing \n",
      "office in 1728.  His success with the Pennslyannia Gazette and Poor Richard’s\n",
      "Almanack helped to provide Franklin with the financial means to retire from\n",
      "business, retaining a stake in his print shop and founding others throughout the \n",
      "colonies.  Print also gave him a public voice: Franklin preferred the printed word, \n",
      "rather than public rhetoric, influencing political and public opinion as a brilliant\n",
      "journalist and pamphleteer.\n",
      "\n",
      "Silence Dogood and the New­England Courant\n",
      "    When James Franklin lost the contract to print the Boston Gazette, he determined\n",
      "to begin his own newspaper, launching the New­England Courant in 1721.\n",
      "Benjamin, who had been indentured secretly to James, helped to print the weekly \n",
      "paper.  One night he slipped a composition under the door, beginning the series\n",
      "of ‘Silence Dogood’ letters, the purported epistles of a vocal widower, with strong \n",
      "opinions on drunks, clergymen, foolish fashions and Boston nightlife. Owing no\n",
      "little debt to the satire of the London Spectator, the letters represented a \n",
      "remarkable literary achievement for the 16­year old.  The British Library’s copy has \n",
      "been uniquely annotated in what appears to be Franklin’s hand. The first \n",
      "‘Dogood’ letter appears on the bottom right.\n",
      "\n",
      "‘The Main Design of the Weekly Paper will be to Entertain the Town’\n",
      "    Benjamin’s brother, James, began the New­England Courant in the face of\n",
      "opposition from the Boston Establishment.  He soon irritated them with his squibs\n",
      "and satires on the great and the good, attacking the influential clergyman Cotton\n",
      "Mather’s pet project of small pox inoculation and the authorities’ weak response \n",
      "to piracy. Twice arrested, James temporally left the paper in Benjamin’s hands, and \n",
      "then continued to publish it under Benjamin’s name to escape a ban on\n",
      "publication.  This issue is the first printed item to carry the imprint ‘B. Franklin’ (on\n",
      "the rear).  Franklin announces his intention to ‘Entertain the Town’ on this page.\n",
      "\n",
      "\n",
      " Subjects: Printing, Literature, Journalism, Political Influence, Public Voice\n",
      "\n",
      "Takeaways:\n",
      "1. Benjamin Franklin was a skilled printer.\n",
      "2. Franklin contributed to literature with 'Silence Dogood' letters.\n",
      "3. He influenced public opinion through print.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for story in user_stories:\n",
    "    prompt = f\"\"\" Extract five subjects that are being discussed in the \n",
    "                  following text, which is delimited by triple backticks.\n",
    "                  Format your response as a list of subjects \"Subjects:\" separated by commas.\n",
    "                  Make each subject at most two words long, not longer. \n",
    "                  Next, enumerate  as a list three takeways, and label them as \"Takeways:\" \n",
    "                  Use short, simple sentences for your takeways.\n",
    "                  Text sample: '''{story}'''\n",
    "                  \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\nComplete Storey: {story}\")\n",
    "    print(f\"\\n {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08da3189-e9d0-42c9-9f70-d403df9e0dc5",
   "metadata": {},
   "source": [
    "## Text classification or sentiment analysis\n",
    "\n",
    "Unlike classical or traditional machine learning, where you'll have to do supervised learning to collect data, label it, and train for hours, depending on how much data,classifying text using LLM is simple.\n",
    "\n",
    "In short, you'll have to build a ML model to understand text and classify its sentiments as positive, negative or neutral. \n",
    "\n",
    "This onus task is easily done with LLM via clever prompting. \n",
    "\n",
    "Let's see what I mean in this *how-to* idenfity sentiments in text But first let's \n",
    "generatre some sentiments as our ground truth, and supply them to LLM to observe it\n",
    "LLM identifies them correctly. This bit is not needed, for I'm just curious.\n",
    "\n",
    "Positive: \"This movie is a true cinematic gem, blending an engaging plot with superb performances and stunning visuals. A masterpiece that leaves a lasting impression.\"\n",
    "\n",
    "*Negative*: \"Regrettably, the film failed to live up to expectations, with a convoluted storyline, lackluster acting, and uninspiring cinematography. A disappointment overall.\"\n",
    "\n",
    "*Neutral*: \"The movie had its moments, offering a decent storyline and average performances. While not groundbreaking, it provided an enjoyable viewing experience.\"\n",
    "\n",
    "*Positive*: \"This city is a vibrant tapestry of culture, with friendly locals, historic landmarks, and a lively atmosphere. An ideal destination for cultural exploration.\"\n",
    "\n",
    "*Negative*: \"The city's charm is overshadowed by traffic congestion, high pollution levels, and a lack of cleanliness. Not recommended for a peaceful retreat.\"\n",
    "\n",
    "*Neutral*: \"The city offers a mix of experiences, from bustling markets to serene parks. An interesting but not extraordinary destination for exploration.\"\n",
    "\n",
    "*Positive*: \"This song is a musical masterpiece, enchanting listeners with its soulful lyrics, mesmerizing melody, and exceptional vocals. A timeless classic.\"\n",
    "\n",
    "*Negative*: \"The song fails to impress, featuring uninspiring lyrics, a forgettable melody, and lackluster vocals. It lacks the creativity to leave a lasting impact.\"\n",
    "\n",
    "*Neutral*: \"The song is decent, with a catchy tune and average lyrics. While enjoyable, it doesn't stand out in the vast landscape of music.\"\n",
    "\n",
    "*Positive*: \"A delightful cinematic experience that seamlessly weaves together a compelling narrative, strong character development, and breathtaking visuals.\"\n",
    "\n",
    "*Negative*: \"This film, unfortunately, falls short with a disjointed plot, subpar performances, and a lack of coherence. A disappointing viewing experience.\"\n",
    "\n",
    "*Neutral*: \"While not groundbreaking, the movie offers a decent storyline and competent performances, providing an overall satisfactory viewing experience.\"\n",
    "\n",
    "*Positive*: \"This city is a haven for culture enthusiasts, boasting historical landmarks, a rich culinary scene, and a welcoming community. A must-visit destination.\"\n",
    "\n",
    "*Negative*: \"The city's appeal is tarnished by overcrowded streets, noise pollution, and a lack of urban planning. Not recommended for a tranquil getaway.\"\n",
    "\n",
    "*Neutral*: \"The city offers a diverse range of experiences, from bustling markets to serene parks. An intriguing destination for those seeking a mix of urban and natural landscapes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26fba25e-e40b-40fc-84b5-0a86df748b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a prominent critic of landscapes, architecture, cities, movies, songs, \n",
    "                    entertainment, and a cultural ombudsman. \"\"\"\n",
    "\n",
    "user_sentiments = [ \"This movie is a true cinematic gem, blending an engaging plot with superb performances and stunning visuals. A masterpiece that leaves a lasting impression.\",\n",
    "                    \"Regrettably, the film failed to live up to expectations, with a convoluted storyline, lackluster acting, and uninspiring cinematography. A disappointment overall.\",\n",
    "                    \"The movie had its moments, offering a decent storyline and average performances. While not groundbreaking, it provided an enjoyable viewing experience.\",\n",
    "                    \"This city is a vibrant tapestry of culture, with friendly locals, historic landmarks, and a lively atmosphere. An ideal destination for cultural exploration.\",\n",
    "                    \"The city's charm is overshadowed by traffic congestion, high pollution levels, and a lack of cleanliness. Not recommended for a peaceful retreat.\",\n",
    "                    \"The city offers a mix of experiences, from bustling markets to serene parks. An interesting but not extraordinary destination for exploration.\",\n",
    "                    \"This song is a musical masterpiece, enchanting listeners with its soulful lyrics, mesmerizing melody, and exceptional vocals. A timeless classic.\",\n",
    "                    \"The song fails to impress, featuring uninspiring lyrics, a forgettable melody, and lackluster vocals. It lacks the creativity to leave a lasting impact.\",\n",
    "                    \"The song is decent, with a catchy tune and average lyrics. While enjoyable, it doesn't stand out in the vast landscape of music.\",\n",
    "                    \"A delightful cinematic experience that seamlessly weaves together a compelling narrative, strong character development, and breathtaking visuals.\",\n",
    "                    \"This film, unfortunately, falls short with a disjointed plot, subpar performances, and a lack of coherence. A disappointing viewing experience.\",\n",
    "                    \"While not groundbreaking, the movie offers a decent storyline and competent performances, providing an overall satisfactory viewing experience.\",\n",
    "                    \"This city is a haven for culture enthusiasts, boasting historical landmarks, a rich culinary scene, and a welcoming community. A must-visit destination.\",\n",
    "                    \"The city's appeal is tarnished by overcrowded streets, noise pollution, and a lack of urban planning. Not recommended for a tranquil getaway.\",\n",
    "                    \"The city offers a diverse range of experiences, from bustling markets to serene parks. An intriguing destination for those seeking a mix of urban and natural landscapes.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bae549c-fa32-46e8-af19-83f923222e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Sentiment: This movie is a true cinematic gem, blending an engaging plot with superb performances and stunning visuals. A masterpiece that leaves a lasting impression.\n",
      "\n",
      "Label    : positive\n",
      "\n",
      "Sentiment: Regrettably, the film failed to live up to expectations, with a convoluted storyline, lackluster acting, and uninspiring cinematography. A disappointment overall.\n",
      "\n",
      "Label    : negative\n",
      "\n",
      "Sentiment: The movie had its moments, offering a decent storyline and average performances. While not groundbreaking, it provided an enjoyable viewing experience.\n",
      "\n",
      "Label    : Positive\n",
      "\n",
      "Sentiment: This city is a vibrant tapestry of culture, with friendly locals, historic landmarks, and a lively atmosphere. An ideal destination for cultural exploration.\n",
      "\n",
      "Label    : positive\n",
      "\n",
      "Sentiment: The city's charm is overshadowed by traffic congestion, high pollution levels, and a lack of cleanliness. Not recommended for a peaceful retreat.\n",
      "\n",
      "Label    : negative\n",
      "\n",
      "Sentiment: The city offers a mix of experiences, from bustling markets to serene parks. An interesting but not extraordinary destination for exploration.\n",
      "\n",
      "Label    : Neutral\n",
      "\n",
      "Sentiment: This song is a musical masterpiece, enchanting listeners with its soulful lyrics, mesmerizing melody, and exceptional vocals. A timeless classic.\n",
      "\n",
      "Label    : positive\n",
      "\n",
      "Sentiment: The song fails to impress, featuring uninspiring lyrics, a forgettable melody, and lackluster vocals. It lacks the creativity to leave a lasting impact.\n",
      "\n",
      "Label    : negative\n",
      "\n",
      "Sentiment: The song is decent, with a catchy tune and average lyrics. While enjoyable, it doesn't stand out in the vast landscape of music.\n",
      "\n",
      "Label    : neutral\n",
      "\n",
      "Sentiment: A delightful cinematic experience that seamlessly weaves together a compelling narrative, strong character development, and breathtaking visuals.\n",
      "\n",
      "Label    : positive\n",
      "\n",
      "Sentiment: This film, unfortunately, falls short with a disjointed plot, subpar performances, and a lack of coherence. A disappointing viewing experience.\n",
      "\n",
      "Label    : negative\n",
      "\n",
      "Sentiment: While not groundbreaking, the movie offers a decent storyline and competent performances, providing an overall satisfactory viewing experience.\n",
      "\n",
      "Label    : positive\n",
      "\n",
      "Sentiment: This city is a haven for culture enthusiasts, boasting historical landmarks, a rich culinary scene, and a welcoming community. A must-visit destination.\n",
      "\n",
      "Label    : Positive\n",
      "\n",
      "Sentiment: The city's appeal is tarnished by overcrowded streets, noise pollution, and a lack of urban planning. Not recommended for a tranquil getaway.\n",
      "\n",
      "Label    : negative\n",
      "\n",
      "Sentiment: The city offers a diverse range of experiences, from bustling markets to serene parks. An intriguing destination for those seeking a mix of urban and natural landscapes.\n",
      "\n",
      "Label    : positive\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for user_sentiment in user_sentiments:\n",
    "    prompt = f\"\"\"What is the sentiment of the ```{user_sentiment}`` which is delimited with triple backticks?\n",
    "                  Classify the given text into single label as neutral, negative \n",
    "                  or positive. Do not expand on your response. Use a single word.\n",
    "                  If you cannot classify do not guess, just label as dont' know.\n",
    "                    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\nSentiment: {user_sentiment}\")\n",
    "    print(f\"\\nLabel    : {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f520fec-af04-4b97-8e66-3187e34b5566",
   "metadata": {},
   "source": [
    "## Text categorization\n",
    "Like sentiment analysis, given a query, an LLM can identify from its context how to classify and route customer queries to respective departments. Also, note that LLM can detect foul language and respond politely. Text categorization can be employed to automate customer on-line queries.\n",
    "\n",
    "Let's look at how we can achieve that with smart and deliberate prompting.\n",
    "\n",
    "<img src=\"./images/category_resp.png\" height=\"35%\" width=\"%65\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75b9307f-a2b3-4393-8e5a-5d7af520ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a smart and helful Assistant who can route customer queries to \n",
    "                    respective customer service departments.\n",
    "                    \"\"\"\n",
    "\n",
    "customer_queries = [\"\"\"My modem has stop working. I tried to restart but the orange light keep flashing. It never turns green.\"\"\",\n",
    "                    \"\"\"I just moved into town, and I need Internet service\"\"\",\n",
    "                    \"\"\"Why am I being charged extra $20 a month for cable TV when I don't use a television?\"\"\",\n",
    "                    \"\"\"I need to change my user name and password since someone is using my credentials\"\"\",\n",
    "                    \"\"\"What days this week are we having a general upgrades to the cable models?\"\"\",\n",
    "                    \"\"\"What day is the best day to call customer service so that I can avoid talking to a bloody bot!\"\"\",\n",
    "                    \"\"\"Your company is full of incompetent fools!\"\"\",\n",
    "                    \"\"\"I hate your worthless services. Cancel my stupid account or else I'll sue you!\"\"\"\n",
    "                   ]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36fe82a0-9486-4e8c-b573-3bb71d7a71b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Query: My modem has stop working. I tried to restart but the orange light keep flashing. It never turns green.\n",
      "Route to: Technical support\n",
      "\n",
      "\n",
      "Query: I just moved into town, and I need Internet service\n",
      "Route to: 4. New Customer\n",
      "\n",
      "\n",
      "Query: Why am I being charged extra $20 a month for cable TV when I don't use a television?\n",
      "Route to: Billing\n",
      "\n",
      "\n",
      "Query: I need to change my user name and password since someone is using my credentials\n",
      "Route to: Account Management\n",
      "\n",
      "\n",
      "Query: What days this week are we having a general upgrades to the cable models?\n",
      "Route to: Technical support\n",
      "\n",
      "\n",
      "Query: What day is the best day to call customer service so that I can avoid talking to a bloody bot!\n",
      "Route to: No need for foul language. Please be respectful.\n",
      "\n",
      "\n",
      "Query: Your company is full of incompetent fools!\n",
      "Route to: No need for foul language. Please be respectful.\n",
      "\n",
      "\n",
      "Query: I hate your worthless services. Cancel my stupid account or else I'll sue you!\n",
      "Route to: No need for foul language. Please be respectful.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for query in customer_queries:\n",
    "    prompt = f\"\"\" Classify each customer {query} into the following categories:\n",
    "                    1. Technical support\n",
    "                    2. Billing \n",
    "                    3. Account Management\n",
    "                    4. New Customer  \n",
    "                    5. General inquiry\n",
    "                  Do not expand your response. Only use the above categories. \n",
    "                  If you can't precisely categorize, then default to \"General inquiry.\"\n",
    "                  If customer {query} is abusive or in a foul language, then respond with \n",
    "                  \"No need for foul language. Please be respectful.\"\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(f\"Route to: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05333b92-c3fb-4341-b59d-82eeb7a65071",
   "metadata": {},
   "source": [
    "## Text transation and transformation\n",
    "\n",
    "Language translation by far is the most common use case for natural language processing. \n",
    "We have seen its early uses in Google translation, but with the emergence of multi-lingual LLMs, this task is simply achieved by exact prompting. \n",
    "\n",
    "In this section, we'll explore tasks in how to use LLMs for text translations, langugage identication, text transformation, spelling and grammar checking, tone adjustment, and format conversion.\n",
    "\n",
    "### Task 1:\n",
    " * Given an English text, translate into French, Spanish, and German.\n",
    " * Given a foreign language text, idenfify the language, and translate to English.\n",
    "\n",
    "\n",
    "👷‍♀️ under construction 🚧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e9dcecd-8c00-45d6-af45-af19ee7bffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content= \"\"\"You are a world reknowned supreme lingiust and a universal translator. You are a polglot, and fluently speak many global languages\"\"\"\n",
    "\n",
    "english_texts = [\"\"\" Welcome to New York for the United Nations General Council Meeting. Today\n",
    "is a special day for us to celeberate all our achievments since this global institute's formation.\n",
    "But more importantly, we want to address how we can mitigate global conflict with conversation\n",
    "and promote deterence, detente, and discussion.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad8986d5-3ade-4264-a29b-77dbf7b0ef8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "English Text:  Welcome to New York for the United Nations General Council Meeting. Today\n",
      "is a special day for us to celeberate all our achievments since this global institute's formation.\n",
      "But more importantly, we want to address how we can mitigate global conflict with conversation\n",
      "and promote deterence, detente, and discussion.\n",
      "Certainly! Here are the translations in the requested languages:\n",
      "\n",
      "**Language: Spanish**\n",
      "Bienvenidos a Nueva York para la Reunión del Consejo General de las Naciones Unidas. Hoy es un día especial para nosotros para celebrar todos nuestros logros desde la formación de este instituto global. Pero más importante aún, queremos abordar cómo podemos mitigar el conflicto global con conversación y promover la disuasión, la distensión y el diálogo.\n",
      "\n",
      "**Language: French**\n",
      "Bienvenue à New York pour la Réunion du Conseil Général des Nations Unies. Aujourd'hui est un jour spécial pour nous pour célébrer tous nos accomplissements depuis la formation de cette institution mondiale. Mais plus important encore, nous voulons aborder comment nous pouvons atténuer les conflits mondiaux avec la conversation et promouvoir la dissuasion, la détente et la discussion.\n",
      "\n",
      "**Language: German**\n",
      "Willkommen in New York zum Treffen des Generalrates der Vereinten Nationen. Heute ist ein besonderer Tag für uns, um all unsere Errungenschaften seit der Gründung dieses globalen Instituts zu feiern. Aber noch wichtiger ist, dass wir ansprechen wollen, wie wir globale Konflikte durch Gespräche mildern und Abschreckung, Entspannung und Diskussion fördern können.\n",
      "\n",
      "**Language: Mandarin**\n",
      "欢迎来到纽约参加联合国大会议。今天对我们来说是一个特别的日子，我们将庆祝自该全球机构成立以来的所有成就。但更重要的是，我们想要讨论我们如何能够通过对话减少全球冲突，并促进威慑、缓和和讨论。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for english_text in english_texts:\n",
    "    prompt = f\"\"\"\"Given an English text in triple ticks '''{english_text}'''. Translate into\n",
    "three languases: Spanish, French, German, and Mandarin. \n",
    "Label each translation with the langauge Name: followed by translation on a seperate line.\"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\nEnglish Text: {english_text}\")\n",
    "    print(f\"{response}\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dae09d-5198-42a6-896b-347f260fe3eb",
   "metadata": {},
   "source": [
    "Given a foreing language, identify the language and translate into English.\n",
    "\n",
    "This is the reverse of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a366e171-38b6-4d8d-928a-a36ec0137a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_texts = [\"\"\"Bienvenidos a Nueva York para la Reunión del Consejo General de las Naciones Unidas. Hoy\n",
    "es un día especial para celebrar todos nuestros logros desde la formación de este instituto global.\n",
    "Pero más importante aún, queremos abordar cómo podemos mitigar el conflicto global con conversaciones\n",
    "y promover la disuasión, la distensión y el diálogo.\"\"\",\n",
    "            \"\"\"Willkommen in New York zur Sitzung des Allgemeinen Rates der Vereinten Nationen. Heute\n",
    "ist ein besonderer Tag für uns, um all unsere Errungenschaften seit der Gründung dieses globalen Instituts zu feiern.\n",
    "Aber wichtiger ist, dass wir ansprechen möchten, wie wir globale Konflikte durch Gespräche mildern können\n",
    "und Abschreckung, Entspannung und Diskussion fördern.\"\"\",\n",
    "                  \"\"\"Bienvenue à New York pour la réunion du Conseil Général des Nations Unies. Aujourd'hui,\n",
    "c'est un jour spécial pour nous pour célébrer toutes nos réalisations depuis la formation de cette institution mondiale.\n",
    "Mais plus important encore, nous voulons aborder comment nous pouvons atténuer les conflits mondiaux grâce à la conversation\n",
    "et promouvoir la dissuasion, la détente et la discussion.\"\"\",\n",
    "                  \"\"\"欢迎来到纽约参加联合国大会议。今天对我们来说是一个特别的日子，我们将庆祝自该全球机构成立以来取得的所有成就。但更重要的是，我们想要讨论如何通过对话来缓解全球冲突，并促进遏制、缓和和讨论。\n",
    "\"\"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44a86628-4641-4283-8bba-9d2961451915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Language Text: Bienvenidos a Nueva York para la Reunión del Consejo General de las Naciones Unidas. Hoy\n",
      "es un día especial para celebrar todos nuestros logros desde la formación de este instituto global.\n",
      "Pero más importante aún, queremos abordar cómo podemos mitigar el conflicto global con conversaciones\n",
      "y promover la disuasión, la distensión y el diálogo.\n",
      "Language Name: Spanish\n",
      "\n",
      "English translation: Welcome to New York for the General Assembly of the United Nations. Today is a special day to celebrate all of our achievements since the formation of this global institute. But even more importantly, we want to discuss how we can mitigate global conflict with conversations and promote deterrence, de-escalation, and dialogue.\n",
      "\n",
      "\n",
      "Language Text: Willkommen in New York zur Sitzung des Allgemeinen Rates der Vereinten Nationen. Heute\n",
      "ist ein besonderer Tag für uns, um all unsere Errungenschaften seit der Gründung dieses globalen Instituts zu feiern.\n",
      "Aber wichtiger ist, dass wir ansprechen möchten, wie wir globale Konflikte durch Gespräche mildern können\n",
      "und Abschreckung, Entspannung und Diskussion fördern.\n",
      "Language Name: German\n",
      "\n",
      "English translation: Welcome to New York for the meeting of the General Assembly of the United Nations. Today is a special day for us to celebrate all of our achievements since the founding of this global institution. But more importantly, we would like to address how we can mitigate global conflicts through conversations and promote deterrence, relaxation, and discussion.\n",
      "\n",
      "\n",
      "Language Text: Bienvenue à New York pour la réunion du Conseil Général des Nations Unies. Aujourd'hui,\n",
      "c'est un jour spécial pour nous pour célébrer toutes nos réalisations depuis la formation de cette institution mondiale.\n",
      "Mais plus important encore, nous voulons aborder comment nous pouvons atténuer les conflits mondiaux grâce à la conversation\n",
      "et promouvoir la dissuasion, la détente et la discussion.\n",
      "Language Name: French\n",
      "\n",
      "English translation: Welcome to New York for the meeting of the General Council of the United Nations. Today is a special day for us to celebrate all our achievements since the formation of this global institution. But more importantly, we want to address how we can mitigate global conflicts through conversation and promote deterrence, relaxation, and discussion.\n",
      "\n",
      "\n",
      "Language Text: 欢迎来到纽约参加联合国大会议。今天对我们来说是一个特别的日子，我们将庆祝自该全球机构成立以来取得的所有成就。但更重要的是，我们想要讨论如何通过对话来缓解全球冲突，并促进遏制、缓和和讨论。\n",
      "\n",
      "Language Name: Chinese (Simplified)\n",
      "\n",
      "English translation: Welcome to New York to attend the United Nations General Assembly. Today is a special day for us as we will celebrate all the achievements made since the establishment of this global institution. More importantly, however, we want to discuss how to alleviate global conflicts through dialogue and promote containment, mitigation, and discussion.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for language_text in languages_texts:\n",
    "    prompt = f\"\"\"\"Given a language text in triple ticks '''{language_text}'''. Idenfity\n",
    "    the language with the langauge Name: followed by an English translation on a seperate line, labeled as English translation:\"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\nLanguage Text: {language_text}\")\n",
    "    print(f\"{response}\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8740e21-ea45-4b38-a0f7-753ef48a02aa",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    " * Given an English text, proof read it and correct any grammatical and usage errors.\n",
    " * Given a Pirate text, correct its tone to standard English.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a31e6bb8-83dd-4f0a-9036-a58e305e7d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a fastidious grammarian. You can proofread any English text and convert to \n",
    "its grammtical correct and usage form.\"\"\"\n",
    "\n",
    "bad_english_texts = [\"\"\"I don't know nothing about them big words and grammar rules. Me and my friend, we was talking, and he don't agree with me. We ain't never gonna figure it out, I reckon. His dog don't listen good, always running around and don't come when you call.\"\"\",\n",
    "                     \"\"\"Yesterday, we was at the park, and them kids was playing. She don't like the way how they acted, but I don't got no problem with it. We seen a movie last night, and it was good, but my sister, she don't seen it yet. Them books on the shelf, they ain't interesting to me.\"\"\"\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e4f0a39-e951-4e69-b547-cb969ea8250c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Original Text: I don't know nothing about them big words and grammar rules. Me and my friend, we was talking, and he don't agree with me. We ain't never gonna figure it out, I reckon. His dog don't listen good, always running around and don't come when you call.\n",
      "Corrected  Text: Certainly. Below is the corrected version of the provided text:\n",
      "\n",
      "\"I don't know anything about those big words and grammar rules. My friend and I were talking, and he doesn't agree with me. We are never going to figure it out, I reckon. His dog doesn't listen well, always running around and not coming when you call.\"\n",
      "\n",
      "\n",
      "Original Text: Yesterday, we was at the park, and them kids was playing. She don't like the way how they acted, but I don't got no problem with it. We seen a movie last night, and it was good, but my sister, she don't seen it yet. Them books on the shelf, they ain't interesting to me.\n",
      "Corrected  Text: \"Yesterday, we were at the park, and those kids were playing. She doesn't like the way they acted, but I have no problem with it. We saw a movie last night, and it was good, but my sister hasn't seen it yet. Those books on the shelf aren't interesting to me.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for bad_english_text in bad_english_texts:\n",
    "    prompt = f\"\"\"\"Proofread and correct the text provided in triple ticks '''{bad_english_text}'''.\n",
    "    Use standard usage and remedy any incorect grammar usage.\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\nOriginal Text: {bad_english_text}\")\n",
    "    print(f\"Corrected  Text: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01c28033-8175-427b-93d2-69db740060e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pirate_texts = [\"\"\"Arrr matey! I be knowin' nuthin' 'bout them fancy words and grammatical rules. Me and me heartie, we be chattin', and he don't be agreein' with me. We ain't never gonna figure it out, I reckon. His scallywag of a dog don't be listenin' well, always runnin' around and not comin' when ye call.\"\"\"\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f09b26f1-b370-4cd3-9079-b5b78df502d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Original Text: Arrr matey! I be knowin' nuthin' 'bout them fancy words and grammatical rules. Me and me heartie, we be chattin', and he don't be agreein' with me. We ain't never gonna figure it out, I reckon. His scallywag of a dog don't be listenin' well, always runnin' around and not comin' when ye call.\n",
      "\n",
      "Corrected  Text: \"Hello! I know nothing about those fancy words and grammatical rules. My friend and I have been chatting, and he doesn't agree with me. We are never going to figure it out, I reckon. His mischievous dog doesn't listen well, always running around and not coming when called.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for pirate_text in pirate_texts:\n",
    "    prompt = f\"\"\"\"Convert the Pirate text provided in triple ticks '''{pirate_text}'''.\n",
    "    Use standard usage and remedy any incorect grammar usage, dropping all Pirate greetings.\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\nOriginal Text: {pirate_text}\")\n",
    "    print(f\"\\nCorrected  Text: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e48460-00a6-4a7f-9e54-b1e25e00860d",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "* Given some text in a particular format, convert it into JSON format.\n",
    "* For example, we LLM to producce names of three top shoes, but we want them it product and its items in JSON format. This JSON format can be fed downstream into another application that may process it.\n",
    "\n",
    "Let's have go at it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab5b7a40-5d26-4bb0-816e-08f04462d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You have knowledge of all sporting goods and will provide knowledge answers\n",
    "to queries about sporting goods.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f77a87f-cf8a-486a-8c43-38a9e5f0c708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"Brand\": \"Nike\",\n",
      "        \"Description\": \"Nike Air Zoom Pegasus 38\",\n",
      "        \"Size\": \"10\",\n",
      "        \"Gender\": \"Male\",\n",
      "        \"Price\": \"$120.00\",\n",
      "        \"Review\": [\n",
      "            {\n",
      "                \"Customer\": \"John Doe\",\n",
      "                \"Comment\": \"Very comfortable for long runs, great cushioning.\",\n",
      "                \"Rating\": 5\n",
      "            },\n",
      "            {\n",
      "                \"Customer\": \"Jane Smith\",\n",
      "                \"Comment\": \"Love the breathability and the fit. Stylish too!\",\n",
      "                \"Rating\": 4\n",
      "            },\n",
      "            {\n",
      "                \"Customer\": \"Mark Taylor\",\n",
      "                \"Comment\": \"Good support but a bit narrow for wide feet.\",\n",
      "                \"Rating\": 4\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"Brand\": \"Adidas\",\n",
      "        \"Description\": \"Adidas Ultraboost 21\",\n",
      "        \"Size\": \"8\",\n",
      "        \"Gender\": \"Female\",\n",
      "        \"Price\": \"$180.00\",\n",
      "        \"Review\": [\n",
      "            {\n",
      "                \"Customer\": \"Emily Jones\",\n",
      "                \"Comment\": \"The bounce in these shoes is incredible, like walking on clouds.\",\n",
      "                \"Rating\": 5\n",
      "            },\n",
      "            {\n",
      "                \"Customer\": \"Sarah Wilson\",\n",
      "                \"Comment\": \"Took them for a marathon and had no blisters or discomfort.\",\n",
      "                \"Rating\": 5\n",
      "            },\n",
      "            {\n",
      "                \"Customer\": \"Lucy Brown\",\n",
      "                \"Comment\": \"A bit expensive but worth it for the quality and comfort.\",\n",
      "                \"Rating\": 4\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"Brand\": \"Asics\",\n",
      "        \"Description\": \"Asics Gel-Kayano 27\",\n",
      "        \"Size\": \"9.5\",\n",
      "        \"Gender\": \"Unisex\",\n",
      "        \"Price\": \"$160.00\",\n",
      "        \"Review\": [\n",
      "            {\n",
      "                \"Customer\": \"Tom Clarkson\",\n",
      "                \"Comment\": \"The support for overpronation is top-notch.\",\n",
      "                \"Rating\": 5\n",
      "            },\n",
      "            {\n",
      "                \"Customer\": \"Alex Green\",\n",
      "                \"Comment\": \"They feel a bit heavy but stabilize my run perfectly.\",\n",
      "                \"Rating\": 4\n",
      "            },\n",
      "            {\n",
      "                \"Customer\": \"Samantha Reed\",\n",
      "                \"Comment\": \"Not the most stylish, but my feet thank me after every workout.\",\n",
      "                \"Rating\": 4\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"Brand\": \"New Balance\",\n",
      "        \"Description\": \"New Balance Fresh Foam 1080v11\",\n",
      "        \"Size\": \"11\",\n",
      "        \"Gender\": \"Male\",\n",
      "        \"Price\": \"$150.00\",\n",
      "        \"Review\": [\n",
      "            {\n",
      "                \"Customer\": \"Derek Holt\",\n",
      "                \"Comment\": \"These are my go-to for long distance. New Balance never disappoints.\",\n",
      "                \"Rating\": 5\n",
      "            },\n",
      "            {\n",
      "                \"Customer\": \"Angela Ray\",\n",
      "                \"Comment\": \"The fit is perfect and they're surprisingly light.\",\n",
      "                \"Rating\": 5\n",
      "            },\n",
      "            {\n",
      "                \"Customer\": \"Steve Fisher\",\n",
      "                \"Comment\": \"They run a little small, had to exchange for a half size up.\",\n",
      "                \"Rating\": 3\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"Brand\": \"Brooks\",\n",
      "        \"Description\": \"Brooks Ghost 13\",\n",
      "        \"Size\": \"7\",\n",
      "        \"Gender\": \"Female\",\n",
      "        \"Price\": \"$130.00\",\n",
      "        \"Review\": [\n",
      "            {\n",
      "                \"Customer\": \"Rachel Evans\",\n",
      "                \"Comment\": \"I have flat feet and these shoes have been a lifesaver for my daily jogs.\",\n",
      "                \"Rating\": 5\n",
      "            },\n",
      "            {\n",
      "                \"Customer\": \"Olivia Stone\",\n",
      "                \"Comment\": \"The cushioning is great and they're durable. On my second pair now.\",\n",
      "                \"Rating\": 5\n",
      "            },\n",
      "            {\n",
      "                \"Customer\": \"Daniel Wright\",\n",
      "                \"Comment\": \"The toe box is roomy, which I appreciate. Solid pair of trainers.\",\n",
      "                \"Rating\": 4\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "prompt = f\"\"\"Generate five distinct products on training shoes. Generate products as a \n",
    "            JSON object. It should contain items: Brand, Description, Size, Gender: Male \n",
    "            or Female or Unisex, Price, and at least three customer reviews as Review \n",
    "            item\"\"\"\n",
    "response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6496b00-0a1d-4a57-9783-11f2dcf09c5a",
   "metadata": {},
   "source": [
    "## Simple and complex reasoning \n",
    "\n",
    "An import characteristic of LLM is that it's not only general respository of compressed\n",
    "knowledge garned from large corpus of text, but can be employed as a simple and complex reasoning engine. With use of precise prompt, you can instruct LLM to think trough a problem in a step by step fashion.\n",
    "\n",
    "Let's look at some tasks as examples.\n",
    " * given a list of numbers identify the prime numbers, add the prime numbers and check if the sum is even or odd.\n",
    " * given an hourly rate of wages, compute your yearly income if you work 30 hours a week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47be9101-2af8-4074-a970-b6cdadc692d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a reasoning engine. Given a problem think through the problem logically\n",
    "in a step by step manner.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c0b6b93-5218-4239-9db4-674e6b8dbd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prime_number_prompt = f\"\"\"given a list of numbers 1,2,3,4,5,7,8, 11,13,17,19,23,24,29 identify the prime numbers, add the prime numbers, \n",
    "and check if the sum is even or odd. Explain each step how you solved the problem\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f0bd7a7-9c8b-4c97-85b3-8f83a0ca61b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_wages_prompt = f\"\"\"If my hourly rate is $117.79 per hour, and I work at most 30 hours a week, what\n",
    "is my yearly income? Break the problem into simple steps and explain in each step how you arrive \n",
    "to the answer. If you don't know, simple say I don't know. Do not make up answers\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4ecb495-ee6f-4033-8fa7-7c364d79ffbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve this problem, we can follow these steps:\n",
      "\n",
      "1. Identify the prime numbers in the list.\n",
      "2. Add the identified prime numbers together.\n",
      "3. Check if the sum is even or odd.\n",
      "\n",
      "Step 1: Identify the prime numbers in the list\n",
      "A prime number is a number greater than 1 that has no positive divisors other than 1 and itself. Let's go through the list and identify which numbers are prime:\n",
      "\n",
      "- 1 (not a prime number because the definition requires a prime number to have only two distinct positive divisors: 1 and the number itself)\n",
      "- 2 (prime number, the only even prime number)\n",
      "- 3 (prime number)\n",
      "- 4 (not a prime number, it's divisible by 2)\n",
      "- 5 (prime number)\n",
      "- 7 (prime number)\n",
      "- 8 (not a prime number, it's divisible by 2)\n",
      "- 11 (prime number)\n",
      "- 13 (prime number)\n",
      "- 17 (prime number)\n",
      "- 19 (prime number)\n",
      "- 23 (prime number)\n",
      "- 24 (not a prime number, it's divisible by 2)\n",
      "- 29 (prime number)\n",
      "\n",
      "From the list, the prime numbers are: 2, 3, 5, 7, 11, 13, 17, 19, 23, and 29.\n",
      "\n",
      "Step 2: Add the identified prime numbers together\n",
      "Now, let's add these prime numbers:\n",
      "\n",
      "2 + 3 + 5 + 7 + 11 + 13 + 17 + 19 + 23 + 29 = 129\n",
      "\n",
      "Step 3: Check if the sum is even or odd\n",
      "Finally, we'll determine if the sum (129) is even or odd. An even number is divisible by 2, meaning it has no remainder when divided by 2. An odd number will have a remainder of 1 when divided by 2.\n",
      "\n",
      "129 divided by 2 is 64 with a remainder of 1, which means 129 is an odd number.\n",
      "\n",
      "Therefore, the sum of the prime numbers in the given list is 129, which is an odd number.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, prime_number_prompt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5651b79b-997e-4524-b17b-14f413e850a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate the yearly income based on an hourly rate and a maximum number of hours worked per week, you can follow these steps:\n",
      "\n",
      "Step 1: Find weekly income.\n",
      "First, calculate how much you would earn in a week by multiplying your hourly rate by the number of hours you work per week.\n",
      "\n",
      "Hourly rate x Hours per week = Weekly income\n",
      "$117.79 x 30 hours = $3,533.70 per week\n",
      "\n",
      "Step 2: Find yearly income (assuming you work every week of the year).\n",
      "Then, multiply your weekly income by the number of weeks in a year to get your yearly income.\n",
      "\n",
      "Weekly income x Weeks per year = Yearly income\n",
      "$3,533.70 per week x 52 weeks = $183,752.40 per year\n",
      "\n",
      "Therefore, if you work 30 hours every week at an hourly rate of $117.79, and you do this without taking any weeks off, your yearly income would be $183,752.40.\n",
      "However, this calculation assumes that you work every week of the year and do not take any time off for holidays, vacation, or any other reason. If you do take time off, the actual yearly income would be lower.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, hourly_wages_prompt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a5da1-986a-4682-a672-8c213eb40be5",
   "metadata": {},
   "source": [
    "## Code generation\n",
    "\n",
    "Language models like ChatGPT and Llama 2 are really good at generating code. Copilot on GitHub is a cool example of this. You can do lots of different code tasks just by asking in a smart way. Let's check out a few examples to see how it's helpful.\n",
    "\n",
    "#### Task 1\n",
    " * Generate Python code to compute the value of PI using Ray distributed framework\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de3ad4ed-e28e-44a7-8a33-11136f6334d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a supreme CoPilot for developer. Given a task you can\n",
    "generate code for that task.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9a85173-dbce-4bf6-b004-7e368a5ccd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_code_prompt=\"\"\"Generate Python code to compute the value of PI using Ray \n",
    "distributed framework API. Use the Monte Carlo method to compute the value of PI.\n",
    "Include in-line comments explaining the code\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60e2b04a-9f0c-450f-aeda-8e6ece5b0a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To compute the value of PI using the Monte Carlo method in a distributed manner using Ray, you need to follow these steps:\n",
      "\n",
      "1. Install Ray if not already installed (`pip install ray`).\n",
      "2. Import necessary modules.\n",
      "3. Initialize Ray.\n",
      "4. Define a remote function that simulates random points and checks if they fall inside a unit circle.\n",
      "5. Invoke this remote function in parallel.\n",
      "6. Collect and reduce the results to estimate PI.\n",
      "\n",
      "Below is the Python code to perform these steps:\n",
      "\n",
      "```python\n",
      "# Import necessary modules\n",
      "import ray\n",
      "import random\n",
      "\n",
      "# Initialize Ray\n",
      "ray.init()\n",
      "\n",
      "# Define a remote function using the @ray.remote decorator\n",
      "# This function simulates 'num_samples' random points and returns how many fall inside the unit circle\n",
      "@ray.remote\n",
      "def simulate_pi(num_samples):\n",
      "    count_inside = 0\n",
      "    for _ in range(num_samples):\n",
      "        # Generate random x, y ∈ [0, 1)\n",
      "        x = random.random()\n",
      "        y = random.random()\n",
      "        # Check if the point is inside the unit circle\n",
      "        if x**2 + y**2 <= 1:\n",
      "            count_inside += 1\n",
      "    # Return the count of points inside the circle\n",
      "    return count_inside\n",
      "\n",
      "# The total number of random points we want to simulate\n",
      "total_samples = 1000000\n",
      "# The number of parallel tasks to run\n",
      "num_parallel_tasks = 10\n",
      "\n",
      "# Split the work among the available tasks\n",
      "samples_per_task = total_samples // num_parallel_tasks\n",
      "futures = [simulate_pi.remote(samples_per_task) for _ in range(num_parallel_tasks)]\n",
      "\n",
      "# Wait for all tasks to complete and retrieve the results\n",
      "results = ray.get(futures)\n",
      "\n",
      "# Calculate the total number of points that fall inside the circle\n",
      "total_inside = sum(results)\n",
      "\n",
      "# Estimate the value of PI\n",
      "# The area of the unit circle is π, and the area of the square is 4\n",
      "# Therefore, PI is approximately 4 times the ratio of points inside the circle to the total number of points\n",
      "pi_estimate = (4.0 * total_inside) / total_samples\n",
      "\n",
      "# Print the estimated value of PI\n",
      "print(f\"Estimated value of PI: {pi_estimate}\")\n",
      "\n",
      "# Shutdown Ray\n",
      "ray.shutdown()\n",
      "```\n",
      "\n",
      "Before running this code, make sure Ray is properly installed, and the Ray cluster is correctly set up if you're using a cluster. The `simulate_pi` function can be scaled out to as many workers as available in the Ray cluster to parallelize the computation of PI. Adjust `total_samples` and `num_parallel_tasks` according to your computational resources and desired accuracy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, python_code_prompt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7fdc8-7a19-4a1a-b119-7a0bf0b3ae0f",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    " * Given SQL schema tables, generate an SQL query \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "585f372c-fe37-43b4-9299-c5708d1be06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_code_prompt=\"\"\"Given the following SQL schema for tables\n",
    "Table clicks, columns = [target_url, orig_url, user_id, clicks]\n",
    "Table users, columns = [user_id, f_name, l_name, e_mail, company, title], generate\n",
    "an SQL query that computes in the descening order of all the clicks. Also, for\n",
    "each user_id, list the f_name, l_name, company, and title\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "351b78d7-c78b-4a1b-946b-8a2abd17efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To generate the SQL query, we need to join the `clicks` table with the `users` table on `user_id` to associate each click with the respective user's information. Then we will group the results by `user_id` (and the corresponding user information fields) to aggregate the total number of clicks per user. Finally, we will order the result in descending order of the total number of clicks for each user.\n",
      "\n",
      "Here's the SQL query to achieve this:\n",
      "\n",
      "```sql\n",
      "SELECT \n",
      "    u.user_id,\n",
      "    u.f_name,\n",
      "    u.l_name,\n",
      "    u.company,\n",
      "    u.title,\n",
      "    SUM(c.clicks) AS total_clicks\n",
      "FROM \n",
      "    users AS u\n",
      "JOIN \n",
      "    clicks AS c\n",
      "ON \n",
      "    u.user_id = c.user_id\n",
      "GROUP BY \n",
      "    u.user_id, u.f_name, u.l_name, u.company, u.title\n",
      "ORDER BY \n",
      "    total_clicks DESC;\n",
      "```\n",
      "\n",
      "This query will return a list of users along with their first name, last name, company, title, and the sum of clicks made by each user, ordered from the highest number of clicks to the lowest.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, sql_code_prompt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d546337d-b9a4-40db-92dd-8cdce63c6979",
   "metadata": {},
   "source": [
    "## All this is amazing! 😜 Feel the wizardy prompt power 🧙‍♀️"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
