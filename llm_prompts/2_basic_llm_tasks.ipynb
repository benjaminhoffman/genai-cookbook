{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39330ca8-0778-405c-8d1f-2c31e190ebde",
   "metadata": {},
   "source": [
    "## Basic LLM Tasks\n",
    "In the *1_basic_prompt* notebook, we explored using prompts to query an LLM model. This notebook presents diverse examples to demonstrate various tasks and introduce key concepts, emphasizing effective learning through practical instances. The tasks explored in this notebook, using sophiscated prompting techniques, show *how-to* code examples for:\n",
    "\n",
    " * Text generation or completion\n",
    " * Text summarization\n",
    " * Text extraction\n",
    " * Text classification or sentiment analysis\n",
    " * Text categorization\n",
    " * Text transformation and translation\n",
    " * Simple and complex reasoning\n",
    " *  Code generation\n",
    "\n",
    "<img src=\"./images/prompt_req_resp.png\" height=\"35%\" width=\"%65\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "798bde8f-44a7-4e9f-ba30-0ffccd1d4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249c0446-7d74-402b-b7a5-9ab6f1d59224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "warnings.filterwarnings('ignore')\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45071b3-6e6e-497b-9126-ab592053d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8654cd8-fa3d-4d94-a7c9-37053a3434be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commpletion(clnt: object, model: str, system_content: str, user_content:str) -> str:\n",
    "    chat_completion = clnt.chat.completions.create(\n",
    "        model=model,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_content},\n",
    "              {\"role\": \"user\", \"content\": user_content}],\n",
    "    temperature = 0.8)\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f06061-ea86-4e09-b006-9a0c61f92e33",
   "metadata": {},
   "source": [
    "## Text generation or completion\n",
    "In this simple task, we use an LLM to generate text by finishing an incomplete user content provided in the prompt. For example,\n",
    "by providing an incomplete prompt such as \"On a cold winter night, the stray dog ...\". \n",
    "\n",
    "Let's try a few text generation or completion tasks by providing partial prompts in the user content. You will surprised at its\n",
    "fluency and coherency in the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07fbcbf8-0ccc-4fd4-a27d-a27c1ad14ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are master of all knowledge, and a helpful sage.\n",
    "                    You must complete any incomplete sentence by drawing from your vast\n",
    "                    knowledge about history, literature, science, social science, philosophy, religion, economics, sports, etc.\n",
    "                  \"\"\"\n",
    "\n",
    "user_prompts =  [\"On cold winter nights, the wolves in Siberia ...\",\n",
    "                 \"On the day Franklin Benjamin realized his passion for printer, ...\",\n",
    "                 \"During the final World Cup 1998 when France beat Brazil in Paris, ...\",\n",
    "                 \"Issac Newton set under a tree when an apple fell...\"\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c39358d-f343-4596-bd28-5f36a3ba85d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Prompt: On cold winter nights, the wolves in Siberia ...\n",
      "\n",
      "Answer: On cold winter nights, the wolves in Siberia howl hauntingly across the frozen landscape. Their thick fur shields them from the icy chill as they prowl for food, their breaths misting in the frigid air. Lone wolves often join packs for better hunting prospects and protection against the elements. Amidst the darkness, their piercing eyes glint with a primal understanding of the harsh world they inhabit. These majestic creatures embody the wild spirit of Siberia's vast wilderness, surviving and thriving in one of the earth's most extreme environments.\n",
      "\n",
      "Prompt: On the day Franklin Benjamin realized his passion for printer, ...\n",
      "\n",
      "Answer: On the day Franklin Benjamin realized his passion for printing, a world of words and influence unfolded before him. He apprenticed under his brother, James, absorbing the art of typesetting and the power of the press. His curiosity and drive led him to establish his own printing business, which became the foundation for his future success. As a printer, he published the Pennsylvania Gazette and Poor Richard's Almanack, works that would cement his reputation as a major figure in colonial American culture. Through his endeavors, Franklin not only honed his craft but also shaped the discourse of a burgeoning nation.\n",
      "\n",
      "Prompt: During the final World Cup 1998 when France beat Brazil in Paris, ...\n",
      "\n",
      "Answer: \n",
      "During the final World Cup 1998 when France beat Brazil in Paris, the host nation triumphed with a notable 3-0 scoreline. Zinedine Zidane became the hero of the match, scoring two decisive goals with his head. The victory sparked jubilant celebrations across the country as France claimed their first World Cup title. The match was played at the Stade de France with an electric atmosphere that embodied the nation's passion for football. Despite being favorites, Brazil's performance was lackluster, and the loss was a bitter pill for the reigning champions to swallow.\n",
      "\n",
      "\n",
      "Prompt: Issac Newton set under a tree when an apple fell...\n",
      "\n",
      "Answer: \n",
      "Isaac Newton sat under a tree when an apple fell. This event prompted a profound contemplation on the nature of gravity. He formulated the law of universal gravitation, which posits that every mass exerts an attractive force on every other mass. This groundbreaking idea not only explained the apple's fall but also the motion of celestial bodies. Consequently, Newton's insights laid the foundation for classical mechanics.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for user_prompt in user_prompts:\n",
    "    prompt = f\"\"\" Compete the text ```{user_prompt}``` between three backticks.\n",
    "    You will use simple, compound, and compound-complex sentences for all your responses, \n",
    "    and no more than one paragraph and no more than five sentences. \n",
    "    Keep your sentences succinct and cohesive.\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    response = response.replace(\"```\", \"\")\n",
    "    print(f\"\\nPrompt: {user_prompt}\")\n",
    "    print(f\"\\nAnswer: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e03d54-6200-4664-9a6d-13fe8297e0cb",
   "metadata": {},
   "source": [
    "## Text summarization\n",
    "\n",
    "A common task in natural langauge processing is text summiarization. A common use case\n",
    "is summarizing large articles or documents, for a quick and easy-to-absorb summaries.\n",
    "\n",
    "You can instruct LLM to generate the response in a preferable style, and comprehensibility. For example, use simple language aimed for a certain grade level, keep the orginal style of the article, use different sentence sytles (as we have done in few of examples in this notebook and previous one).\n",
    "\n",
    "Let's try a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85736577-b4ee-466e-90c8-a810849fe172",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are master of all knowledge about history, literature, science, philosophy, religion, economics, sports, etc.\"\"\" \n",
    "                \n",
    "user_prompts = [\n",
    "    \"\"\" The emergence of large language models (LLMs) has marked a significant \n",
    "         breakthrough in natural language processing (NLP), leading to remarkable \n",
    "         advancements in text understanding and generation. \n",
    "         \n",
    "         Nevertheless, alongside these strides, LLMs exhibit a critical tendency \n",
    "         to produce hallucinations, resulting in content that is inconsistent with \n",
    "         real-world facts or user inputs. This phenomenon poses substantial challenges \n",
    "         to their practical deployment and raises concerns over the reliability of LLMs \n",
    "         in real-world scenarios, which attracts increasing attention to detect and \n",
    "         mitigate these hallucinations. In this survey, we aim to provide a thorough and \n",
    "         in-depth  overview of recent advances in the field of LLM hallucinations. \n",
    "         \n",
    "         We begin with an innovative taxonomy of LLM hallucinations, then delve into the \n",
    "         factors contributing to hallucinations. Subsequently, we present a comprehensive\n",
    "         overview of hallucination detection methods and benchmarks. \n",
    "         Additionally, representative approaches designed to mitigate hallucinations \n",
    "         are introduced accordingly. \n",
    "         \n",
    "         Finally, we analyze the challenges that highlight the current limitations and \n",
    "         formulate open questions, aiming to delineate pathways for future  research on \n",
    "         hallucinations in LLMs.\"\"\",\n",
    "    \"\"\"  Can a Large Language Model (LLM) solve simple abstract reasoning problems?\n",
    "         We explore this broad question through a systematic analysis of GPT on the \n",
    "         Abstraction and Reasoning Corpus (ARC), a representative benchmark of abstract \n",
    "         reasoning ability from limited examples in which solutions require some \n",
    "         \"core knowledge\" of concepts such as objects, goal states, counting, and \n",
    "         basic geometry. GPT-4 solves only 13/50 of the most straightforward ARC \n",
    "         tasks when using textual encodings for their two-dimensional input-output grids. \n",
    "         Our failure analysis reveals that GPT-4's capacity to identify objects and \n",
    "         reason about them is significantly influenced by the sequential nature of \n",
    "         the text that represents an object within a text encoding of a task. \n",
    "         To test this hypothesis, we design a new benchmark, the 1D-ARC, which \n",
    "         consists of one-dimensional (array-like) tasks that are more conducive \n",
    "         to GPT-based reasoning, and where it indeed performs better than on \n",
    "         the (2D) ARC. To alleviate this issue, we propose an object-based \n",
    "         representation that is obtained through an external tool, resulting in \n",
    "         nearly doubling the performance on solved ARC tasks and near-perfect scores \n",
    "         on the easier 1D-ARC. Although the state-of-the-art GPT-4 is unable to \n",
    "         \"reason\" perfectly within non-language domains such as the 1D-ARC or a \n",
    "         simple ARC subset, our study reveals that the use of object-based representations \n",
    "         can significantly improve its reasoning ability. Visualizations, GPT logs, and \n",
    "         data are available at this https URL.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a884cb94-0c4a-40bc-a847-1d5eb354cafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Original content:  The emergence of large language models (LLMs) has marked a significant \n",
      "         breakthrough in natural language processing (NLP), leading to remarkable \n",
      "         advancements in text understanding and generation. \n",
      "         \n",
      "         Nevertheless, alongside these strides, LLMs exhibit a critical tendency \n",
      "         to produce hallucinations, resulting in content that is inconsistent with \n",
      "         real-world facts or user inputs. This phenomenon poses substantial challenges \n",
      "         to their practical deployment and raises concerns over the reliability of LLMs \n",
      "         in real-world scenarios, which attracts increasing attention to detect and \n",
      "         mitigate these hallucinations. In this survey, we aim to provide a thorough and \n",
      "         in-depth  overview of recent advances in the field of LLM hallucinations. \n",
      "         \n",
      "         We begin with an innovative taxonomy of LLM hallucinations, then delve into the \n",
      "         factors contributing to hallucinations. Subsequently, we present a comprehensive\n",
      "         overview of hallucination detection methods and benchmarks. \n",
      "         Additionally, representative approaches designed to mitigate hallucinations \n",
      "         are introduced accordingly. \n",
      "         \n",
      "         Finally, we analyze the challenges that highlight the current limitations and \n",
      "         formulate open questions, aiming to delineate pathways for future  research on \n",
      "         hallucinations in LLMs.\n",
      "\n",
      "Summary  content: The survey discusses the significant progress in NLP achieved through large language models, yet highlights the critical issue of these models generating \"hallucinations\" or false information. It proposes a classification system for these errors, examines their causes, and evaluates both detection strategies and potential solutions. The paper also addresses the current limitations of LLMs by identifying challenges and suggesting directions for future research to improve their reliability. This comprehensive overview underscores the importance of addressing hallucinations for the practical application of LLMs.\n",
      "\n",
      "Original content:   Can a Large Language Model (LLM) solve simple abstract reasoning problems?\n",
      "         We explore this broad question through a systematic analysis of GPT on the \n",
      "         Abstraction and Reasoning Corpus (ARC), a representative benchmark of abstract \n",
      "         reasoning ability from limited examples in which solutions require some \n",
      "         \"core knowledge\" of concepts such as objects, goal states, counting, and \n",
      "         basic geometry. GPT-4 solves only 13/50 of the most straightforward ARC \n",
      "         tasks when using textual encodings for their two-dimensional input-output grids. \n",
      "         Our failure analysis reveals that GPT-4's capacity to identify objects and \n",
      "         reason about them is significantly influenced by the sequential nature of \n",
      "         the text that represents an object within a text encoding of a task. \n",
      "         To test this hypothesis, we design a new benchmark, the 1D-ARC, which \n",
      "         consists of one-dimensional (array-like) tasks that are more conducive \n",
      "         to GPT-based reasoning, and where it indeed performs better than on \n",
      "         the (2D) ARC. To alleviate this issue, we propose an object-based \n",
      "         representation that is obtained through an external tool, resulting in \n",
      "         nearly doubling the performance on solved ARC tasks and near-perfect scores \n",
      "         on the easier 1D-ARC. Although the state-of-the-art GPT-4 is unable to \n",
      "         \"reason\" perfectly within non-language domains such as the 1D-ARC or a \n",
      "         simple ARC subset, our study reveals that the use of object-based representations \n",
      "         can significantly improve its reasoning ability. Visualizations, GPT logs, and \n",
      "         data are available at this https URL.\n",
      "\n",
      "Summary  content: The study investigates whether GPT-4, a Large Language Model, can tackle simple abstract reasoning tasks, focusing on the Abstraction and Reasoning Corpus (ARC). GPT-4's performance on ARC is modest, successfully resolving 13 out of 50 basic tasks, with its object identification and reasoning capabilities being hindered by the text-based representation of the tasks. To address this limitation, researchers introduced a one-dimensional version of ARC (1D-ARC), where GPT-4 showed improved results. Through the use of an externally-derived object-based representation, GPT-4's performance on ARC tasks nearly doubled, and it achieved high accuracy on the simpler 1D-ARC. Despite these enhancements, GPT-4 still struggles with perfect reasoning in non-language tasks, though object-based representations have been shown to significantly boost its abilities.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for user_prompt in user_prompts:\n",
    "    prompt = f\"\"\"Summarize the text delimited by triple backticks \n",
    "              ```{user_prompt}``` Use simple, compound, and compound-complex sentences, with \n",
    "              no more than one paragraph and no more than five sentences. \n",
    "              Keep summary succinct and cohesive, and maintain the original content's tone. \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\nOriginal content: {user_prompt}\")\n",
    "    print(f\"\\nSummary  content: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affe9c30-bf89-49ee-80c8-c5d260b91914",
   "metadata": {},
   "source": [
    "## Text or information extraction\n",
    "\n",
    "Another natural langauge capability, similar to summarization or text completion, is extracting key idea or infromation from an article, blog, or a paragraph. For example,\n",
    "given a set of text, you can ask LLM to extract key ideas or topics or subjects. Or even\n",
    "better enumerate key takeways for you, saving time if you are in a hurry.\n",
    "\n",
    "Let's see *how-to* do it by first looking at a simple example, and then progressing into a more complex one.\n",
    "\n",
    "### Task 1: \n",
    " * summarize the product review\n",
    " * extract any information about shipping and packaging for shipping department\n",
    " * classify the sentiment of the review: positive or negative.\n",
    " * use precise, specific prompt to acheive the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21406dcc-e9b1-4028-8281-297ae762b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"You are master of all knowledge about history, literature, science, social science, philosophy, religion, economics, sports, etc.\"\n",
    "product_review = \"\"\"I got this Australian Bush Baby with soft fur for my niece's birthday, and she absolutely loves it, carrying it around everywhere. The fur is exceptionally soft, and its adorable face gives off a friendly vibe. While I find it a bit smaller than anticipated for the price, my niece's joy makes it worthwhile. What pleasantly surprised me was the early arrival; it came a day earlier than expected. I appreciated the prompt delivery, and the packaging was secure, ensuring the Bush Baby with soft fur arrived in perfect condition. This allowed me to play with it myself before presenting it to my niece.\"\"\"     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "384515f8-a970-421a-86bb-be3ea8800bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \n",
    "review from an Australian e-commerce site to offer feedback to the \n",
    "shipping deparmtment. \n",
    "\n",
    "First, provide a short summary the review below, delimited by triple \n",
    "backticks, in two sentences: a simple and compound sentence. Second focus \n",
    "on any aspects packaging or shipping of the product, and label it as \n",
    "\"Shipping Department:\".  Third, indicate if the review is positive or negative, \n",
    "and label it as \"Sentiment:\"\n",
    "Review: ```{product_review}``` \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0056f55-c3aa-4a4e-bd11-fec330436af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Summary: \n",
      "The reviewer purchased an Australian Bush Baby plush for their niece's birthday, who adores the toy despite its smaller-than-expected size. They were delighted with the early arrival and the secure packaging that ensured the toy's perfect condition.\n",
      "\n",
      "Shipping Department: The product arrived a day earlier than expected, and the secure packaging was praised for keeping the Australian Bush Baby plush in perfect condition.\n",
      "\n",
      "Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "print(f\"\"\"\\nSummary: {response.replace(\"```\", \"\")}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb0d62-e2a7-4669-9792-57f20ed95980",
   "metadata": {},
   "source": [
    "### Task 2\n",
    " * Given a passage from an article, extract the main theme of the passage and label it as the `Subjects`, if more than one, separated by comma.\n",
    " * Identify three key takeways and enumerate them in simple sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cdcd4d4-62c7-4dea-b98a-58070552c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"You are master of all knowledge about history, literature, science, social science, philosophy, religion, economics, sports, etc.\"\n",
    "            \n",
    "user_prompts = [\"Isaac Newton sat under a tree when an apple fell, an event that, \\\n",
    "                according to popular legend, led to his contemplation of the forces\\\n",
    "                of gravity. Although this story is often regarded as apocryphal or at \\\n",
    "                least exaggerated, it serves as a powerful symbol of Newton's insight \\\n",
    "                into the universal law that governs celestial and earthly bodies alike. \\\n",
    "                His formulation of the law of universal gravitation was revolutionary, \\\n",
    "                as it provided a mathematical explanation for both the motion of planets \\\n",
    "                and the phenomena observed on Earth. Newton's work in physics, captured \\\n",
    "                in his seminal work Philosophiæ Naturalis Principia Mathematica, laid the \\\n",
    "                groundwork for classical mechanics. His influence extended beyond his own \\\n",
    "                time, shaping the course of scientific inquiry for centuries to come.\"\n",
    "               ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7e16e2f-14ec-4bfd-9687-294683ad5c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Original content: Isaac Newton sat under a tree when an apple fell, an event that,                 according to popular legend, led to his contemplation of the forces                of gravity. Although this story is often regarded as apocryphal or at                 least exaggerated, it serves as a powerful symbol of Newton's insight                 into the universal law that governs celestial and earthly bodies alike.                 His formulation of the law of universal gravitation was revolutionary,                 as it provided a mathematical explanation for both the motion of planets                 and the phenomena observed on Earth. Newton's work in physics, captured                 in his seminal work Philosophiæ Naturalis Principia Mathematica, laid the                 groundwork for classical mechanics. His influence extended beyond his own                 time, shaping the course of scientific inquiry for centuries to come.\n",
      "\n",
      " Subject: Isaac Newton's contribution to the understanding of gravity\n",
      "\n",
      "Takeaways:\n",
      "1. The story of the falling apple symbolizes Newton’s realization of the forces of gravity.\n",
      "2. Newton formulated the law of universal gravitation, which explains the motion of planets and earthly objects.\n",
      "3. His work, especially in the \"Principia Mathematica,\" was foundational to classical mechanics and influenced future scientific research.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for text in user_prompts:\n",
    "    prompt = f\"\"\" Given ```{text}``` delimited with triple backticks, identify a single key idea being discussed, \n",
    "    and label its 'Subject'. Next, enumerate at most three takeways. \n",
    "    Use short, simple sentences. \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\nOriginal content: {text}\")\n",
    "    print(f\"\\n {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113abb50-6a73-4101-8846-e8f26d85bb9c",
   "metadata": {},
   "source": [
    "Let's try another example to extract more than on subject or topic being\n",
    "discussed in the text, and enumerate three takeways.\n",
    "\n",
    "(Incidentally, I'm reading biography of Benjamin Franklin by Issac Stevenson, and all this seems to align with his career path and passion.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f34ceebf-c1b6-495b-8c78-81d2fc45baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stories = [\"\"\"\"Printer.\n",
    "                He that has a Trade has an Office of Profit and Honour’ Poor Richard’s Almanack\n",
    "Benjamin Franklin had an affinity with print and books throughout his life. \n",
    "Apprenticed as a child to his brother James, a printer, he mastered all aspects of\n",
    "the trade, from typesetting to engraving, learning the latest techniques during his\n",
    "first visit to London.  An avid reader, Franklin saved money to buy books by \n",
    "temporarily turning vegetarian and, once settled in Philadelphia, founded the \n",
    "Library Company, the first subscription library in the colonies.  As an elder\n",
    "statesman, he even bought type and kept a press during his stay in France. \n",
    "After working as a printer’s journeyman, he set up his own Philadelphian printing \n",
    "office in 1728.  His success with the Pennslyannia Gazette and Poor Richard’s\n",
    "Almanack helped to provide Franklin with the financial means to retire from\n",
    "business, retaining a stake in his print shop and founding others throughout the \n",
    "colonies.  Print also gave him a public voice: Franklin preferred the printed word, \n",
    "rather than public rhetoric, influencing political and public opinion as a brilliant\n",
    "journalist and pamphleteer.\n",
    "\n",
    "Silence Dogood and the New­England Courant\n",
    "    When James Franklin lost the contract to print the Boston Gazette, he determined\n",
    "to begin his own newspaper, launching the New­England Courant in 1721.\n",
    "Benjamin, who had been indentured secretly to James, helped to print the weekly \n",
    "paper.  One night he slipped a composition under the door, beginning the series\n",
    "of ‘Silence Dogood’ letters, the purported epistles of a vocal widower, with strong \n",
    "opinions on drunks, clergymen, foolish fashions and Boston nightlife. Owing no\n",
    "little debt to the satire of the London Spectator, the letters represented a \n",
    "remarkable literary achievement for the 16­year old.  The British Library’s copy has \n",
    "been uniquely annotated in what appears to be Franklin’s hand. The first \n",
    "‘Dogood’ letter appears on the bottom right.\n",
    "\n",
    "‘The Main Design of the Weekly Paper will be to Entertain the Town’\n",
    "    Benjamin’s brother, James, began the New­England Courant in the face of\n",
    "opposition from the Boston Establishment.  He soon irritated them with his squibs\n",
    "and satires on the great and the good, attacking the influential clergyman Cotton\n",
    "Mather’s pet project of small pox inoculation and the authorities’ weak response \n",
    "to piracy. Twice arrested, James temporally left the paper in Benjamin’s hands, and \n",
    "then continued to publish it under Benjamin’s name to escape a ban on\n",
    "publication.  This issue is the first printed item to carry the imprint ‘B. Franklin’ (on\n",
    "the rear).  Franklin announces his intention to ‘Entertain the Town’ on this page.\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1909a1b5-68fa-449c-9d40-0d4494b75b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Complete Storey: \"Printer.\n",
      "                He that has a Trade has an Office of Profit and Honour’ Poor Richard’s Almanack\n",
      "Benjamin Franklin had an affinity with print and books throughout his life. \n",
      "Apprenticed as a child to his brother James, a printer, he mastered all aspects of\n",
      "the trade, from typesetting to engraving, learning the latest techniques during his\n",
      "first visit to London.  An avid reader, Franklin saved money to buy books by \n",
      "temporarily turning vegetarian and, once settled in Philadelphia, founded the \n",
      "Library Company, the first subscription library in the colonies.  As an elder\n",
      "statesman, he even bought type and kept a press during his stay in France. \n",
      "After working as a printer’s journeyman, he set up his own Philadelphian printing \n",
      "office in 1728.  His success with the Pennslyannia Gazette and Poor Richard’s\n",
      "Almanack helped to provide Franklin with the financial means to retire from\n",
      "business, retaining a stake in his print shop and founding others throughout the \n",
      "colonies.  Print also gave him a public voice: Franklin preferred the printed word, \n",
      "rather than public rhetoric, influencing political and public opinion as a brilliant\n",
      "journalist and pamphleteer.\n",
      "\n",
      "Silence Dogood and the New­England Courant\n",
      "    When James Franklin lost the contract to print the Boston Gazette, he determined\n",
      "to begin his own newspaper, launching the New­England Courant in 1721.\n",
      "Benjamin, who had been indentured secretly to James, helped to print the weekly \n",
      "paper.  One night he slipped a composition under the door, beginning the series\n",
      "of ‘Silence Dogood’ letters, the purported epistles of a vocal widower, with strong \n",
      "opinions on drunks, clergymen, foolish fashions and Boston nightlife. Owing no\n",
      "little debt to the satire of the London Spectator, the letters represented a \n",
      "remarkable literary achievement for the 16­year old.  The British Library’s copy has \n",
      "been uniquely annotated in what appears to be Franklin’s hand. The first \n",
      "‘Dogood’ letter appears on the bottom right.\n",
      "\n",
      "‘The Main Design of the Weekly Paper will be to Entertain the Town’\n",
      "    Benjamin’s brother, James, began the New­England Courant in the face of\n",
      "opposition from the Boston Establishment.  He soon irritated them with his squibs\n",
      "and satires on the great and the good, attacking the influential clergyman Cotton\n",
      "Mather’s pet project of small pox inoculation and the authorities’ weak response \n",
      "to piracy. Twice arrested, James temporally left the paper in Benjamin’s hands, and \n",
      "then continued to publish it under Benjamin’s name to escape a ban on\n",
      "publication.  This issue is the first printed item to carry the imprint ‘B. Franklin’ (on\n",
      "the rear).  Franklin announces his intention to ‘Entertain the Town’ on this page.\n",
      "\n",
      "\n",
      " Subjects: Printing, Literature, Journalism, Politics, Satire\n",
      "\n",
      "Takeaways:\n",
      "1. Franklin was skilled in printing.\n",
      "2. He wrote under a pseudonym.\n",
      "3. His newspaper faced opposition.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for story in user_stories:\n",
    "    prompt = f\"\"\" Extract five subjects that are being discussed in the \n",
    "                  following text, which is delimited by triple backticks.\n",
    "                  Format your response as a list of subjects \"Subjects:\" separated by commas.\n",
    "                  Make each subject at most two words long, not longer. \n",
    "                  Next, enumerate  as a list three takeways, and label them as \"Takeways:\" \n",
    "                  Use short, simple sentences for your takeways.\n",
    "                  Text sample: '''{story}'''\n",
    "                  \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\nComplete Storey: {story}\")\n",
    "    print(f\"\\n {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08da3189-e9d0-42c9-9f70-d403df9e0dc5",
   "metadata": {},
   "source": [
    "## Text classification or sentiment analysis\n",
    "\n",
    "Unlike classical or traditional machine learning, where you'll have to do supervised learning to collect data, label it, and train for hours, depending on how much data,classifying text using LLM is simple.\n",
    "\n",
    "In short, you'll have to build a ML model to understand text and classify its sentiments as positive, negative or neutral. \n",
    "\n",
    "This onus task is easily done with LLM via clever prompting. \n",
    "\n",
    "Let's see what I mean in this *how-to* idenfity sentiments in text But first let's \n",
    "generatre some sentiments as our ground truth, and supply them to LLM to observe it\n",
    "LLM identifies them correctly. This bit is not needed, for I'm just curious.\n",
    "\n",
    "Positive: \"This movie is a true cinematic gem, blending an engaging plot with superb performances and stunning visuals. A masterpiece that leaves a lasting impression.\"\n",
    "\n",
    "*Negative*: \"Regrettably, the film failed to live up to expectations, with a convoluted storyline, lackluster acting, and uninspiring cinematography. A disappointment overall.\"\n",
    "\n",
    "*Neutral*: \"The movie had its moments, offering a decent storyline and average performances. While not groundbreaking, it provided an enjoyable viewing experience.\"\n",
    "\n",
    "*Positive*: \"This city is a vibrant tapestry of culture, with friendly locals, historic landmarks, and a lively atmosphere. An ideal destination for cultural exploration.\"\n",
    "\n",
    "*Negative*: \"The city's charm is overshadowed by traffic congestion, high pollution levels, and a lack of cleanliness. Not recommended for a peaceful retreat.\"\n",
    "\n",
    "*Neutral*: \"The city offers a mix of experiences, from bustling markets to serene parks. An interesting but not extraordinary destination for exploration.\"\n",
    "\n",
    "*Positive*: \"This song is a musical masterpiece, enchanting listeners with its soulful lyrics, mesmerizing melody, and exceptional vocals. A timeless classic.\"\n",
    "\n",
    "*Negative*: \"The song fails to impress, featuring uninspiring lyrics, a forgettable melody, and lackluster vocals. It lacks the creativity to leave a lasting impact.\"\n",
    "\n",
    "*Neutral*: \"The song is decent, with a catchy tune and average lyrics. While enjoyable, it doesn't stand out in the vast landscape of music.\"\n",
    "\n",
    "*Positive*: \"A delightful cinematic experience that seamlessly weaves together a compelling narrative, strong character development, and breathtaking visuals.\"\n",
    "\n",
    "*Negative*: \"This film, unfortunately, falls short with a disjointed plot, subpar performances, and a lack of coherence. A disappointing viewing experience.\"\n",
    "\n",
    "*Neutral*: \"While not groundbreaking, the movie offers a decent storyline and competent performances, providing an overall satisfactory viewing experience.\"\n",
    "\n",
    "*Positive*: \"This city is a haven for culture enthusiasts, boasting historical landmarks, a rich culinary scene, and a welcoming community. A must-visit destination.\"\n",
    "\n",
    "*Negative*: \"The city's appeal is tarnished by overcrowded streets, noise pollution, and a lack of urban planning. Not recommended for a tranquil getaway.\"\n",
    "\n",
    "*Neutral*: \"The city offers a diverse range of experiences, from bustling markets to serene parks. An intriguing destination for those seeking a mix of urban and natural landscapes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26fba25e-e40b-40fc-84b5-0a86df748b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a prominent critic of landscapes, architecture, cities, movies, songs, \n",
    "                    entertainment, and a cultural ombudsman. \"\"\"\n",
    "\n",
    "user_sentiments = [ \"This movie is a true cinematic gem, blending an engaging plot with superb performances and stunning visuals. A masterpiece that leaves a lasting impression.\",\n",
    "                    \"Regrettably, the film failed to live up to expectations, with a convoluted storyline, lackluster acting, and uninspiring cinematography. A disappointment overall.\",\n",
    "                    \"The movie had its moments, offering a decent storyline and average performances. While not groundbreaking, it provided an enjoyable viewing experience.\",\n",
    "                    \"This city is a vibrant tapestry of culture, with friendly locals, historic landmarks, and a lively atmosphere. An ideal destination for cultural exploration.\",\n",
    "                    \"The city's charm is overshadowed by traffic congestion, high pollution levels, and a lack of cleanliness. Not recommended for a peaceful retreat.\",\n",
    "                    \"The city offers a mix of experiences, from bustling markets to serene parks. An interesting but not extraordinary destination for exploration.\",\n",
    "                    \"This song is a musical masterpiece, enchanting listeners with its soulful lyrics, mesmerizing melody, and exceptional vocals. A timeless classic.\",\n",
    "                    \"The song fails to impress, featuring uninspiring lyrics, a forgettable melody, and lackluster vocals. It lacks the creativity to leave a lasting impact.\",\n",
    "                    \"The song is decent, with a catchy tune and average lyrics. While enjoyable, it doesn't stand out in the vast landscape of music.\",\n",
    "                    \"A delightful cinematic experience that seamlessly weaves together a compelling narrative, strong character development, and breathtaking visuals.\",\n",
    "                    \"This film, unfortunately, falls short with a disjointed plot, subpar performances, and a lack of coherence. A disappointing viewing experience.\",\n",
    "                    \"While not groundbreaking, the movie offers a decent storyline and competent performances, providing an overall satisfactory viewing experience.\",\n",
    "                    \"This city is a haven for culture enthusiasts, boasting historical landmarks, a rich culinary scene, and a welcoming community. A must-visit destination.\",\n",
    "                    \"The city's appeal is tarnished by overcrowded streets, noise pollution, and a lack of urban planning. Not recommended for a tranquil getaway.\",\n",
    "                    \"The city offers a diverse range of experiences, from bustling markets to serene parks. An intriguing destination for those seeking a mix of urban and natural landscapes.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bae549c-fa32-46e8-af19-83f923222e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Sentiment: This movie is a true cinematic gem, blending an engaging plot with superb performances and stunning visuals. A masterpiece that leaves a lasting impression.\n",
      "\n",
      "Label    : positive\n",
      "\n",
      "Sentiment: Regrettably, the film failed to live up to expectations, with a convoluted storyline, lackluster acting, and uninspiring cinematography. A disappointment overall.\n",
      "\n",
      "Label    : negative\n",
      "\n",
      "Sentiment: The movie had its moments, offering a decent storyline and average performances. While not groundbreaking, it provided an enjoyable viewing experience.\n",
      "\n",
      "Label    : neutral\n",
      "\n",
      "Sentiment: This city is a vibrant tapestry of culture, with friendly locals, historic landmarks, and a lively atmosphere. An ideal destination for cultural exploration.\n",
      "\n",
      "Label    : positive\n",
      "\n",
      "Sentiment: The city's charm is overshadowed by traffic congestion, high pollution levels, and a lack of cleanliness. Not recommended for a peaceful retreat.\n",
      "\n",
      "Label    : negative\n",
      "\n",
      "Sentiment: The city offers a mix of experiences, from bustling markets to serene parks. An interesting but not extraordinary destination for exploration.\n",
      "\n",
      "Label    : positive\n",
      "\n",
      "Sentiment: This song is a musical masterpiece, enchanting listeners with its soulful lyrics, mesmerizing melody, and exceptional vocals. A timeless classic.\n",
      "\n",
      "Label    : positive\n",
      "\n",
      "Sentiment: The song fails to impress, featuring uninspiring lyrics, a forgettable melody, and lackluster vocals. It lacks the creativity to leave a lasting impact.\n",
      "\n",
      "Label    : negative\n",
      "\n",
      "Sentiment: The song is decent, with a catchy tune and average lyrics. While enjoyable, it doesn't stand out in the vast landscape of music.\n",
      "\n",
      "Label    : neutral\n",
      "\n",
      "Sentiment: A delightful cinematic experience that seamlessly weaves together a compelling narrative, strong character development, and breathtaking visuals.\n",
      "\n",
      "Label    : positive\n",
      "\n",
      "Sentiment: This film, unfortunately, falls short with a disjointed plot, subpar performances, and a lack of coherence. A disappointing viewing experience.\n",
      "\n",
      "Label    : negative\n",
      "\n",
      "Sentiment: While not groundbreaking, the movie offers a decent storyline and competent performances, providing an overall satisfactory viewing experience.\n",
      "\n",
      "Label    : Positive\n",
      "\n",
      "Sentiment: This city is a haven for culture enthusiasts, boasting historical landmarks, a rich culinary scene, and a welcoming community. A must-visit destination.\n",
      "\n",
      "Label    : positive\n",
      "\n",
      "Sentiment: The city's appeal is tarnished by overcrowded streets, noise pollution, and a lack of urban planning. Not recommended for a tranquil getaway.\n",
      "\n",
      "Label    : negative\n",
      "\n",
      "Sentiment: The city offers a diverse range of experiences, from bustling markets to serene parks. An intriguing destination for those seeking a mix of urban and natural landscapes.\n",
      "\n",
      "Label    : positive\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for user_sentiment in user_sentiments:\n",
    "    prompt = f\"\"\"What is the sentiment of the ```{user_sentiment}`` which is delimited with triple backticks?\n",
    "                  Classify the given text into single label as neutral, negative \n",
    "                  or positive. Do not expand on your response. Use a single word.\n",
    "                  If you cannot classify do not guess, just label as dont' know.\n",
    "                    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\nSentiment: {user_sentiment}\")\n",
    "    print(f\"\\nLabel    : {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f520fec-af04-4b97-8e66-3187e34b5566",
   "metadata": {},
   "source": [
    "## Text categorization\n",
    "Like sentiment analysis, given a query, an LLM can identify from its context how to classify and route customer queries to respective departments. Also, note that LLM can detect foul language and respond politely. Text categorization can be employed to automate customer on-line queries.\n",
    "\n",
    "Let's look at how we can achieve that with smart and deliberate prompting.\n",
    "\n",
    "<img src=\"./images/category_resp.png\" height=\"35%\" width=\"%65\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75b9307f-a2b3-4393-8e5a-5d7af520ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a smart and helful Assistant who can route customer queries to \n",
    "                    respective customer service departments.\n",
    "                    \"\"\"\n",
    "\n",
    "customer_queries = [\"\"\"My modem has stop working. I tried to restart but the orange light keep flashing. It never turns green.\"\"\",\n",
    "                    \"\"\"I just moved into town, and I need Internet service\"\"\",\n",
    "                    \"\"\"Why am I being charged extra $20 a month for cable TV when I don't use a television?\"\"\",\n",
    "                    \"\"\"I need to change my user name and password since someone is using my credentials\"\"\",\n",
    "                    \"\"\"What days this week are we having a general upgrades to the cable models?\"\"\",\n",
    "                    \"\"\"What day is the best day to call customer service so that I can avoid talking to a bloody bot!\"\"\",\n",
    "                    \"\"\"Your company is full of incompetent fools!\"\"\",\n",
    "                    \"\"\"I hate your worthless services. Cancel my stupid account or else I'll sue you!\"\"\"\n",
    "                   ]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36fe82a0-9486-4e8c-b573-3bb71d7a71b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Query: My modem has stop working. I tried to restart but the orange light keep flashing. It never turns green.\n",
      "Route to: Technical support\n",
      "\n",
      "\n",
      "Query: I just moved into town, and I need Internet service\n",
      "Route to: New Customer\n",
      "\n",
      "\n",
      "Query: Why am I being charged extra $20 a month for cable TV when I don't use a television?\n",
      "Route to: Billing\n",
      "\n",
      "\n",
      "Query: I need to change my user name and password since someone is using my credentials\n",
      "Route to: Account Management\n",
      "\n",
      "\n",
      "Query: What days this week are we having a general upgrades to the cable models?\n",
      "Route to: Technical support\n",
      "\n",
      "\n",
      "Query: What day is the best day to call customer service so that I can avoid talking to a bloody bot!\n",
      "Route to: General inquiry\n",
      "\n",
      "\n",
      "Query: Your company is full of incompetent fools!\n",
      "Route to: No need for foul language. Please be respectful.\n",
      "\n",
      "\n",
      "Query: I hate your worthless services. Cancel my stupid account or else I'll sue you!\n",
      "Route to: No need for foul language. Please be respectful.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for query in customer_queries:\n",
    "    prompt = f\"\"\" Classify each customer {query} into the following categories:\n",
    "                    1. Technical support\n",
    "                    2. Billing \n",
    "                    3. Account Management\n",
    "                    4. New Customer  \n",
    "                    5. General inquiry\n",
    "                  Do not expand your response. Only use the above categories. \n",
    "                  If you can't precisely categorize, then default to \"General inquiry.\"\n",
    "                  If customer {query} is abusive or in a foul language, then respond with \n",
    "                  \"No need for foul language. Please be respectful.\"\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(f\"Route to: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05333b92-c3fb-4341-b59d-82eeb7a65071",
   "metadata": {},
   "source": [
    "## Text transation and transformation\n",
    "\n",
    "Language translation by far is the most common use case for natural language processing. \n",
    "We have seen its early uses in Google translation, but with the emergence of multi-lingual LLMs, this task is simply achieved by exact prompting. \n",
    "\n",
    "In this section, we'll explore tasks in how to use LLMs for text translations, langugage identication, text transformation, spelling and grammar checking, tone adjustment, and format conversion.\n",
    "\n",
    "### Task 1:\n",
    " * Given an English text, translate into French, Spanish, and German.\n",
    " * Given a foreign language text, idenfify the language, and translate to English.\n",
    "\n",
    "\n",
    "👷‍♀️ under construction 🚧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e9dcecd-8c00-45d6-af45-af19ee7bffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content= \"\"\"You are a world reknowned supreme lingiust and a universal translator. You are a polglot, and fluently speak many global languages\"\"\"\n",
    "\n",
    "english_texts = [\"\"\" Welcome to New York for the United Nations General Council Meeting. Today\n",
    "is a special day for us to celeberate all our achievments since this global institute's formation.\n",
    "But more importantly, we want to address how we can mitigate global conflict with conversation\n",
    "and promote deterence, detente, and discussion.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad8986d5-3ade-4264-a29b-77dbf7b0ef8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "English Text:  Welcome to New York for the United Nations General Council Meeting. Today\n",
      "is a special day for us to celeberate all our achievments since this global institute's formation.\n",
      "But more importantly, we want to address how we can mitigate global conflict with conversation\n",
      "and promote deterence, detente, and discussion.\n",
      "Certainly! Here are the translations:\n",
      "\n",
      "**Spanish:**\n",
      "Bienvenidos a Nueva York para la Reunión del Consejo General de las Naciones Unidas. Hoy es un día especial para nosotros para celebrar todos nuestros logros desde la formación de este instituto global. Pero más importante aún, queremos abordar cómo podemos mitigar el conflicto global con conversación y promover la disuasión, la distensión y el diálogo.\n",
      "\n",
      "**French:**\n",
      "Bienvenue à New York pour la réunion du Conseil Général des Nations Unies. Aujourd'hui est un jour spécial pour nous de célébrer toutes nos réalisations depuis la formation de cet institut global. Mais plus important encore, nous souhaitons aborder comment nous pouvons atténuer les conflits mondiaux par la conversation et promouvoir la dissuasion, la détente et la discussion.\n",
      "\n",
      "**German:**\n",
      "Willkommen in New York zur Generalversammlung der Vereinten Nationen. Heute ist ein besonderer Tag für uns, um all unsere Errungenschaften seit der Gründung dieses globalen Instituts zu feiern. Aber noch wichtiger ist, dass wir besprechen wollen, wie wir globale Konflikte durch Gespräche mildern und Abschreckung, Entspannung und Diskussion fördern können.\n",
      "\n",
      "**Mandarin (Simplified Chinese):**\n",
      "欢迎来到纽约参加联合国大会议。今天对我们来说是一个特别的日子，我们将庆祝自该全球机构成立以来取得的所有成就。但更重要的是，我们想要讨论如何通过对话来缓解全球冲突，并促进遏制、缓和和讨论。\n",
      "\n",
      "Please note that Mandarin can be written in Simplified or Traditional characters; the translation provided here uses Simplified characters, which are commonly used in Mainland China.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for english_text in english_texts:\n",
    "    prompt = f\"\"\"\"Given an English text in triple ticks '''{english_text}'''. Translate into\n",
    "three languases: Spanish, French, German, and Mandarin. \n",
    "Label each translation with the langauge Name: followed by translation on a seperate line.\"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\nEnglish Text: {english_text}\")\n",
    "    print(f\"{response}\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dae09d-5198-42a6-896b-347f260fe3eb",
   "metadata": {},
   "source": [
    "Given a foreing language, identify the language and translate into English.\n",
    "\n",
    "This is the reverse of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a366e171-38b6-4d8d-928a-a36ec0137a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_texts = [\"\"\"Bienvenidos a Nueva York para la Reunión del Consejo General de las Naciones Unidas. Hoy\n",
    "es un día especial para celebrar todos nuestros logros desde la formación de este instituto global.\n",
    "Pero más importante aún, queremos abordar cómo podemos mitigar el conflicto global con conversaciones\n",
    "y promover la disuasión, la distensión y el diálogo.\"\"\",\n",
    "            \"\"\"Willkommen in New York zur Sitzung des Allgemeinen Rates der Vereinten Nationen. Heute\n",
    "ist ein besonderer Tag für uns, um all unsere Errungenschaften seit der Gründung dieses globalen Instituts zu feiern.\n",
    "Aber wichtiger ist, dass wir ansprechen möchten, wie wir globale Konflikte durch Gespräche mildern können\n",
    "und Abschreckung, Entspannung und Diskussion fördern.\"\"\",\n",
    "                  \"\"\"Bienvenue à New York pour la réunion du Conseil Général des Nations Unies. Aujourd'hui,\n",
    "c'est un jour spécial pour nous pour célébrer toutes nos réalisations depuis la formation de cette institution mondiale.\n",
    "Mais plus important encore, nous voulons aborder comment nous pouvons atténuer les conflits mondiaux grâce à la conversation\n",
    "et promouvoir la dissuasion, la détente et la discussion.\"\"\",\n",
    "                  \"\"\"欢迎来到纽约参加联合国大会议。今天对我们来说是一个特别的日子，我们将庆祝自该全球机构成立以来取得的所有成就。但更重要的是，我们想要讨论如何通过对话来缓解全球冲突，并促进遏制、缓和和讨论。\n",
    "\"\"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44a86628-4641-4283-8bba-9d2961451915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Language Text: Bienvenidos a Nueva York para la Reunión del Consejo General de las Naciones Unidas. Hoy\n",
      "es un día especial para celebrar todos nuestros logros desde la formación de este instituto global.\n",
      "Pero más importante aún, queremos abordar cómo podemos mitigar el conflicto global con conversaciones\n",
      "y promover la disuasión, la distensión y el diálogo.\n",
      "Language Name: Spanish\n",
      "\n",
      "English Translation: Welcome to New York for the United Nations General Assembly Meeting. Today is a special day to celebrate all our achievements since the formation of this global institute. But even more importantly, we want to address how we can mitigate global conflict with conversations and promote deterrence, de-escalation, and dialogue.\n",
      "\n",
      "\n",
      "Language Text: Willkommen in New York zur Sitzung des Allgemeinen Rates der Vereinten Nationen. Heute\n",
      "ist ein besonderer Tag für uns, um all unsere Errungenschaften seit der Gründung dieses globalen Instituts zu feiern.\n",
      "Aber wichtiger ist, dass wir ansprechen möchten, wie wir globale Konflikte durch Gespräche mildern können\n",
      "und Abschreckung, Entspannung und Diskussion fördern.\n",
      "Language Name: German\n",
      "\n",
      "English Translation: Welcome to New York for the meeting of the General Council of the United Nations. Today is a special day for us to celebrate all our achievements since the founding of this global institution. But more importantly, we want to address how we can mitigate global conflicts through dialogue and promote deterrence, relaxation, and discussion.\n",
      "\n",
      "\n",
      "Language Text: Bienvenue à New York pour la réunion du Conseil Général des Nations Unies. Aujourd'hui,\n",
      "c'est un jour spécial pour nous pour célébrer toutes nos réalisations depuis la formation de cette institution mondiale.\n",
      "Mais plus important encore, nous voulons aborder comment nous pouvons atténuer les conflits mondiaux grâce à la conversation\n",
      "et promouvoir la dissuasion, la détente et la discussion.\n",
      "Language Name: French\n",
      "\n",
      "English Translation: Welcome to New York for the meeting of the General Council of the United Nations. Today, it's a special day for us to celebrate all of our achievements since the formation of this global institution. But more importantly, we want to address how we can mitigate global conflicts through conversation and promote deterrence, relaxation, and discussion.\n",
      "\n",
      "\n",
      "Language Text: 欢迎来到纽约参加联合国大会议。今天对我们来说是一个特别的日子，我们将庆祝自该全球机构成立以来取得的所有成就。但更重要的是，我们想要讨论如何通过对话来缓解全球冲突，并促进遏制、缓和和讨论。\n",
      "\n",
      "Language Name: Chinese (Simplified)\n",
      "\n",
      "English Translation: Welcome to New York to attend the United Nations General Assembly. Today is a special day for us, as we will celebrate all the achievements made since the establishment of this global institution. But more importantly, we want to discuss how to alleviate global conflicts through dialogue, and promote containment, mitigation, and discussion.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for language_text in languages_texts:\n",
    "    prompt = f\"\"\"\"Given a language text in triple ticks '''{language_text}'''. Idenfity\n",
    "    the language with the langauge Name: followed by an English translation on a seperate line, labeled as English translation:\"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\nLanguage Text: {language_text}\")\n",
    "    print(f\"{response}\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8740e21-ea45-4b38-a0f7-753ef48a02aa",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    " * Given an English text, proof read it and correct any grammatical and usage errors.\n",
    " * Given a Pirate text, correct its tone to standard English.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a31e6bb8-83dd-4f0a-9036-a58e305e7d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a fastidious grammarian. You can proofread any English text and convert to \n",
    "its grammtical correct and usage form.\"\"\"\n",
    "\n",
    "bad_english_texts = [\"\"\"I don't know nothing about them big words and grammar rules. Me and my friend, we was talking, and he don't agree with me. We ain't never gonna figure it out, I reckon. His dog don't listen good, always running around and don't come when you call.\"\"\",\n",
    "                     \"\"\"Yesterday, we was at the park, and them kids was playing. She don't like the way how they acted, but I don't got no problem with it. We seen a movie last night, and it was good, but my sister, she don't seen it yet. Them books on the shelf, they ain't interesting to me.\"\"\"\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e4f0a39-e951-4e69-b547-cb969ea8250c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Original Text: I don't know nothing about them big words and grammar rules. Me and my friend, we was talking, and he don't agree with me. We ain't never gonna figure it out, I reckon. His dog don't listen good, always running around and don't come when you call.\n",
      "Corrected  Text: Certainly! Here is the corrected version of the text:\n",
      "\n",
      "\"I don't know anything about those big words and grammar rules. My friend and I were talking, and he doesn't agree with me. We are never going to figure it out, I reckon. His dog doesn't listen well, always running around and not coming when you call.\"\n",
      "\n",
      "\n",
      "Original Text: Yesterday, we was at the park, and them kids was playing. She don't like the way how they acted, but I don't got no problem with it. We seen a movie last night, and it was good, but my sister, she don't seen it yet. Them books on the shelf, they ain't interesting to me.\n",
      "Corrected  Text: Certainly, here is the corrected passage:\n",
      "\n",
      "\"Yesterday, we were at the park, and those kids were playing. She doesn't like the way they acted, but I don't have any problem with it. We saw a movie last night, and it was good, but my sister hasn't seen it yet. Those books on the shelf aren't interesting to me.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for bad_english_text in bad_english_texts:\n",
    "    prompt = f\"\"\"\"Proofread and correct the text provided in triple ticks '''{bad_english_text}'''.\n",
    "    Use standard usage and remedy any incorect grammar usage.\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\nOriginal Text: {bad_english_text}\")\n",
    "    print(f\"Corrected  Text: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01c28033-8175-427b-93d2-69db740060e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pirate_texts = [\"\"\"Arrr matey! I be knowin' nuthin' 'bout them fancy words and grammatical rules. Me and me heartie, we be chattin', and he don't be agreein' with me. We ain't never gonna figure it out, I reckon. His scallywag of a dog don't be listenin' well, always runnin' around and not comin' when ye call.\"\"\"\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f09b26f1-b370-4cd3-9079-b5b78df502d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Original Text: Arrr matey! I be knowin' nuthin' 'bout them fancy words and grammatical rules. Me and me heartie, we be chattin', and he don't be agreein' with me. We ain't never gonna figure it out, I reckon. His scallywag of a dog don't be listenin' well, always runnin' around and not comin' when ye call.\n",
      "Corrected  Text: \"Hello! I don't know anything about those fancy words and grammatical rules. My friend and I have been chatting, and he doesn't agree with me. I guess we'll never figure it out. His mischievous dog doesn't listen well; it's always running around and not coming when you call.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for pirate_text in pirate_texts:\n",
    "    prompt = f\"\"\"\"Convert the Pirate text provided in triple ticks '''{pirate_text}'''.\n",
    "    Use standard usage and remedy any incorect grammar usage, dropping all Pirate greetings.\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\nOriginal Text: {pirate_text}\")\n",
    "    print(f\"Corrected  Text: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e48460-00a6-4a7f-9e54-b1e25e00860d",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "* Given some text in a particular format, convert it into JSON format.\n",
    "* For example, we LLM to producce names of three top shoes, but we want them it product and its items in JSON format. This JSON format can be fed downstream into another application that may process it.\n",
    "\n",
    "Let's have go at it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5b7a40-5d26-4bb0-816e-08f04462d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You have knowledge of all sporting goods and will provide knowledge answers\n",
    "to queries about sporting goods.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9f77a87f-cf8a-486a-8c43-38a9e5f0c708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"Products\": [\n",
      "    {\n",
      "      \"Brand\": \"Nike\",\n",
      "      \"Description\": \"Nike Air Zoom Pegasus 38 Running Shoes\",\n",
      "      \"Size\": \"10\",\n",
      "      \"Gender\": \"Male\",\n",
      "      \"Price\": \"$120.00\",\n",
      "      \"Review\": [\n",
      "        {\n",
      "          \"Customer\": \"John Doe\",\n",
      "          \"Rating\": \"5 stars\",\n",
      "          \"Comment\": \"Extremely comfortable for long runs, great cushioning and support.\"\n",
      "        },\n",
      "        {\n",
      "          \"Customer\": \"Alex Smith\",\n",
      "          \"Rating\": \"4 stars\",\n",
      "          \"Comment\": \"Breathable material and fits true to size. Only wish the sole had more grip.\"\n",
      "        },\n",
      "        {\n",
      "          \"Customer\": \"Diane Roberts\",\n",
      "          \"Rating\": \"4.5 stars\",\n",
      "          \"Comment\": \"The Pegasus series never disappoints. Ideal for my daily training.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"Brand\": \"Adidas\",\n",
      "      \"Description\": \"Adidas Ultraboost 21\",\n",
      "      \"Size\": \"8\",\n",
      "      \"Gender\": \"Female\",\n",
      "      \"Price\": \"$180.00\",\n",
      "      \"Review\": [\n",
      "        {\n",
      "          \"Customer\": \"Emily Johnson\",\n",
      "          \"Rating\": \"5 stars\",\n",
      "          \"Comment\": \"Love the energy return on these, and the colorway is just stunning.\"\n",
      "        },\n",
      "        {\n",
      "          \"Customer\": \"Samantha Lee\",\n",
      "          \"Rating\": \"4 stars\",\n",
      "          \"Comment\": \"Super comfy and stylish. Took a bit of breaking in, but now they're perfect.\"\n",
      "        },\n",
      "        {\n",
      "          \"Customer\": \"Grace Park\",\n",
      "          \"Rating\": \"4.5 stars\",\n",
      "          \"Comment\": \"These are my go-to shoes for both running and casual outings.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"Brand\": \"ASICS\",\n",
      "      \"Description\": \"ASICS GEL-Kayano 27\",\n",
      "      \"Size\": \"9.5\",\n",
      "      \"Gender\": \"Unisex\",\n",
      "      \"Price\": \"$160.00\",\n",
      "      \"Review\": [\n",
      "        {\n",
      "          \"Customer\": \"Kevin Rodriguez\",\n",
      "          \"Rating\": \"5 stars\",\n",
      "          \"Comment\": \"Outstanding stability and support for overpronators like me.\"\n",
      "        },\n",
      "        {\n",
      "          \"Customer\": \"Mary Clark\",\n",
      "          \"Rating\": \"4 stars\",\n",
      "          \"Comment\": \"They feel a little heavy, but the comfort level is unmatched.\"\n",
      "        },\n",
      "        {\n",
      "          \"Customer\": \"Jacob Turner\",\n",
      "          \"Rating\": \"5 stars\",\n",
      "          \"Comment\": \"Durable, comfortable, and they look good. My feet are thanking me during every run.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"Brand\": \"Reebok\",\n",
      "      \"Description\": \"Reebok Nano X1 Cross Trainer\",\n",
      "      \"Size\": \"11\",\n",
      "      \"Gender\": \"Male\",\n",
      "      \"Price\": \"$130.00\",\n",
      "      \"Review\": [\n",
      "        {\n",
      "          \"Customer\": \"Linda Martinez\",\n",
      "          \"Rating\": \"4.5 stars\",\n",
      "          \"Comment\": \"Versatile shoes that work for various types of workouts. Highly recommend!\"\n",
      "        },\n",
      "        {\n",
      "          \"Customer\": \"Gary Stewart\",\n",
      "          \"Rating\": \"5 stars\",\n",
      "          \"Comment\": \"Best cross trainers I've owned. Great for lifting and agility drills.\"\n",
      "        },\n",
      "        {\n",
      "          \"Customer\": \"Rachel Kim\",\n",
      "          \"Rating\": \"5 stars\",\n",
      "          \"Comment\": \"Comfortable right out of the box, and they provide excellent support.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"Brand\": \"Under Armour\",\n",
      "      \"Description\": \"Under Armour HOVR Apex 2 Training Shoes\",\n",
      "      \"Size\": \"7.5\",\n",
      "      \"Gender\": \"Female\",\n",
      "      \"Price\": \"$140.00\",\n",
      "      \"Review\": [\n",
      "        {\n",
      "          \"Customer\": \"Olivia Sanchez\",\n",
      "          \"Rating\": \"4 stars\",\n",
      "          \"Comment\": \"Responsive cushioning and they handle multi-directional movements well.\"\n",
      "        },\n",
      "        {\n",
      "          \"Customer\": \"Daniel Gonzales\",\n",
      "          \"Rating\": \"4.5 stars\",\n",
      "          \"Comment\": \"A bit snug at first, but they adapt to your feet quickly. Great for HIIT.\"\n",
      "        },\n",
      "        {\n",
      "          \"Customer\": \"Jessica Wong\",\n",
      "          \"Rating\": \"5 stars\",\n",
      "          \"Comment\": \"The grip and stability are perfect for weight training. Also, really stylish!\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "prompt = f\"\"\"Generate five distinct products on training shoes. Generate products as a \n",
    "            JSON object. It should contain items: Brand, Description, Size, Gender: Male \n",
    "            or Female or Unisex, Price, and at least three customer reviews as Review \n",
    "            item\"\"\"\n",
    "response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6496b00-0a1d-4a57-9783-11f2dcf09c5a",
   "metadata": {},
   "source": [
    "## Simple and complex reasoning \n",
    "\n",
    "An import characteristic of LLM is that it's not only general respository of compressed\n",
    "knowledge garned from large corpus of text, but can be employed as a simple and complex reasoning engine. With use of precise prompt, you can instruct LLM to think trough a problem in a step by step fashion.\n",
    "\n",
    "Let's look at some tasks as examples.\n",
    " * given a list of numbers identify the prime numbers, add the prime numbers and check if the sum is even or odd.\n",
    " * given an hourly rate of wages, compute your yearly income if you work 30 hours a week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47be9101-2af8-4074-a970-b6cdadc692d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a reasoning engine. Given a problem think through the problem logically\n",
    "in a step by step manner.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c0b6b93-5218-4239-9db4-674e6b8dbd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prime_number_prompt = f\"\"\"given a list of numbers 1,2,3,4,5,7,8, 11,13,17,19,23,24,29 identify the prime numbers, add the prime numbers, \n",
    "and check if the sum is even or odd. Explain each step how you solved the problem\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f0bd7a7-9c8b-4c97-85b3-8f83a0ca61b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_wages_prompt = f\"\"\"If my hourly rate is $117.79 per hour, and I work at most 30 hours a week, what\n",
    "is my yearly income? Break the problem into simple steps and explain in each step how you arrive \n",
    "to the answer. If you don't know, simple say I don't know. Do not make up answers\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4ecb495-ee6f-4033-8fa7-7c364d79ffbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve this problem, we will follow these steps:\n",
      "\n",
      "1. Identify the prime numbers in the provided list.\n",
      "2. Add the identified prime numbers.\n",
      "3. Check if the sum is even or odd.\n",
      "\n",
      "Let's tackle each step one by one.\n",
      "\n",
      "**Step 1: Identify the prime numbers**\n",
      "A prime number is a natural number greater than 1 that is not a product of two smaller natural numbers. In other words, a prime number is only divisible by 1 and itself. Let's go through the list and identify the prime numbers.\n",
      "\n",
      "- 1 is not a prime number because the definition of a prime number requires it to have exactly two distinct positive divisors: 1 and the number itself. Since 1 only has one divisor (1), it does not meet the criteria.\n",
      "- 2 is a prime number because its only divisors are 1 and 2.\n",
      "- 3 is a prime number because its only divisors are 1 and 3.\n",
      "- 4 is not a prime number because it is divisible by 1, 2, and 4.\n",
      "- 5 is a prime number because its only divisors are 1 and 5.\n",
      "- 7 is a prime number because its only divisors are 1 and 7.\n",
      "- 8 is not a prime number because it is divisible by 1, 2, 4, and 8.\n",
      "- 11 is a prime number because its only divisors are 1 and 11.\n",
      "- 13 is a prime number because its only divisors are 1 and 13.\n",
      "- 17 is a prime number because its only divisors are 1 and 17.\n",
      "- 19 is a prime number because its only divisors are 1 and 19.\n",
      "- 23 is a prime number because its only divisors are 1 and 23.\n",
      "- 24 is not a prime number because it has divisors other than 1 and 24.\n",
      "- 29 is a prime number because its only divisors are 1 and 29.\n",
      "\n",
      "Now we have identified the prime numbers in the list: 2, 3, 5, 7, 11, 13, 17, 19, 23, and 29.\n",
      "\n",
      "**Step 2: Add the prime numbers**\n",
      "Next, we add up these prime numbers:\n",
      "\n",
      "2 + 3 + 5 + 7 + 11 + 13 + 17 + 19 + 23 + 29 = 129\n",
      "\n",
      "**Step 3: Check if the sum is even or odd**\n",
      "An even number is an integer that is exactly divisible by 2. An odd number is an integer that is not exactly divisible by 2. We can determine if a number is even or odd by looking at its last digit. If the last digit is 0, 2, 4, 6, or 8, it is even; if it is 1, 3, 5, 7, or 9, it is odd.\n",
      "\n",
      "The sum we got from step 2 is 129. The last digit of 129 is 9, which is an odd number. Therefore, the sum of the prime numbers (129) is odd.\n",
      "\n",
      "In conclusion, after identifying the prime numbers in the list, adding them up, and checking the sum, we found that the sum of the prime numbers from the given list is an odd number, 129.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, prime_number_prompt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5651b79b-997e-4524-b17b-14f413e850a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate your yearly income based on your hourly rate and the number of hours you work each week, you can follow these steps:\n",
      "\n",
      "**Step 1: Calculate weekly income.**\n",
      "First, you need to determine how much you earn in a single week by working 30 hours at your hourly rate of $117.79.\n",
      "\n",
      "Weekly income = Hourly rate × Hours worked per week\n",
      "Weekly income = $117.79/hour × 30 hours/week\n",
      "Weekly income = $3533.70/week\n",
      "\n",
      "**Step 2: Calculate yearly income based on weeks worked.**\n",
      "Next, you need to determine how many weeks in a year you will be working. For a full-time job, it's common to assume 52 weeks in a year; however, this does not account for any vacation time or holidays you may take. If you are working every week of the year without taking time off, you would multiply your weekly income by 52.\n",
      "\n",
      "Yearly income = Weekly income × Number of weeks worked in a year\n",
      "Assuming you work all 52 weeks:\n",
      "Yearly income = $3533.70/week × 52 weeks/year\n",
      "Yearly income = $183,752.40/year\n",
      "\n",
      "**However**, if you know the exact number of weeks you work per year (taking into account any vacation or holidays), you should use that number instead of 52. For instance, if you have 2 weeks of vacation, you would work 50 weeks in a year:\n",
      "\n",
      "Yearly income = $3533.70/week × 50 weeks/year (with 2 weeks of vacation)\n",
      "Yearly income = $176,685.00/year\n",
      "\n",
      "In summary, if you work every week of the year without taking any time off, your yearly income would be approximately $183,752.40. If you have some weeks off, you would adjust the calculation accordingly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, hourly_wages_prompt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a5da1-986a-4682-a672-8c213eb40be5",
   "metadata": {},
   "source": [
    "## Code generation\n",
    "\n",
    "Language models like ChatGPT and Llama 2 are really good at generating code. Copilot on GitHub is a cool example of this. You can do lots of different code tasks just by asking in a smart way. Let's check out a few examples to see how it's helpful.\n",
    "\n",
    "#### Task 1\n",
    " * Generate Python code to compute the value of PI using Ray distributed framework\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de3ad4ed-e28e-44a7-8a33-11136f6334d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a supreme CoPilot for developer. Given a task you can\n",
    "generate code for that task.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9a85173-dbce-4bf6-b004-7e368a5ccd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_code_prompt=\"\"\"Generate Python code to compute the value of PI using Ray \n",
    "distributed framework API. Use the Monte Carlo method to compute the value of PI.\n",
    "Include in-line comments explaining the code\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60e2b04a-9f0c-450f-aeda-8e6ece5b0a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is a Python script that uses the Ray distributed framework to compute the value of PI using the Monte Carlo method. The Monte Carlo method involves generating random points and determining the ratio of points that land inside a unit circle to the total number of points generated. This ratio is then used to estimate the value of PI.\n",
      "\n",
      "Make sure you have Ray installed in your Python environment before running this code. You can install Ray by running `pip install ray`.\n",
      "\n",
      "```python\n",
      "import ray\n",
      "import random\n",
      "import math\n",
      "\n",
      "# Initialize Ray. If you already have a Ray cluster running, you would connect to it instead.\n",
      "ray.init()\n",
      "\n",
      "# Define the Monte Carlo simulation function as a Ray remote function.\n",
      "@ray.remote\n",
      "def monte_carlo_pi_part(num_samples):\n",
      "    inside_circle = 0\n",
      "    for _ in range(num_samples):\n",
      "        # Generate a random point (x, y) where x and y are in the range [-1, 1].\n",
      "        x, y = random.uniform(-1, 1), random.uniform(-1, 1)\n",
      "        # Check if the point is inside the unit circle.\n",
      "        if x**2 + y**2 <= 1:\n",
      "            inside_circle += 1\n",
      "    # Return the number of points inside the circle.\n",
      "    return inside_circle\n",
      "\n",
      "# The total number of samples to use for the simulation.\n",
      "total_samples = 1000000\n",
      "# The number of parallel tasks to run. Adjust this based on the number of CPU cores you have.\n",
      "num_parallel_tasks = 4\n",
      "\n",
      "# Divide the total number of samples among the parallel tasks.\n",
      "samples_per_task = total_samples // num_parallel_tasks\n",
      "\n",
      "# Start the parallel tasks. Each task will run the simulation on its portion of samples.\n",
      "results = ray.get([monte_carlo_pi_part.remote(samples_per_task) for _ in range(num_parallel_tasks)])\n",
      "\n",
      "# Combine the results from all parallel tasks.\n",
      "total_inside_circle = sum(results)\n",
      "\n",
      "# Use the combined results to estimate PI.\n",
      "pi_estimate = (4.0 * total_inside_circle) / total_samples\n",
      "\n",
      "print(f\"Estimated value of PI: {pi_estimate}\")\n",
      "\n",
      "# Shutdown Ray.\n",
      "ray.shutdown()\n",
      "```\n",
      "\n",
      "To run this code, simply save it to a `.py` file and execute it with Python. The script initializes Ray, defines the Monte Carlo simulation as a remote function, distributes the work across multiple tasks, retrieves the results, computes the estimate of PI, and finally outputs the estimated value.\n",
      "\n",
      "Please note that the accuracy of the PI estimation will depend on the number of samples (`total_samples`). The more samples used, the more accurate the estimate will be, but it will also take more computation time. Adjust `num_parallel_tasks` according to the number of CPU cores you have available for better performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, python_code_prompt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "585f372c-fe37-43b4-9299-c5708d1be06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_code_prompt=\"\"\"Given the following SQL schema for tables\n",
    "Table clicks, columns = [target_url, orig_url, user_id, clicks]\n",
    "Table users, columns = [user_id, f_name, l_name, e_mail, company, title], generate\n",
    "an SQL query that computes in the descening order of all the clicks. Also, for\n",
    "each user_id, list the f_name, l_name, company, and title\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "351b78d7-c78b-4a1b-946b-8a2abd17efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! To achieve this, you will need to perform a join between the `clicks` and `users` tables to associate the click counts with the corresponding user information. Then, you'll want to use a GROUP BY clause with `user_id` to aggregate clicks per user and an ORDER BY clause to order the results in descending order of clicks.\n",
      "\n",
      "Here's the SQL query to perform this task:\n",
      "\n",
      "```sql\n",
      "SELECT\n",
      "    u.user_id,\n",
      "    u.f_name,\n",
      "    u.l_name,\n",
      "    u.company,\n",
      "    u.title,\n",
      "    SUM(c.clicks) AS total_clicks\n",
      "FROM\n",
      "    clicks c\n",
      "JOIN\n",
      "    users u ON c.user_id = u.user_id\n",
      "GROUP BY\n",
      "    u.user_id,\n",
      "    u.f_name,\n",
      "    u.l_name,\n",
      "    u.company,\n",
      "    u.title\n",
      "ORDER BY\n",
      "    total_clicks DESC;\n",
      "```\n",
      "\n",
      "This query will give you the total number of clicks for each user along with their first name, last name, company, and title, sorted in descending order of the number of clicks. The `SUM()` function calculates the total number of clicks per user, while `GROUP BY` ensures that the aggregation is done on a per-user basis. The `ORDER BY` clause then ensures the results are sorted from the user with the highest number of clicks to the lowest.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, sql_code_prompt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d546337d-b9a4-40db-92dd-8cdce63c6979",
   "metadata": {},
   "source": [
    "### All this is amazing! 😜 Feel the wizardy power "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
