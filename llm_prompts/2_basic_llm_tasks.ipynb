{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39330ca8-0778-405c-8d1f-2c31e190ebde",
   "metadata": {},
   "source": [
    "## Basic LLM Tasks\n",
    "In the *1_basic_prompt* notebook, we explored using prompts to query an LLM model. This notebook presents diverse examples to demonstrate various tasks and introduce key concepts, emphasizing effective learning through practical instances. The tasks explored in this notebook, using sophiscated prompting techniques, show *how-to* code examples for:\n",
    "\n",
    " * Text generation or completion\n",
    " * Text summarization\n",
    " * Entity name extraction\n",
    " * Text classification or sentiment analysis\n",
    " * Text categorization\n",
    " * Code generation\n",
    " * Simple and complex reasoning\n",
    "\n",
    "<img src=\"./images/prompt_req_resp.png\" height=\"35%\" width=\"%65\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "798bde8f-44a7-4e9f-ba30-0ffccd1d4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "249c0446-7d74-402b-b7a5-9ab6f1d59224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "warnings.filterwarnings('ignore')\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b45071b3-6e6e-497b-9126-ab592053d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8654cd8-fa3d-4d94-a7c9-37053a3434be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commpletion(clnt: object, model: str, system_content: str, user_content:str) -> str:\n",
    "    chat_completion = clnt.chat.completions.create(\n",
    "        model=model,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_content},\n",
    "              {\"role\": \"user\", \"content\": user_content}],\n",
    "    temperature = 0.8)\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f06061-ea86-4e09-b006-9a0c61f92e33",
   "metadata": {},
   "source": [
    "## Text generation or completion\n",
    "In this simple task, we use an LLM to generate text by finishing an incomplete user content provided in the prompt. For example,\n",
    "by providing an incomplete prompt such as \"On a cold winter night, the stray dog ...\". \n",
    "\n",
    "Let's try a few text generation or completion tasks by providing partial prompts in the user content. You will surprised at its\n",
    "fluency and coherency in the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07fbcbf8-0ccc-4fd4-a27d-a27c1ad14ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"You are master of all knowledge. You must complete any incomplete sentence by drawing from your \\\n",
    "                  knowledge about history, literature, science, philosophy, religion, economics, sports, etc. \\\n",
    "                  You will use simple, compound, and compound-complex sentences for all your responses, and no more than \\\n",
    "                  one paragraph and no more than five sentences. Keep them succinct and cohesive.\"\n",
    "\n",
    "user_prompts =  [\"On a cold winter night, the stray dog ...\",\n",
    "                 \"A week ago during the hottest week ...\",\n",
    "                 \"During the final World Cup 1998 when France beat Brazil in Paris, ...\",\n",
    "                 \"Issac Newton set under a tree when an apple fell...\"\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c39358d-f343-4596-bd28-5f36a3ba85d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "\n",
      "Prompt: On a cold winter night, the stray dog ...\n",
      "\n",
      "Answer: On a cold winter night, the stray dog found solace beneath the overhang of a closed storefront, its breath visible in the frosty air. Shivering, it curled up tightly, conserving warmth within its thin fur. Though the streets were mostly deserted, a kind passerby noticed the dog's plight and approached gently, offering a scrap of food and a soft pat on the head. The dog, initially wary, soon accepted the gesture, tail wagging with cautious optimism. This small act of kindness provided the animal with both physical sustenance and a momentary reprieve from its loneliness.\n",
      "\n",
      "Prompt: A week ago during the hottest week ...\n",
      "\n",
      "Answer: A week ago, during the hottest week of the year, many regions experienced record-breaking temperatures that strained power grids and prompted public health concerns. Authorities issued heat advisories and opened cooling centers to help vulnerable populations cope with the extreme conditions. In some areas, the intense heat led to wildfires, which further complicated emergency responses. Environmental experts pointed to the heatwave as an example of the effects of climate change. Communities were urged to stay hydrated, avoid strenuous outdoor activities, and check on neighbors, especially the elderly and those without air conditioning.\n",
      "\n",
      "Prompt: During the final World Cup 1998 when France beat Brazil in Paris, ...\n",
      "\n",
      "Answer: ...the host nation secured a resounding 3-0 victory, with Zinedine Zidane scoring two goals via headers from corner kicks in the first half, and Emmanuel Petit rounding off the scoring in injury time. The French team, led by captain Didier Deschamps, played with formidable skill and coordination, overwhelming the Brazilian side, which included the likes of Ronaldo, Rivaldo, and Bebeto. The victory led to widespread celebrations across France, as it marked the country's first FIFA World Cup win. The Stade de France, filled with nearly 80,000 spectators, became a cauldron of national pride and joy. This triumph is often seen as an iconic moment in French football history, symbolizing both sporting excellence and national unity.\n",
      "\n",
      "Prompt: Issac Newton set under a tree when an apple fell...\n",
      "\n",
      "Answer: Isaac Newton sat under a tree when an apple fell and supposedly hit him on the head, although this story is likely apocryphal or exaggerated. This event is said to have inspired his thoughts on gravity, leading him to formulate the universal law of gravitation. Newton's work on gravity was a part of his larger contribution to physics, detailed in his seminal work \"Philosophi√¶ Naturalis Principia Mathematica.\" He used mathematics to describe gravity, proposing that every mass attracts every other mass with a force that is proportional to the product of their masses and inversely proportional to the square of the distance between them. His laws of motion and universal gravitation became fundamental principles that dominated scientists' view of the physical universe for the next three centuries.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for user_prompt in user_prompts:\n",
    "    response = get_commpletion(client, MODEL, system_content, user_prompt)\n",
    "    print(f\"\\nPrompt: {user_prompt}\")\n",
    "    print(f\"\\nAnswer: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b3fa1-7073-4070-a39e-b62e52cad735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
