{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39330ca8-0778-405c-8d1f-2c31e190ebde",
   "metadata": {},
   "source": [
    "## Basic LLM Tasks\n",
    "In the [*1_basic_prompt*](./1_basic_prompt.ipynb) notebook, we explored  prompts to query an LLM model. This notebook goes a bit futher with diverse examples to demonstrate various tasks, emphasizing effective usage of prompt engineering through practical instances and using [CO-STAR prompt framework](https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41) for \n",
    "eliciting the best response from the LLM\n",
    "\n",
    "The tasks explored in this notebook, using sophiscated prompting techniques, show *how-to* code examples for common natural language understanfing capabilites of a generalized LLM, such as ChatGPT and Llama 2 series:\n",
    "\n",
    " * Text generation or completion\n",
    " * Text summarization\n",
    " * Text extraction\n",
    " * Text classification or sentiment analysis\n",
    " * Text categorization\n",
    " * Text transformation and translation\n",
    " * Simple and complex reasoning\n",
    "\n",
    "<img src=\"./images/prompt_req_resp.png\" height=\"35%\" width=\"%65\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798bde8f-44a7-4e9f-ba30-0ffccd1d4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d617225a-eb51-4d76-a324-bc1547759d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOLD_BEGIN = \"\\033[1m\"\n",
    "BOLD_END = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249c0446-7d74-402b-b7a5-9ab6f1d59224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=mistralai/Mistral-7B-Instruct-v0.1; base=https://console.endpoints.anyscale.com/m/v1\n"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "warnings.filterwarnings('ignore')\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45071b3-6e6e-497b-9126-ab592053d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b425c6a-fe00-4180-aab8-6250513713ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOLD_BEGIN = \"\\033[1m\"\n",
    "BOLD_END = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8654cd8-fa3d-4d94-a7c9-37053a3434be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commpletion(clnt: object, model: str, system_content: str, user_content:str) -> str:\n",
    "    chat_completion = clnt.chat.completions.create(\n",
    "        model=model,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_content},\n",
    "              {\"role\": \"user\", \"content\": user_content}],\n",
    "    temperature = 0.8)\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f06061-ea86-4e09-b006-9a0c61f92e33",
   "metadata": {},
   "source": [
    "## Text generation or completion\n",
    "In this simple task, we use an LLM to generate text by finishing an incomplete user content provided in the prompt. For example,\n",
    "by providing an incomplete prompt such as \"On a cold winter night, the stray dog ...\". \n",
    "\n",
    "Let's try a few text generation or completion tasks by providing partial prompts in the user content. You will surprised at its fluency and coherency in the generated text.\n",
    "\n",
    "For prompting, we use the C0-STAR framework.\n",
    "\n",
    "<img src=\"./images/co-star-framework.png\" height=\"35%\" width=\"%65\">\n",
    "\n",
    "\n",
    "**(C): Context: Provide background and information on the task**\n",
    "\n",
    "**(O): Objective: Define the task that you want the LLM to perform**\n",
    "\n",
    "**(S): Style: Specify the writing style you want the LLM to use**\n",
    "\n",
    "**(T): Set the attidue of the response**\n",
    "\n",
    "**(A): Audience: Idenfiy who the response is for**\n",
    "\n",
    "**(R): Provide the response format**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07fbcbf8-0ccc-4fd4-a27d-a27c1ad14ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are master of all knowledge, and a helpful sage.\n",
    "                    You must complete any incomplete sentence by drawing from your vast\n",
    "                    knowledge about history, literature, science, social science, philosophy, religion, economics, \n",
    "                    sports, etc. Do not make up any responses.\n",
    "                  \"\"\"\n",
    "\n",
    "user_prompts =  [\"On cold winter nights, the wolves in Siberia ...\",\n",
    "                 \"On the day Franklin Benjamin realized his passion for printer, ...\",\n",
    "                 \"During the final World Cup 1998 when France beat Brazil in Paris, ...\",\n",
    "                 \"Issac Newton set under a tree when an apple fell...\"\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c39358d-f343-4596-bd28-5f36a3ba85d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://console.endpoints.anyscale.com/m/v1 ...\n",
      "\n",
      "\n",
      "\u001b[1mPrompt:\u001b[0m On cold winter nights, the wolves in Siberia ...\n",
      "\n",
      "\u001b[1mAnswer:\u001b[0m  On cold winter nights, the wolves in Siberia can be heard howling in the distance, their haunting cries echoing across the frozen landscape. These creatures are one of the most fascinating and mysterious animals on the planet.\n",
      "\n",
      "In terms of their biology, wolves are mammals that belong to the canidae family, and are closely related to dogs, foxes, and other canines. They are highly social animals, living in packs that can range in size from just a few individuals to over a hundred wolves.\n",
      "\n",
      "Wolves are also known for their incredible hunting abilities, using their keen senses and teamwork to take down prey such as deer, bison, and even moose. They are also skilled at adapting to changing environments, and have been known to live in a variety of habitats, from the tundra to deserts to forests.\n",
      "\n",
      "Despite their fearsome reputation, wolves are also important members of their ecosystems. They play a crucial role in controlling populations of herbivores, and their presence helps to maintain the balance of the natural world.\n",
      "\n",
      "In terms of their cultural significance, wolves have been revered and feared by humans for thousands of years. In many indigenous cultures, wolves are seen as symbols of strength, courage, and power. They have also been used as hunting partners by nomadic tribes, and their hunting techniques have been passed down through generations.\n",
      "\n",
      "However, wolves have also faced significant threats in recent years, including habitat loss, poaching, and even being hunted for sport. These threats have led to a decline in wolf populations in many parts of the world, and conservation efforts are underway to protect these incredible animals and their habitats.\n",
      "\n",
      "In conclusion, wolves are fascinating and mysterious creatures that have played an important role in human history and culture. Their biology, hunting abilities, and cultural significance make them one of the most interesting animals on the planet. However, their survival is threatened by a variety of factors, and conservation efforts are needed to ensure their continued existence.'``\n",
      "\n",
      "\u001b[1mPrompt:\u001b[0m On the day Franklin Benjamin realized his passion for printer, ...\n",
      "\n",
      "\u001b[1mAnswer:\u001b[0m  On the day Franklin Benjamin realized his passion for printing, he was a young man with a thirst for knowledge and a desire to make a difference in the world. He had always been fascinated by the process of creating written materials and had spent hours observing printers at work. As he grew older, he decided to pursue a career in printing and began studying the craft in earnest.\n",
      "\n",
      "Through years of hard work and dedication, Franklin Benjamin became one of the most skilled printers of his time. He developed new and innovative printing techniques, and his work helped to shape the future of the printing industry. He also used his skills to make a positive impact on society, using his printing press to distribute important information and ideas that helped to shape the world.\n",
      "\n",
      "Franklin Benjamin's passion for printing was the driving force behind his many achievements and contributions to the world. His dedication to his craft and his commitment to making a difference in the world continue to inspire people today, and his legacy remains an important part of the history of printing.\n",
      "\n",
      "\u001b[1mPrompt:\u001b[0m During the final World Cup 1998 when France beat Brazil in Paris, ...\n",
      "\n",
      "\u001b[1mAnswer:\u001b[0m  During the final World Cup 1998, France emerged victorious over Brazil in a thrilling match held in Paris. France's team, led by the legendary coach Jacques Anquetil, featured some of the greatest players of the era, including Patrick Vieira, Didier Drogba, and Zinedine Zidane. Brazil, on the other hand, was led by the talented Ronaldo, who scored a hat-trick in the match.\n",
      "\n",
      "The match was memorable for several reasons, including the dramatic goal scored by France's Youri Djiméne in extra time, which was considered a classic moment in the history of the World Cup. The match was also notable for the strong performances of France's midfield, which was anchored by the incomparable Vieira.\n",
      "\n",
      "In terms of the broader context of the match, it was significant because it marked the end of an era for Brazil, who had won the previous four World Cups. France, on the other hand, was seen as a rising power in world football, and the victory over Brazil helped to solidify their reputation as a force to be reckoned with.\n",
      "\n",
      "Overall, the final World Cup 1998 was a classic match that will be remembered for generations to come, and it was a defining moment in the history of the World Cup.\n",
      "\n",
      "\u001b[1mPrompt:\u001b[0m Issac Newton set under a tree when an apple fell...\n",
      "\n",
      "\u001b[1mAnswer:\u001b[0m  Isaac Newton is widely regarded as one of the most influential scientists in history, having made groundbreaking contributions to the fields of physics and mathematics. His famous story of an apple falling from a tree inspiring his theory of gravity is well-known, but it is not the only explanation for how he came up with this revolutionary idea.\n",
      "\n",
      "In fact, Newton's work in mathematics and optics laid the groundwork for his theory of gravity, which was built upon the foundations of calculus. This mathematical tool allowed Newton to calculate the motion of planets and other celestial bodies, and it was the key to his understanding of the relationship between gravity and motion.\n",
      "\n",
      "In addition to his work in mathematics, Newton also made significant contributions to the field of optics. He discovered the laws of reflection and refraction, which allowed him to understand how light behaves as it passes through different mediums. This knowledge was crucial to his development of the telescope, which he used to study the heavens and make many of his most famous discoveries.\n",
      "\n",
      "Overall, Isaac Newton's legacy in science and mathematics cannot be overstated. His work laid the groundwork for many of the key concepts and ideas that we take for granted today, and his influence can still be felt in everything from the study of physics to the development of modern technology.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for user_prompt in user_prompts:\n",
    "    prompt = f\"\"\"\n",
    "    # CONTEXT #\n",
    "    I want to write a complete and cohesive paragpraph for \n",
    "    magazine: Things to know.\n",
    "\n",
    "    #############\n",
    "    \n",
    "    # OBJECTIVE #\n",
    "    Compete the text ```{user_prompt}``` between three backticks to the best \n",
    "    of your acquired knowledge.\n",
    "\n",
    "    #############\n",
    "\n",
    "    # STYLE #\n",
    "    You will use simple, compound, and compound-complex sentences for all your responses, \n",
    "    and no more than one paragraph and no more than five sentences.\n",
    "\n",
    "    Adhere to a litrary magazine writing style. Keep your sentences succinct and cohesive.\n",
    "\n",
    "    #############\n",
    "\n",
    "    # TONE #\n",
    "    Maintain an editorial tone.\n",
    "\n",
    "    #############\n",
    "\n",
    "    # AUDIENCE #\n",
    "    Our audience are generally curious first to second year college\n",
    "    students.\n",
    "\n",
    "    #############\n",
    "\n",
    "    # RESPONSE #\n",
    "    Finally, keep the response concise and succinct.\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    response = response.replace(\"```\", \"\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Prompt:{BOLD_END} {user_prompt}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Answer:{BOLD_END} {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e03d54-6200-4664-9a6d-13fe8297e0cb",
   "metadata": {},
   "source": [
    "## Text summarization\n",
    "\n",
    "A common task in natural langauge processing is text summiarization. A common use case\n",
    "is summarizing large articles or documents, for a quick and easy-to-absorb summaries.\n",
    "\n",
    "You can instruct LLM to generate the response in a preferable style, and comprehensibility. For example, use simple language aimed for a certain grade level, keep the orginal style of the article, use different sentence sytles (as we have done in few of examples in this notebook and previous one).\n",
    "\n",
    "Let's try a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85736577-b4ee-466e-90c8-a810849fe172",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are master of all knowledge about history, literature, science, philosophy, religion, \n",
    "                    economics, sports, etc. Respond to only answers\n",
    "                    you know of. Do not make up answers\"\"\" \n",
    "                \n",
    "user_prompts = [\n",
    "    \"\"\" The emergence of large language models (LLMs) has marked a significant \n",
    "         breakthrough in natural language processing (NLP), leading to remarkable \n",
    "         advancements in text understanding and generation. \n",
    "         \n",
    "         Nevertheless, alongside these strides, LLMs exhibit a critical tendency \n",
    "         to produce hallucinations, resulting in content that is inconsistent with \n",
    "         real-world facts or user inputs. This phenomenon poses substantial challenges \n",
    "         to their practical deployment and raises concerns over the reliability of LLMs \n",
    "         in real-world scenarios, which attracts increasing attention to detect and \n",
    "         mitigate these hallucinations. In this survey, we aim to provide a thorough and \n",
    "         in-depth  overview of recent advances in the field of LLM hallucinations. \n",
    "         \n",
    "         We begin with an innovative taxonomy of LLM hallucinations, then delve into the \n",
    "         factors contributing to hallucinations. Subsequently, we present a comprehensive\n",
    "         overview of hallucination detection methods and benchmarks. \n",
    "         Additionally, representative approaches designed to mitigate hallucinations \n",
    "         are introduced accordingly. \n",
    "         \n",
    "         Finally, we analyze the challenges that highlight the current limitations and \n",
    "         formulate open questions, aiming to delineate pathways for future  research on \n",
    "         hallucinations in LLMs.\"\"\",\n",
    "    \"\"\"  Can a Large Language Model (LLM) solve simple abstract reasoning problems?\n",
    "         We explore this broad question through a systematic analysis of GPT on the \n",
    "         Abstraction and Reasoning Corpus (ARC), a representative benchmark of abstract \n",
    "         reasoning ability from limited examples in which solutions require some \n",
    "         \"core knowledge\" of concepts such as objects, goal states, counting, and \n",
    "         basic geometry. GPT-4 solves only 13/50 of the most straightforward ARC \n",
    "         tasks when using textual encodings for their two-dimensional input-output grids. \n",
    "         Our failure analysis reveals that GPT-4's capacity to identify objects and \n",
    "         reason about them is significantly influenced by the sequential nature of \n",
    "         the text that represents an object within a text encoding of a task. \n",
    "         To test this hypothesis, we design a new benchmark, the 1D-ARC, which \n",
    "         consists of one-dimensional (array-like) tasks that are more conducive \n",
    "         to GPT-based reasoning, and where it indeed performs better than on \n",
    "         the (2D) ARC. To alleviate this issue, we propose an object-based \n",
    "         representation that is obtained through an external tool, resulting in \n",
    "         nearly doubling the performance on solved ARC tasks and near-perfect scores \n",
    "         on the easier 1D-ARC. Although the state-of-the-art GPT-4 is unable to \n",
    "         \"reason\" perfectly within non-language domains such as the 1D-ARC or a \n",
    "         simple ARC subset, our study reveals that the use of object-based representations \n",
    "         can significantly improve its reasoning ability. Visualizations, GPT logs, and \n",
    "         data are available at this https URL.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a884cb94-0c4a-40bc-a847-1d5eb354cafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://console.endpoints.anyscale.com/m/v1 ...\n",
      "\n",
      "\n",
      "\u001b[1mOriginal content:\u001b[0m  The emergence of large language models (LLMs) has marked a significant \n",
      "         breakthrough in natural language processing (NLP), leading to remarkable \n",
      "         advancements in text understanding and generation. \n",
      "         \n",
      "         Nevertheless, alongside these strides, LLMs exhibit a critical tendency \n",
      "         to produce hallucinations, resulting in content that is inconsistent with \n",
      "         real-world facts or user inputs. This phenomenon poses substantial challenges \n",
      "         to their practical deployment and raises concerns over the reliability of LLMs \n",
      "         in real-world scenarios, which attracts increasing attention to detect and \n",
      "         mitigate these hallucinations. In this survey, we aim to provide a thorough and \n",
      "         in-depth  overview of recent advances in the field of LLM hallucinations. \n",
      "         \n",
      "         We begin with an innovative taxonomy of LLM hallucinations, then delve into the \n",
      "         factors contributing to hallucinations. Subsequently, we present a comprehensive\n",
      "         overview of hallucination detection methods and benchmarks. \n",
      "         Additionally, representative approaches designed to mitigate hallucinations \n",
      "         are introduced accordingly. \n",
      "         \n",
      "         Finally, we analyze the challenges that highlight the current limitations and \n",
      "         formulate open questions, aiming to delineate pathways for future  research on \n",
      "         hallucinations in LLMs.\n",
      "\n",
      "\u001b[1mSummary  content:\u001b[0m  The emergence of large language models (LLMs) has marked a significant breakthrough in natural language processing (NLP), leading to remarkable advancements in text understanding and generation. However, alongside these strides, LLMs exhibit a critical tendency to produce hallucinations, resulting in content that is inconsistent with real-world facts or user inputs. This phenomenon poses substantial challenges to their practical deployment and raises concerns over the reliability of LLMs in real-world scenarios, which attracts increasing attention to detect and mitigate these hallucinations. This survey aims to provide a thorough and in-depth overview of recent advances in the field of LLM hallucinations.\n",
      "\n",
      "Firstly, an innovative taxonomy of LLM hallucinations is presented, which categorizes them into multiple forms, such as factual, semantic, and syntactic hallucinations. Factual hallucinations occur when LLMs generate incorrect or invalid information, while semantic hallucinations result in meaningless or irrelevant content. Syntactic hallucinations, on the other hand, refer to the generation of grammatically correct but semantically incorrect sentences.\n",
      "\n",
      "Secondly, the factors contributing to hallucinations are analyzed, such as the quality and quantity of training data, the model architecture, and the optimizer used. It is found that the use of smaller training datasets and less complex model architectures can help reduce the likelihood of hallucinations.\n",
      "\n",
      "Thirdly, a comprehensive overview of hallucination detection methods and benchmarks is presented, such as fact checking, debiasing, and language modeling. Fact checking involves verifying the accuracy of the generated content, while debiasing aims to reduce the influence of biased language or stereotypes. Language modeling, on the other hand, utilizes statistical models to predict the likelihood of a generated sentence being factually correct.\n",
      "\n",
      "Finally, representative approaches designed to mitigate hallucinations are introduced, such as data augmentation, model retraining, and the use of ensemble models. Data augmentation involves generating synthetic data to augment the training dataset, while model retraining involves retraining the model with a larger, more diverse dataset. The use of ensemble models combines the predictions of multiple LLMs to produce more accurate and reliable outputs.\n",
      "\n",
      "In conclusion, LLM hallucinations pose significant challenges to the practical deployment and reliability of LLMs in real-world scenarios. However, recent advances in the field have provided innovative taxonomies, detection methods, and mitigation approaches to address these challenges. Future research should focus on developing more accurate and reliable LLMs through the use of larger and more diverse training datasets and more complex model architectures.\n",
      "\n",
      "\u001b[1mOriginal content:\u001b[0m   Can a Large Language Model (LLM) solve simple abstract reasoning problems?\n",
      "         We explore this broad question through a systematic analysis of GPT on the \n",
      "         Abstraction and Reasoning Corpus (ARC), a representative benchmark of abstract \n",
      "         reasoning ability from limited examples in which solutions require some \n",
      "         \"core knowledge\" of concepts such as objects, goal states, counting, and \n",
      "         basic geometry. GPT-4 solves only 13/50 of the most straightforward ARC \n",
      "         tasks when using textual encodings for their two-dimensional input-output grids. \n",
      "         Our failure analysis reveals that GPT-4's capacity to identify objects and \n",
      "         reason about them is significantly influenced by the sequential nature of \n",
      "         the text that represents an object within a text encoding of a task. \n",
      "         To test this hypothesis, we design a new benchmark, the 1D-ARC, which \n",
      "         consists of one-dimensional (array-like) tasks that are more conducive \n",
      "         to GPT-based reasoning, and where it indeed performs better than on \n",
      "         the (2D) ARC. To alleviate this issue, we propose an object-based \n",
      "         representation that is obtained through an external tool, resulting in \n",
      "         nearly doubling the performance on solved ARC tasks and near-perfect scores \n",
      "         on the easier 1D-ARC. Although the state-of-the-art GPT-4 is unable to \n",
      "         \"reason\" perfectly within non-language domains such as the 1D-ARC or a \n",
      "         simple ARC subset, our study reveals that the use of object-based representations \n",
      "         can significantly improve its reasoning ability. Visualizations, GPT logs, and \n",
      "         data are available at this https URL.\n",
      "\n",
      "\u001b[1mSummary  content:\u001b[0m  In recent research, it was found that a Large Language Model (LLM) may struggle with simple abstract reasoning problems, even with limited examples. The study used the Abstraction and Reasoning Corpus (ARC) to benchmark the LLM's ability to reason about concepts such as objects, goal states, counting, and basic geometry. The study found that the LLM's capacity to identify objects and reason about them was significantly influenced by the sequential nature of the text that represented an object within the task. To address this issue, a new benchmark, the 1D-ARC, was designed, which consisted of one-dimensional tasks that are more conducive to GPT-based reasoning. Furthermore, an object-based representation was proposed, which significantly improved the LLM's reasoning ability. Despite the limitations of the study, the results revealed that the use of object-based representations could significantly enhance the LLM's reasoning ability, even in non-language domains.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for user_prompt in user_prompts:\n",
    "    prompt = f\"\"\"\n",
    "\n",
    "    # CONTEXT #\n",
    "    I want to write a summarize cohesively into at most two paragpraphs for \n",
    "    my magazine: Things to know quickly\n",
    "\n",
    "    #############\n",
    "    \n",
    "    # OBJECTIVE #\n",
    "    Summarize the text ```{user_prompt}``` between three backticks to the best \n",
    "    of your acquired knowledge.\n",
    "\n",
    "     #############\n",
    "\n",
    "    # STYLE #\n",
    "    You will use simple, compound, and compound-complex sentences for all your responses, \n",
    "    and no more than one paragraph and no more than five sentences.\n",
    "\n",
    "    Adhere to a litrary magazine writing style. Keep your sentences succinct and cohesive.\n",
    "\n",
    "    # TONE #\n",
    "    Maintain the same tone as the text supplied.\n",
    "\n",
    "    #############\n",
    "\n",
    "    # AUDIENCE #\n",
    "    Our audience are generally curious first to second year college\n",
    "    students.\n",
    "\n",
    "    #############\n",
    "\n",
    "     # RESPONSE #\n",
    "    Finally, keep the response concise and succinct\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Original content:{BOLD_END} {user_prompt}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Summary  content:{BOLD_END} {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affe9c30-bf89-49ee-80c8-c5d260b91914",
   "metadata": {},
   "source": [
    "## Text or information extraction\n",
    "\n",
    "Another natural langauge capability, similar to summarization or text completion, is extracting key idea or infromation from an article, blog, or a paragraph. For example,\n",
    "given a set of text, you can ask LLM to extract key ideas or topics or subjects. Or even\n",
    "better enumerate key takeways for you, saving time if you are in a hurry.\n",
    "\n",
    "Let's see *how-to* do it by first looking at a simple example, and then progressing into a more complex one, all along keepin \n",
    "the [CO-STAR prompting framework](https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41) in mind.\n",
    "\n",
    "### Task 1: \n",
    " * summarize the product review\n",
    " * extract any information about shipping and packaging for shipping department\n",
    " * classify the sentiment of the review: positive or negative.\n",
    " * use precise, specific prompt to acheive the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21406dcc-e9b1-4028-8281-297ae762b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are master of all knowledge about history, literature, science, social science, \n",
    "philosophy, religion, economics, sports, etc.\n",
    "\"\"\"\n",
    "\n",
    "product_review = \"\"\"I got this Australian Bush Baby with soft fur for my niece's birthday,\n",
    "and she absolutely loves it, carrying it around everywhere. The fur is exceptionally soft,\n",
    "and its adorable face gives off a friendly vibe. While I find it a bit smaller than \n",
    "anticipated for the price, my niece's joy makes it worthwhile. What pleasantly surprised \n",
    "me was the early arrival; it came a day earlier than expected. \n",
    "I appreciated the prompt delivery, and the packaging was secure, ensuring the \n",
    "Bush Baby with soft fur arrived in perfect condition. This allowed me to play with \n",
    "it myself before presenting it to my niece.\n",
    "\"\"\"     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "384515f8-a970-421a-86bb-be3ea8800bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "# CONTEXT #\n",
    "In our customer service department, we value customer feedback and want to\n",
    "analyze their reviews by summarizing their review assessing, labeling or categorizing\n",
    "and its idenfitying its sentiment. \n",
    "\n",
    "#############\n",
    "\n",
    "# OBJECTIVE #\n",
    "Your task is to generate a short summary of a product \n",
    "review from an Australian e-commerce site to offer feedback to the \n",
    "shipping deparmtment. Follow the steps below:\n",
    "\n",
    "First, generate a short summary of review below, delimited by triple \n",
    "backticks, in two sentences: a simple and compound sentence. \n",
    "\n",
    "Second, focus on any aspects of packaging or shipping of the product, and label it as \n",
    "\"Shipping Department:\".  \n",
    "\n",
    "Third, indicate if the review is positive or negative, and label it as \"Sentiment:\".\n",
    "Do not provide any preamble, only a simple two words: Positive or negative\n",
    "Review: ```{product_review}``` \n",
    "\n",
    "#############\n",
    "\n",
    "# STYLE #\n",
    "You will use simple, compound, and compound-complex sentences for all your responses, \n",
    "and no more than one paragraph and no more than five sentences.\n",
    "\n",
    "#############\n",
    "\n",
    "# TONE #\n",
    "Maintain a professional tone for internal communications\n",
    "\n",
    "#############\n",
    "\n",
    " # AUDIENCE #\n",
    "Our audience are internal departments in customer success to ensure we can\n",
    "improve our customer service\n",
    "\n",
    "#############\n",
    "\n",
    "# RESPONSE #\n",
    "Finally, keep the response concise and succinct\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0056f55-c3aa-4a4e-bd11-fec330436af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://console.endpoints.anyscale.com/m/v1 ...\n",
      "\n",
      "\n",
      "\u001b[1mSummary:\u001b[0m  `\n",
      "Summary: This product is an Australian Bush Baby with soft fur that the reviewer purchased for their niece's birthday. The niece loves the toy and carries it around everywhere. The fur is exceptionally soft, and the adorable face gives off a friendly vibe. While the reviewer finds the size slightly smaller than anticipated for the price, the niece's joy makes it worthwhile. The product arrived early and was securely packaged, allowing the reviewer to play with it before presenting it to their niece.\n",
      "\n",
      "Shipping Department: The product arrived early and was securely packaged.\n",
      "\n",
      "Sentiment: Positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "print(f\"\"\"\\n{BOLD_BEGIN}Summary:{BOLD_END} {response.replace(\"```\", \"\")}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb0d62-e2a7-4669-9792-57f20ed95980",
   "metadata": {},
   "source": [
    "### Task 2\n",
    " * Given a passage from an article, extract the main theme of the passage and label it as the `Subjects`, if more than one, separated by comma.\n",
    " * Identify three key takeways and enumerate them in simple sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3cdcd4d4-62c7-4dea-b98a-58070552c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"You are master of all knowledge about history, literature, science, social science, philosophy, religion, economics, sports, etc.\"\n",
    "            \n",
    "user_prompts = [\"\"\"Isaac Newton sat under a tree when an apple fell, an event that, \n",
    "                according to popular legend, led to his contemplation of the forces\n",
    "                of gravity. Although this story is often regarded as apocryphal or at \n",
    "                least exaggerated, it serves as a powerful symbol of Newton's insight \n",
    "                into the universal law that governs celestial and earthly bodies alike. \n",
    "                His formulation of the law of universal gravitation was revolutionary, \n",
    "                as it provided a mathematical explanation for both the motion of planets \n",
    "                and the phenomena observed on Earth. Newton's work in physics, captured \n",
    "                in his seminal work Philosophiæ Naturalis Principia Mathematica, laid the \n",
    "                groundwork for classical mechanics. His influence extended beyond his own \n",
    "                time, shaping the course of scientific inquiry for centuries to come.\n",
    "                \"\"\"\n",
    "               ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7e16e2f-14ec-4bfd-9687-294683ad5c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://console.endpoints.anyscale.com/m/v1 ...\n",
      "\n",
      "\n",
      "\u001b[1mOriginal content:\u001b[0m Isaac Newton sat under a tree when an apple fell, an event that, \n",
      "                according to popular legend, led to his contemplation of the forces\n",
      "                of gravity. Although this story is often regarded as apocryphal or at \n",
      "                least exaggerated, it serves as a powerful symbol of Newton's insight \n",
      "                into the universal law that governs celestial and earthly bodies alike. \n",
      "                His formulation of the law of universal gravitation was revolutionary, \n",
      "                as it provided a mathematical explanation for both the motion of planets \n",
      "                and the phenomena observed on Earth. Newton's work in physics, captured \n",
      "                in his seminal work Philosophiæ Naturalis Principia Mathematica, laid the \n",
      "                groundwork for classical mechanics. His influence extended beyond his own \n",
      "                time, shaping the course of scientific inquiry for centuries to come.\n",
      "                \n",
      "\n",
      " \u001b[1mExtracted answers: \u001b[0m  Subject: Isaac Newton's Law of Universal Gravitation\n",
      "\n",
      "Takeaways:\n",
      "\n",
      "1. The story of Newton sitting under a tree and contemplating gravity after an apple fell is a popular legend that symbolizes his insight into the universal law of gravity.\n",
      "2. Newton's formulation of the law of universal gravitation was revolutionary, providing a mathematical explanation for the motion of planets and phenomena observed on Earth.\n",
      "3. His work in physics, captured in his seminal work Philosophiæ Naturalis Principia Mathematica, laid the groundwork for classical mechanics and influenced scientific inquiry for centuries to come.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for text in user_prompts:\n",
    "    prompt = f\"\"\" Given ```{text}``` delimited with triple backticks, identify a single key idea being discussed, \n",
    "    and label its 'Subject'. Next, enumerate at most three takeways. \n",
    "    Use short, simple sentences. \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Original content:{BOLD_END} {text}\")\n",
    "    print(f\"\\n {BOLD_BEGIN}Extracted answers: {BOLD_END} {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113abb50-6a73-4101-8846-e8f26d85bb9c",
   "metadata": {},
   "source": [
    "Let's try another example to extract more than one subject or topic being\n",
    "discussed in the text, and enumerate three takeways.\n",
    "\n",
    "(Incidentally, I'm reading biography of Benjamin Franklin by Issac Stevenson, and all this seems to align with his career path and passion.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f34ceebf-c1b6-495b-8c78-81d2fc45baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stories = [\"\"\"\"\n",
    "'The Printer'\n",
    "    He that has a Trade has an Office of Profit and Honour’ Poor Richard’s Almanack\n",
    "Benjamin Franklin had an affinity with print and books throughout his life. \n",
    "Apprenticed as a child to his brother James, a printer, he mastered all aspects of\n",
    "the trade, from typesetting to engraving, learning the latest techniques during his\n",
    "first visit to London.  An avid reader, Franklin saved money to buy books by \n",
    "temporarily turning vegetarian and, once settled in Philadelphia, founded the \n",
    "Library Company, the first subscription library in the colonies.  As an elder\n",
    "statesman, he even bought type and kept a press during his stay in France. \n",
    "After working as a printer’s journeyman, he set up his own Philadelphian printing \n",
    "office in 1728.  His success with the Pennslyannia Gazette and Poor Richard’s\n",
    "Almanack helped to provide Franklin with the financial means to retire from\n",
    "business, retaining a stake in his print shop and founding others throughout the \n",
    "colonies.  Print also gave him a public voice: Franklin preferred the printed word, \n",
    "rather than public rhetoric, influencing political and public opinion as a brilliant\n",
    "journalist and pamphleteer.\n",
    "\n",
    "'Silence Dogood and the New­England Courant'\n",
    "    When James Franklin lost the contract to print the Boston Gazette, he determined\n",
    "to begin his own newspaper, launching the New­England Courant in 1721.\n",
    "Benjamin, who had been indentured secretly to James, helped to print the weekly \n",
    "paper.  One night he slipped a composition under the door, beginning the series\n",
    "of ‘Silence Dogood’ letters, the purported epistles of a vocal widower, with strong \n",
    "opinions on drunks, clergymen, foolish fashions and Boston nightlife. Owing no\n",
    "little debt to the satire of the London Spectator, the letters represented a \n",
    "remarkable literary achievement for the 16­year old.  The British Library’s copy has \n",
    "been uniquely annotated in what appears to be Franklin’s hand. The first \n",
    "‘Dogood’ letter appears on the bottom right.\n",
    "\n",
    "‘The Main Design of the Weekly Paper will be to Entertain the Town’\n",
    "    Benjamin’s brother, James, began the New­England Courant in the face of\n",
    "opposition from the Boston Establishment.  He soon irritated them with his squibs\n",
    "and satires on the great and the good, attacking the influential clergyman Cotton\n",
    "Mather’s pet project of small pox inoculation and the authorities’ weak response \n",
    "to piracy. Twice arrested, James temporally left the paper in Benjamin’s hands, and \n",
    "then continued to publish it under Benjamin’s name to escape a ban on\n",
    "publication.  This issue is the first printed item to carry the imprint ‘B. Franklin’ (on\n",
    "the rear).  Franklin announces his intention to ‘Entertain the Town’ on this page.\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1909a1b5-68fa-449c-9d40-0d4494b75b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://console.endpoints.anyscale.com/m/v1 ...\n",
      "\n",
      "\n",
      "\u001b[1mOriginal Story:\u001b[0m \"\n",
      "'The Printer'\n",
      "    He that has a Trade has an Office of Profit and Honour’ Poor Richard’s Almanack\n",
      "Benjamin Franklin had an affinity with print and books throughout his life. \n",
      "Apprenticed as a child to his brother James, a printer, he mastered all aspects of\n",
      "the trade, from typesetting to engraving, learning the latest techniques during his\n",
      "first visit to London.  An avid reader, Franklin saved money to buy books by \n",
      "temporarily turning vegetarian and, once settled in Philadelphia, founded the \n",
      "Library Company, the first subscription library in the colonies.  As an elder\n",
      "statesman, he even bought type and kept a press during his stay in France. \n",
      "After working as a printer’s journeyman, he set up his own Philadelphian printing \n",
      "office in 1728.  His success with the Pennslyannia Gazette and Poor Richard’s\n",
      "Almanack helped to provide Franklin with the financial means to retire from\n",
      "business, retaining a stake in his print shop and founding others throughout the \n",
      "colonies.  Print also gave him a public voice: Franklin preferred the printed word, \n",
      "rather than public rhetoric, influencing political and public opinion as a brilliant\n",
      "journalist and pamphleteer.\n",
      "\n",
      "'Silence Dogood and the New­England Courant'\n",
      "    When James Franklin lost the contract to print the Boston Gazette, he determined\n",
      "to begin his own newspaper, launching the New­England Courant in 1721.\n",
      "Benjamin, who had been indentured secretly to James, helped to print the weekly \n",
      "paper.  One night he slipped a composition under the door, beginning the series\n",
      "of ‘Silence Dogood’ letters, the purported epistles of a vocal widower, with strong \n",
      "opinions on drunks, clergymen, foolish fashions and Boston nightlife. Owing no\n",
      "little debt to the satire of the London Spectator, the letters represented a \n",
      "remarkable literary achievement for the 16­year old.  The British Library’s copy has \n",
      "been uniquely annotated in what appears to be Franklin’s hand. The first \n",
      "‘Dogood’ letter appears on the bottom right.\n",
      "\n",
      "‘The Main Design of the Weekly Paper will be to Entertain the Town’\n",
      "    Benjamin’s brother, James, began the New­England Courant in the face of\n",
      "opposition from the Boston Establishment.  He soon irritated them with his squibs\n",
      "and satires on the great and the good, attacking the influential clergyman Cotton\n",
      "Mather’s pet project of small pox inoculation and the authorities’ weak response \n",
      "to piracy. Twice arrested, James temporally left the paper in Benjamin’s hands, and \n",
      "then continued to publish it under Benjamin’s name to escape a ban on\n",
      "publication.  This issue is the first printed item to carry the imprint ‘B. Franklin’ (on\n",
      "the rear).  Franklin announces his intention to ‘Entertain the Town’ on this page.\n",
      "\n",
      "\n",
      " \u001b[1mExtracted entities:\u001b[0m  Subjects:\n",
      "\t1. Print and Books\n",
      "\t2. Benjamin Franklin\n",
      "\t3. Newspapers\n",
      "\t4. Satire\n",
      "\t5. Printing\n",
      "\n",
      "Takeaways:\n",
      "\t1. Franklin was involved in the printing industry throughout his life and helped establish the first subscription library in the colonies.\n",
      "\t2. The New England Courant, a newspaper founded by James Franklin, was a significant event in the development of the American press.\n",
      "\t3. The satirical letters \"Silence Dogood\" were a remarkable literary achievement for a 16-year old and helped establish Franklin's reputation as a brilliant journalist and pamphleteer.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for story in user_stories:\n",
    "    prompt = f\"\"\" Extract five subjects that are being discussed in the \n",
    "                  following text, which is delimited by triple backticks.\n",
    "                  Format your response as a list of subjects \n",
    "                  \"Subjects:\" separate each subject by a comma.\n",
    "                  Make each subject at most two words long, not longer. \n",
    "                  Next, enumerate  as a list three takeways, and label them as \"Takeways:\" \n",
    "                  Use short, simple sentences for your takeways.\n",
    "                  Text sample: '''{story}'''\n",
    "                  \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Original Story:{BOLD_END} {story}\")\n",
    "    print(f\"\\n {BOLD_BEGIN}Extracted entities:{BOLD_END} {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08da3189-e9d0-42c9-9f70-d403df9e0dc5",
   "metadata": {},
   "source": [
    "## Text classification or sentiment analysis\n",
    "\n",
    "Unlike classical or traditional machine learning, where you'll have to do supervised learning to collect data, label it, and train for hours, depending on how much data,classifying text using LLM is simple.\n",
    "\n",
    "In short, you'll have to build an ML model to understand text and classify its sentiments as positive, negative or neutral. \n",
    "\n",
    "This onus task is easily done with LLM via clever prompting. \n",
    "\n",
    "Let's see what I mean in this *how-to* idenfity sentiments in text. But first let's \n",
    "generatre some sentiments as our ground truth, and supply them to LLM to observe if\n",
    "LLM identifies them correctly. This bit is not needed, for I'm just curious.\n",
    "\n",
    "*Positive*: \"This movie is a true cinematic gem, blending an engaging plot with superb performances and stunning visuals. A masterpiece that leaves a lasting impression.\"\n",
    "\n",
    "*Negative*: \"Regrettably, the film failed to live up to expectations, with a convoluted storyline, lackluster acting, and uninspiring cinematography. A disappointment overall.\"\n",
    "\n",
    "*Neutral*: \"The movie had its moments, offering a decent storyline and average performances. While not groundbreaking, it provided an enjoyable viewing experience.\"\n",
    "\n",
    "*Positive*: \"This city is a vibrant tapestry of culture, with friendly locals, historic landmarks, and a lively atmosphere. An ideal destination for cultural exploration.\"\n",
    "\n",
    "*Negative*: \"The city's charm is overshadowed by traffic congestion, high pollution levels, and a lack of cleanliness. Not recommended for a peaceful retreat.\"\n",
    "\n",
    "*Neutral*: \"The city offers a mix of experiences, from bustling markets to serene parks. An interesting but not extraordinary destination for exploration.\"\n",
    "\n",
    "*Positive*: \"This song is a musical masterpiece, enchanting listeners with its soulful lyrics, mesmerizing melody, and exceptional vocals. A timeless classic.\"\n",
    "\n",
    "*Negative*: \"The song fails to impress, featuring uninspiring lyrics, a forgettable melody, and lackluster vocals. It lacks the creativity to leave a lasting impact.\"\n",
    "\n",
    "*Neutral*: \"The song is decent, with a catchy tune and average lyrics. While enjoyable, it doesn't stand out in the vast landscape of music.\"\n",
    "\n",
    "*Positive*: \"A delightful cinematic experience that seamlessly weaves together a compelling narrative, strong character development, and breathtaking visuals.\"\n",
    "\n",
    "*Negative*: \"This film, unfortunately, falls short with a disjointed plot, subpar performances, and a lack of coherence. A disappointing viewing experience.\"\n",
    "\n",
    "*Neutral*: \"While not groundbreaking, the movie offers a decent storyline and competent performances, providing an overall satisfactory viewing experience.\"\n",
    "\n",
    "*Positive*: \"This city is a haven for culture enthusiasts, boasting historical landmarks, a rich culinary scene, and a welcoming community. A must-visit destination.\"\n",
    "\n",
    "*Negative*: \"The city's appeal is tarnished by overcrowded streets, noise pollution, and a lack of urban planning. Not recommended for a tranquil getaway.\"\n",
    "\n",
    "*Neutral*: \"The city offers a diverse range of experiences, from bustling markets to serene parks. An intriguing destination for those seeking a mix of urban and natural landscapes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "26fba25e-e40b-40fc-84b5-0a86df748b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a prominent critic of landscapes, architecture, cities, movies, songs, \n",
    "                    entertainment, and a cultural ombudsman. \"\"\"\n",
    "\n",
    "user_sentiments = [ \"This movie is a true cinematic gem, blending an engaging plot with superb performances and stunning visuals. A masterpiece that leaves a lasting impression.\",\n",
    "                    \"Regrettably, the film failed to live up to expectations, with a convoluted storyline, lackluster acting, and uninspiring cinematography. A disappointment overall.\",\n",
    "                    \"The movie had its moments, offering a decent storyline and average performances. While not groundbreaking, it provided an enjoyable viewing experience.\",\n",
    "                    \"This city is a vibrant tapestry of culture, with friendly locals, historic landmarks, and a lively atmosphere. An ideal destination for cultural exploration.\",\n",
    "                    \"The city's charm is overshadowed by traffic congestion, high pollution levels, and a lack of cleanliness. Not recommended for a peaceful retreat.\",\n",
    "                    \"The city offers a mix of experiences, from bustling markets to serene parks. An interesting but not extraordinary destination for exploration.\",\n",
    "                    \"This song is a musical masterpiece, enchanting listeners with its soulful lyrics, mesmerizing melody, and exceptional vocals. A timeless classic.\",\n",
    "                    \"The song fails to impress, featuring uninspiring lyrics, a forgettable melody, and lackluster vocals. It lacks the creativity to leave a lasting impact.\",\n",
    "                    \"The song is decent, with a catchy tune and average lyrics. While enjoyable, it doesn't stand out in the vast landscape of music.\",\n",
    "                    \"A delightful cinematic experience that seamlessly weaves together a compelling narrative, strong character development, and breathtaking visuals.\",\n",
    "                    \"This film, unfortunately, falls short with a disjointed plot, subpar performances, and a lack of coherence. A disappointing viewing experience.\",\n",
    "                    \"While not groundbreaking, the movie offers a decent storyline and competent performances, providing an overall satisfactory viewing experience.\",\n",
    "                    \"This city is a haven for culture enthusiasts, boasting historical landmarks, a rich culinary scene, and a welcoming community. A must-visit destination.\",\n",
    "                    \"The city's appeal is tarnished by overcrowded streets, noise pollution, and a lack of urban planning. Not recommended for a tranquil getaway.\",\n",
    "                    \"The city offers a diverse range of experiences, from bustling markets to serene parks. An intriguing destination for those seeking a mix of urban and natural landscapes.\",\n",
    "                    \"xxxyyyzzz was curious and dubious\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4bae549c-fa32-46e8-af19-83f923222e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://console.endpoints.anyscale.com/m/v1 ...\n",
      "\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m This movie is a true cinematic gem, blending an engaging plot with superb performances and stunning visuals. A masterpiece that leaves a lasting impression.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m  positive\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m Regrettably, the film failed to live up to expectations, with a convoluted storyline, lackluster acting, and uninspiring cinematography. A disappointment overall.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m  Negative\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m The movie had its moments, offering a decent storyline and average performances. While not groundbreaking, it provided an enjoyable viewing experience.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m  neutral\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m This city is a vibrant tapestry of culture, with friendly locals, historic landmarks, and a lively atmosphere. An ideal destination for cultural exploration.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m  positive\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m The city's charm is overshadowed by traffic congestion, high pollution levels, and a lack of cleanliness. Not recommended for a peaceful retreat.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m  negative\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m The city offers a mix of experiences, from bustling markets to serene parks. An interesting but not extraordinary destination for exploration.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m  neutral\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m This song is a musical masterpiece, enchanting listeners with its soulful lyrics, mesmerizing melody, and exceptional vocals. A timeless classic.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m  positive\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m The song fails to impress, featuring uninspiring lyrics, a forgettable melody, and lackluster vocals. It lacks the creativity to leave a lasting impact.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m  negative\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m The song is decent, with a catchy tune and average lyrics. While enjoyable, it doesn't stand out in the vast landscape of music.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m  neutral\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m A delightful cinematic experience that seamlessly weaves together a compelling narrative, strong character development, and breathtaking visuals.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m  Positive.\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m This film, unfortunately, falls short with a disjointed plot, subpar performances, and a lack of coherence. A disappointing viewing experience.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m  negative\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m While not groundbreaking, the movie offers a decent storyline and competent performances, providing an overall satisfactory viewing experience.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m  Positive\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m This city is a haven for culture enthusiasts, boasting historical landmarks, a rich culinary scene, and a welcoming community. A must-visit destination.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m  positive\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m The city's appeal is tarnished by overcrowded streets, noise pollution, and a lack of urban planning. Not recommended for a tranquil getaway.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m  negative.\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m The city offers a diverse range of experiences, from bustling markets to serene parks. An intriguing destination for those seeking a mix of urban and natural landscapes.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m  positive\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m xxxyyyzzz was curious and dubious\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m  Negative\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for user_sentiment in user_sentiments:\n",
    "    prompt = f\"\"\"Classify the sentiment in the ```{user_sentiment}`` which is delimited \n",
    "        with triple backticks? Classify the given text into single label as \n",
    "        neutral, negative or positive. Do not expand on your response. \n",
    "        Use single words: positive, negative, neutral\n",
    "        If you cannot classify do not guess, do not ask for more info,\n",
    "        just classify as NA.\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Sentiment:{BOLD_END} {user_sentiment}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Label    :{BOLD_END} {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f520fec-af04-4b97-8e66-3187e34b5566",
   "metadata": {},
   "source": [
    "## Text categorization\n",
    "Like sentiment analysis, given a query, an LLM can identify from its context how to classify and route customer queries to respective departments. Also, note that LLM can detect foul language and respond politely. Text categorization can be employed to automate customer on-line queries.\n",
    "\n",
    "Let's look at how we can achieve that with smart and deliberate prompting.\n",
    "\n",
    "<img src=\"./images/category_resp.png\" height=\"35%\" width=\"%65\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "75b9307f-a2b3-4393-8e5a-5d7af520ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a smart and helful Assistant who can route customer queries to \n",
    "                    respective customer service departments.\n",
    "                    \"\"\"\n",
    "\n",
    "customer_queries = [\"\"\"My modem has stop working. I tried to restart but the orange light keep flashing. It never turns green.\"\"\",\n",
    "                    \"\"\"I just moved into town, and I need Internet service\"\"\",\n",
    "                    \"\"\"Why does my bill include an extra $20 a month for cable TV when I don't use a television?\"\"\",\n",
    "                    \"\"\"I need to change my user name and password since someone is using my credentials. I cannot access my account.\"\"\",\n",
    "                    \"\"\"What days this week are we having a general upgrades to the cable models?\"\"\",\n",
    "                    \"\"\"What day is the best day to call customer service so that I can avoid talking to a bot!\"\"\",\n",
    "                    \"\"\"Your company is full of incompetent morons and fools!\"\"\",\n",
    "                    \"\"\"I hate your worthless services. Cancel my stupid account or else I'll sue you!\"\"\"\n",
    "                   ]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "36fe82a0-9486-4e8c-b573-3bb71d7a71b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://console.endpoints.anyscale.com/m/v1 ...\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m My modem has stop working. I tried to restart but the orange light keep flashing. It never turns green.\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m  Technical support.\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m I just moved into town, and I need Internet service\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m  Technical support\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m Why does my bill include an extra $20 a month for cable TV when I don't use a television?\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m  No need for foul language. Please be respectful.\n",
      "\n",
      "Category: Billing\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m I need to change my user name and password since someone is using my credentials. I cannot access my account.\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m  No need for foul language. Please be respectful.\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m What days this week are we having a general upgrades to the cable models?\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m  No need for foul language. Please be respectful.\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m What day is the best day to call customer service so that I can avoid talking to a bot!\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m  Technical support\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m Your company is full of incompetent morons and fools!\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m  No need for foul language. Please be respectful.\n",
      "\n",
      "Category: General inquiry\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m I hate your worthless services. Cancel my stupid account or else I'll sue you!\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m  No need for foul language. Please be respectful. Can you provide more information about the customer's inquiry?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for query in customer_queries:\n",
    "    prompt = f\"\"\" \n",
    "    We are an Internet Service provider in a big metropolitan city. We want to \n",
    "    improve our customer service support by building a routing system so\n",
    "    that customer inquiries are routed responsively, respectfully, and actively to\n",
    "    appropriate company departments. Your task is to classify each customer's {query} \n",
    "    into one of the the following five categories:\n",
    "    1. Technical support\n",
    "    2. Billing \n",
    "    3. Account Management\n",
    "    4. New Customer  \n",
    "    5. General inquiry\n",
    "    \n",
    "    Do not expand or explain your response. Do not include backticks or quotes \n",
    "    in your response. Do not choose more than one category in your response from these categories: \n",
    "    Technical support, Billing, Account Management, New Customer, General inquiry\n",
    "    Do not include the {query} in your response.\n",
    "    If you can't classify the {query}, default to \"General inquiry.\"\n",
    "    If customer {query} uses a foul language, then respond with \n",
    "    \"No need for foul language. Please be respectful.\"\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Query:{BOLD_END} {query}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Route to:{BOLD_END} {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05333b92-c3fb-4341-b59d-82eeb7a65071",
   "metadata": {},
   "source": [
    "## Text transation and transformation\n",
    "\n",
    "Language translation by far is the most common use case for natural language processing. \n",
    "We have seen its early uses in Google translation, but with the emergence of multi-lingual LLMs, this task is simply achieved by exact prompting. \n",
    "\n",
    "In this section, we'll explore tasks in how to use LLMs for text translations, langugage identication, text transformation, spelling and grammar checking, tone adjustment, and format conversion.\n",
    "\n",
    "### Task 1:\n",
    " * Given an English text, translate into French, Spanish, and German.\n",
    " * Given a foreign language text, idenfify the language, and translate to English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9e9dcecd-8c00-45d6-af45-af19ee7bffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content= \"\"\"You are a world reknowned supreme lingiust and a universal translator. You are a polglot, and fluently speak many global languages\"\"\"\n",
    "\n",
    "english_texts = [\"\"\" Welcome to New York for the United Nations General Council Meeting. Today\n",
    "is a special day for us to celeberate all our achievments since this global institute's formation.\n",
    "But more importantly, we want to address how we can mitigate global conflict with conversation\n",
    "and promote deterence, detente, and discussion.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ad8986d5-3ade-4264-a29b-77dbf7b0ef8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://console.endpoints.anyscale.com/m/v1 ...\n",
      "\n",
      "\n",
      "\u001b[1mEnglish Text:\u001b[0m  Welcome to New York for the United Nations General Council Meeting. Today\n",
      "is a special day for us to celeberate all our achievments since this global institute's formation.\n",
      "But more importantly, we want to address how we can mitigate global conflict with conversation\n",
      "and promote deterence, detente, and discussion.\n",
      "\n",
      "\u001b[1mTranslation: \u001b[0m Spanish:\n",
      "Bienvenido a Nueva York para la reunión del Consejo General de las Naciones Unidas. Hoy es un día especial para celebrar nuestras logros desde la formación de esta institución global. Sin embargo, nuestro objetivo principal es abordar cómo podemos mitigar el conflicto global a través de conversación y promover la detención, la detente y la discusión.\n",
      "\n",
      "French:\n",
      "Bonjour à New York pour la réunion du Conseil général des Nations unies. Aujourd'hui est un jour spécial pour célébrer nos réalisations depuis la formation de cette institution mondiale. Cependant, notre objectif principal est d'aborder comment nous pouvons mitiger le conflit global à travers la conversation et promouvoir la détente, la détente et la discussion.\n",
      "\n",
      "German:\n",
      "Willkommen nach New York für den Sitzungstag des Generalkomitees der Vereinten Nationen. Heute ist ein besonderer Tag, um unsere Erfolge seit der Gründung dieser weltweiten Institution zu feiern. Aber unser Hauptziel ist es, globalen Konflikt durch Gespräch und Verhinderung der Eskalation zu reduzieren, sowie die Entente und die Diskussion zu fördern.\n",
      "\n",
      "Mandarin:\n",
      "欢迎来到新约翰特骨城，参加 Vereinten国家总会议会。今天是一日，以来自该全球组织的成立以来，庆祝我们的成就。然而，我们的主要目标是，通过谈判和减轻全球对话，以及推动滿意和谈判来实现。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for english_text in english_texts:\n",
    "    prompt = f\"\"\"\"Given an English text in triple ticks '''{english_text}'''. Translate into\n",
    "three languases: Spanish, French, German, and Mandarin. \n",
    "Label each translation with the langauge Name: followed by translation on a seperate line.\"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}English Text:{BOLD_END} {english_text}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Translation: {BOLD_END}{response}\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dae09d-5198-42a6-896b-347f260fe3eb",
   "metadata": {},
   "source": [
    "Given a foreing language, identify the language and translate into English.\n",
    "\n",
    "This is the reverse of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a366e171-38b6-4d8d-928a-a36ec0137a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_texts = [\"\"\"Bienvenidos a Nueva York para la Reunión del Consejo General de las Naciones Unidas. Hoy\n",
    "es un día especial para celebrar todos nuestros logros desde la formación de este instituto global.\n",
    "Pero más importante aún, queremos abordar cómo podemos mitigar el conflicto global con conversaciones\n",
    "y promover la disuasión, la distensión y el diálogo.\"\"\",\n",
    "            \"\"\"Willkommen in New York zur Sitzung des Allgemeinen Rates der Vereinten Nationen. Heute\n",
    "ist ein besonderer Tag für uns, um all unsere Errungenschaften seit der Gründung dieses globalen Instituts zu feiern.\n",
    "Aber wichtiger ist, dass wir ansprechen möchten, wie wir globale Konflikte durch Gespräche mildern können\n",
    "und Abschreckung, Entspannung und Diskussion fördern.\"\"\",\n",
    "                  \"\"\"Bienvenue à New York pour la réunion du Conseil Général des Nations Unies. Aujourd'hui,\n",
    "c'est un jour spécial pour nous pour célébrer toutes nos réalisations depuis la formation de cette institution mondiale.\n",
    "Mais plus important encore, nous voulons aborder comment nous pouvons atténuer les conflits mondiaux grâce à la conversation\n",
    "et promouvoir la dissuasion, la détente et la discussion.\"\"\",\n",
    "                  \"\"\"欢迎来到纽约参加联合国大会议。今天对我们来说是一个特别的日子，我们将庆祝自该全球机构成立以来取得的所有成就。但更重要的是，我们想要讨论如何通过对话来缓解全球冲突，并促进遏制、缓和和讨论。\n",
    "\"\"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "44a86628-4641-4283-8bba-9d2961451915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://console.endpoints.anyscale.com/m/v1 ...\n",
      "\n",
      "\n",
      "\u001b[1m Language Text: \u001b[0m Bienvenidos a Nueva York para la Reunión del Consejo General de las Naciones Unidas. Hoy\n",
      "es un día especial para celebrar todos nuestros logros desde la formación de este instituto global.\n",
      "Pero más importante aún, queremos abordar cómo podemos mitigar el conflicto global con conversaciones\n",
      "y promover la disuasión, la distensión y el diálogo.\n",
      "\n",
      "\u001b[1mTranslation: \u001b[0m  The language is English.\n",
      "English translation:\n",
      "\n",
      "Welcome to New York for the General Assembly of the United Nations. Today is a special day to celebrate our achievements since the formation of this global institution. But more importantly, we want to discuss how we can mitigate global conflict through conversation, dissuasion, and dialogue.\n",
      "\n",
      "\n",
      "\u001b[1m Language Text: \u001b[0m Willkommen in New York zur Sitzung des Allgemeinen Rates der Vereinten Nationen. Heute\n",
      "ist ein besonderer Tag für uns, um all unsere Errungenschaften seit der Gründung dieses globalen Instituts zu feiern.\n",
      "Aber wichtiger ist, dass wir ansprechen möchten, wie wir globale Konflikte durch Gespräche mildern können\n",
      "und Abschreckung, Entspannung und Diskussion fördern.\n",
      "\n",
      "\u001b[1mTranslation: \u001b[0m  The language of the given text is German.\n",
      "\n",
      "English translation:\n",
      "Welcome to New York for the meeting of the General Assembly of the United Nations. Today is a special day for us to celebrate our achievements since the founding of this global institution. But what is even more important is that we want to speak about how we can calm global conflicts through dialogue and promote reconciliation, deterrence, and discussion.\n",
      "\n",
      "\n",
      "\u001b[1m Language Text: \u001b[0m Bienvenue à New York pour la réunion du Conseil Général des Nations Unies. Aujourd'hui,\n",
      "c'est un jour spécial pour nous pour célébrer toutes nos réalisations depuis la formation de cette institution mondiale.\n",
      "Mais plus important encore, nous voulons aborder comment nous pouvons atténuer les conflits mondiaux grâce à la conversation\n",
      "et promouvoir la dissuasion, la détente et la discussion.\n",
      "\n",
      "\u001b[1mTranslation: \u001b[0m  English translation:\n",
      "\n",
      "Welcome to New York for the meeting of the General Council of the United Nations. Today, it is a special day for us to celebrate our achievements since the formation of this global institution. But more importantly, we want to discuss how we can reduce global conflicts through conversation, dissuasion, and dialogue.\n",
      "\n",
      "\n",
      "\u001b[1m Language Text: \u001b[0m 欢迎来到纽约参加联合国大会议。今天对我们来说是一个特别的日子，我们将庆祝自该全球机构成立以来取得的所有成就。但更重要的是，我们想要讨论如何通过对话来缓解全球冲突，并促进遏制、缓和和讨论。\n",
      "\n",
      "\n",
      "\u001b[1mTranslation: \u001b[0m  Language: Chinese\n",
      "\n",
      "English translation:\n",
      "\n",
      "欢迎来到纽约参加联合国大会议。今天对我们来说是一个特别的日子，我们将庆祝自该全球机构成立以来取得的所有成就。但更重要的是，我们想要讨论如何通过对话来缓解全球冲突，并促进遏制、缓和和讨论。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for language_text in languages_texts:\n",
    "    prompt = f\"\"\"\"Given a language text in triple ticks '''{language_text}'''. Idenfity\n",
    "    the language with the langauge Name: followed by an English translation on a seperate line, labeled as English translation:\"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN} Language Text: {BOLD_END} {language_text}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Translation: {BOLD_END} {response}\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8740e21-ea45-4b38-a0f7-753ef48a02aa",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    " * Given an English text, proof read it and correct any grammatical and usage errors.\n",
    " * Given a Pirate text, correct its tone to standard English.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a31e6bb8-83dd-4f0a-9036-a58e305e7d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a fastidious grammarian. You can proofread any English text and convert to \n",
    "its grammtical correct and usage form.\"\"\"\n",
    "\n",
    "bad_english_texts = [\"\"\"I don't know nothing about them big words and grammar rules. Me and my friend, we was talking, and he don't agree with me. We ain't never gonna figure it out, I reckon. His dog don't listen good, always running around and don't come when you call.\"\"\",\n",
    "                     \"\"\"Yesterday, we was at the park, and them kids was playing. She don't like the way how they acted, but I don't got no problem with it. We seen a movie last night, and it was good, but my sister, she don't seen it yet. Them books on the shelf, they ain't interesting to me.\"\"\"\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9e4f0a39-e951-4e69-b547-cb969ea8250c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://console.endpoints.anyscale.com/m/v1 ...\n",
      "\n",
      "\n",
      "\u001b[1mOriginal Text:\u001b[0m I don't know nothing about them big words and grammar rules. Me and my friend, we was talking, and he don't agree with me. We ain't never gonna figure it out, I reckon. His dog don't listen good, always running around and don't come when you call.\n",
      "\n",
      "\u001b[1mCorrected  Text:\u001b[0m  I do not know anything about those big words and grammar rules. Me and my friend, we were talking, and he does not agree with me. We will never figure it out, I reckon. His dog does not listen well, always running around and does not come when you call.\n",
      "\n",
      "Note: In the original text, \"know nothing\" should not be used instead of \"do not know anything.\" \"My friend, we was talking\" should be \"My friend and I were talking.\" \"He don't agree\" should be \"He does not agree.\" \"We ain't never gonna figure it out\" should be \"We will never figure it out.\" \"His dog don't listen\" should be \"His dog does not listen.\"\n",
      "\n",
      "\n",
      "\u001b[1mOriginal Text:\u001b[0m Yesterday, we was at the park, and them kids was playing. She don't like the way how they acted, but I don't got no problem with it. We seen a movie last night, and it was good, but my sister, she don't seen it yet. Them books on the shelf, they ain't interesting to me.\n",
      "\n",
      "\u001b[1mCorrected  Text:\u001b[0m  \"Yesterday, we were at the park, and those kids were playing. She didn't like the way they acted, but I didn't have any problems with it. We saw a movie last night, and it was good, but my sister hadn't seen it yet. Those books on the shelf weren't interesting to me.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for bad_english_text in bad_english_texts:\n",
    "    prompt = f\"\"\"\"Proofread and correct the text provided in triple ticks '''{bad_english_text}'''.\n",
    "    Use standard usage and remedy any incorect grammar usage.\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Original Text:{BOLD_END} {bad_english_text}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Corrected  Text:{BOLD_END} {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "01c28033-8175-427b-93d2-69db740060e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pirate_texts = [\"\"\"Arrr matey! I be knowin' nuthin' 'bout them fancy words and grammatical rules. Me and me heartie, we be chattin', and he don't be agreein' with me. We ain't never gonna figure it out, I reckon. His scallywag of a dog don't be listenin' well, always runnin' around and not comin' when ye call.\"\"\"\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f09b26f1-b370-4cd3-9079-b5b78df502d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://console.endpoints.anyscale.com/m/v1 ...\n",
      "\n",
      "\n",
      "\u001b[1mOriginal Text:\u001b[0m Arrr matey! I be knowin' nuthin' 'bout them fancy words and grammatical rules. Me and me heartie, we be chattin', and he don't be agreein' with me. We ain't never gonna figure it out, I reckon. His scallywag of a dog don't be listenin' well, always runnin' around and not comin' when ye call.\n",
      "\n",
      "\u001b[1mCorrected  Text:\u001b[0m  \"I know nothing about fancy words and grammatical rules. My friend and I are chatting, but he doesn't agree with me. We won't figure it out, I think. His dog doesn't listen well and always runs around, not coming when you call.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "for pirate_text in pirate_texts:\n",
    "    prompt = f\"\"\"\"Convert the Pirate text provided in triple ticks '''{pirate_text}'''.\n",
    "    Use standard usage and remedy any incorect grammar usage, dropping all Pirate greetings.\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Original Text:{BOLD_END} {pirate_text}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Corrected  Text:{BOLD_END} {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e48460-00a6-4a7f-9e54-b1e25e00860d",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "* Given some text in a particular format, convert it into JSON format.\n",
    "* For example, we LLM to producce names of three top shoes, but we want them it product and its items in JSON format. This JSON format can be fed downstream into another application that may process it.\n",
    "\n",
    "Let's have go at it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ab5b7a40-5d26-4bb0-816e-08f04462d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You have knowledge of all sporting goods and will provide knowledge answers\n",
    "to queries about sporting goods.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9f77a87f-cf8a-486a-8c43-38a9e5f0c708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://console.endpoints.anyscale.com/m/v1 ...\n",
      "\n",
      "\n",
      " \u001b[1mJSON response:\u001b[0m  Here is an example JSON object containing five distinct products on training shoes:\n",
      "```\n",
      "{\n",
      "  \"product1\": {\n",
      "    \"Brand\": \"Nike\",\n",
      "    \"Description\": \"Nike Air Zoom Pegasus 39 running shoes for men\",\n",
      "    \"Size\": \"M\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Price\": 129.99,\n",
      "    \"Reviews\": [\n",
      "      {\n",
      "        \"Rating\": 5,\n",
      "        \"Text\": \"These are my go-to running shoes. They are comfortable and provide great support.\"\n",
      "      },\n",
      "      {\n",
      "        \"Rating\": 4,\n",
      "        \"Text\": \"These shoes are a bit pricey, but they are worth it for the quality and support.\"\n",
      "      },\n",
      "      {\n",
      "        \"Rating\": 3,\n",
      "        \"Text\": \"I don't find these shoes to be very breathable. I prefer shoes with more ventilation.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"product2\": {\n",
      "    \"Brand\": \"New Balance\",\n",
      "    \"Description\": \"New Balance 990v7 running shoes for women\",\n",
      "    \"Size\": \"W\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Price\": 149.99,\n",
      "    \"Reviews\": [\n",
      "      {\n",
      "        \"Rating\": 5,\n",
      "        \"Text\": \"These shoes are incredibly comfortable and provide great support for my feet.\"\n",
      "      },\n",
      "      {\n",
      "        \"Rating\": 4,\n",
      "        \"Text\": \"The fit of these shoes is a bit tight. I recommend ordering a size larger.\"\n",
      "      },\n",
      "      {\n",
      "        \"Rating\": 3,\n",
      "        \"Text\": \"These shoes are a bit heavier than I expected. I prefer lighter shoes for running.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"product3\": {\n",
      "    \"Brand\": \"Adidas\",\n",
      "    \"Description\": \"Adidas Ultra Boost running shoes for men\",\n",
      "    \"Size\": \"M\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Price\": 199.99,\n",
      "    \"Reviews\": [\n",
      "      {\n",
      "        \"Rating\": 5,\n",
      "        \"Text\": \"These shoes are incredibly comfortable and provide great cushioning for my runs.\"\n",
      "      },\n",
      "      {\n",
      "        \"Rating\": 4,\n",
      "        \"Text\": \"I find these shoes to be a bit tight around the midfoot. I recommend ordering a size larger.\"\n",
      "      },\n",
      "      {\n",
      "        \"Rating\": 3,\n",
      "        \"Text\": \"These shoes are a bit expensive. I prefer shoes that are more affordable.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"product4\": {\n",
      "    \"Brand\": \"Puma\",\n",
      "    \"Description\": \"Puma Ignite running shoes for women\",\n",
      "    \"Size\": \"W\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Price\": 129.99,\n",
      "    \"Reviews\": [\n",
      "      {\n",
      "        \"Rating\": 5,\n",
      "        \"Text\": \"These shoes are incredibly comfortable and provide great support for my feet.\"\n",
      "      },\n",
      "      {\n",
      "        \"Rating\": 4,\n",
      "        \"Text\": \"The fit of these shoes is a bit tight. I recommend ordering a size larger.\"\n",
      "      },\n",
      "      {\n",
      "        \"Rating\": 3,\n",
      "        \"Text\": \"These shoes are a bit heavier than I expected. I prefer lighter shoes for running.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"product5\": {\n",
      "    \"Brand\": \"Brooks\",\n",
      "    \"Description\": \"Brooks Ghost 12 running shoes for men\",\n",
      "    \"Size\": \"M\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Price\": 119.99,\n",
      "    \"Reviews\": [\n",
      "      {\n",
      "        \"Rating\": 5,\n",
      "        \"Text\": \"These shoes are incredibly comfortable and provide great support for my feet.\"\n",
      "      },\n",
      "      {\n",
      "        \"Rating\": 4,\n",
      "        \"Text\": \"The fit of these shoes is a bit tight. I recommend ordering a size larger.\"\n",
      "      },\n",
      "      {\n",
      "        \"Rating\": 3,\n",
      "        \"Text\": \"These shoes are a bit expensive. I prefer shoes that are more affordable.\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "```\n",
      "This JSON object contains five distinct products on training shoes, each with information about the brand, description, size, gender, price, and customer reviews. The reviews are formatted as an array of objects, each with a rating and text.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "prompt = f\"\"\"Generate five distinct products on training shoes. Generate products and format them all as a \n",
    "            in a single JSON object. For each product, the JSON object should contain items: Brand, Description, Size, Gender: Male \n",
    "            or Female or Unisex, Price, and at least three customer reviews as Review \n",
    "            item\"\"\"\n",
    "response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "print(f\"\\n {BOLD_BEGIN}JSON response:{BOLD_END} {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6496b00-0a1d-4a57-9783-11f2dcf09c5a",
   "metadata": {},
   "source": [
    "## Simple and complex reasoning \n",
    "\n",
    "An import characteristic of LLM is that it's not only general respository of compressed\n",
    "knowledge garned from large corpus of text, but can be employed as a simple and complex reasoning engine. With use of precise prompt, you can instruct LLM to think trough a problem in a step by step fashion.\n",
    "\n",
    "Let's look at some tasks as examples.\n",
    " * **Task 1**: given a list of numbers identify the prime numbers, add the prime numbers and check if the sum is even or odd.\n",
    " * **Task 2**: given an hourly rate of wages, compute your yearly income if you work 30 hours a week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "47be9101-2af8-4074-a970-b6cdadc692d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a reasoning engine. Given a problem think through the problem logically\n",
    "in a step by step manner.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3c0b6b93-5218-4239-9db4-674e6b8dbd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 prompt\n",
    "prime_number_prompt = f\"\"\"given a list of numbers 1,2,3,4,5,7,8, 11,13,17,19,23,24,29 identify the prime numbers, add the prime numbers, \n",
    "and check if the sum is even or odd. Explain each step how you solved the problem\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4f0bd7a7-9c8b-4c97-85b3-8f83a0ca61b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 2 prompt\n",
    "hourly_wages_prompt = f\"\"\"If my hourly rate is $117.79 per hour and 30 hours a week, what\n",
    "is my yearly income? Break the problem into simple steps and explain in each step how you arrive \n",
    "to the answer. If you don't know, simple say I don't know. Do not make up answers\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e36694e-5634-4aee-9a00-e677da6baa5d",
   "metadata": {},
   "source": [
    "#### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b4ecb495-ee6f-4033-8fa7-7c364d79ffbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAnswer: \u001b[0m Sure, I'd be happy to help you solve this problem!\n",
      "\n",
      "Here's my step-by-step approach:\n",
      "\n",
      "1. Identify the prime numbers in the list of numbers.\n",
      "2. Add all the prime numbers together.\n",
      "3. Determine whether the sum is even or odd.\n",
      "\n",
      "Let's go through each step in more detail:\n",
      "\n",
      "1. Identify the prime numbers in the list of numbers.\n",
      "\n",
      "To do this, we need to check each number in the list to see if it is divisible by any other number in the list except for itself. If a number is not divisible by any other number in the list except for itself, then it is a prime number. Here's a table of the divisibility of each number in the list:\n",
      "\n",
      "| Number | Divisibility |\n",
      "| --- | --- |\n",
      "| 1 | 1 |\n",
      "| 2 | 1 |\n",
      "| 3 | 1 |\n",
      "| 4 | 2 |\n",
      "| 5 | 5 |\n",
      "| 7 | 7 |\n",
      "| 8 | 2, 4 |\n",
      "| 11 | 11 |\n",
      "| 13 | 13 |\n",
      "| 17 | 17 |\n",
      "| 19 | 19 |\n",
      "| 23 | 23 |\n",
      "| 24 | 2, 4, 12 |\n",
      "| 29 | 29 |\n",
      "\n",
      "From the table, we can see that the prime numbers in the list of numbers are 2, 3, 5, 7, 11, 13, 17, 19, 23 and 29.\n",
      "\n",
      "2. Add all the prime numbers together.\n",
      "\n",
      "To do this, we simply add up the values of the prime numbers we identified in step 1: 2 + 3 + 5 + 7 + 11 + 13 + 17 + 19 + 23 + 29 = 127.\n",
      "\n",
      "3. Determine whether the sum is even or odd.\n",
      "\n",
      "To do this, we simply take the sum of the prime numbers (127) and check whether it is divisible by 2. If a number is divisible by 2, then it is an even number. If a number is not divisible by 2, then it is an odd number. In this case, 127 is not divisible by 2, so the sum is an odd number.\n",
      "\n",
      "Therefore, the sum of the prime numbers in the list is 127, and this sum is an odd number.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, prime_number_prompt)\n",
    "print(f\"\\n{BOLD_BEGIN}Answer: {BOLD_END}{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bd2c6e-bfa7-45cc-804d-acaf4797f8f3",
   "metadata": {},
   "source": [
    "#### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5651b79b-997e-4524-b17b-14f413e850a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAnswer: \u001b[0m To calculate your yearly income, we need to first calculate your weekly income and then multiply that by the number of weeks in a year. Here's a step-by-step breakdown of the calculation:\n",
      "\n",
      "Step 1: Calculate your weekly income.\n",
      "\n",
      "To do this, you need to multiply your hourly rate by the number of hours you work per week. In this case, your hourly rate is $117.79 per hour and you work 30 hours per week, so:\n",
      "\n",
      "Weekly income = Hourly rate x Hours per week\n",
      "= $117.79/hour x 30 hours/week\n",
      "= $3533.70/week\n",
      "\n",
      "Step 2: Calculate your yearly income.\n",
      "\n",
      "To do this, you need to multiply your weekly income by the number of weeks in a year. There are 52 weeks in a year, so:\n",
      "\n",
      "Yearly income = Weekly income x Weeks per year\n",
      "= $3533.70/week x 52 weeks/year\n",
      "= $190,242.00/year\n",
      "\n",
      "Therefore, your yearly income is $190,242.00.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, hourly_wages_prompt)\n",
    "print(f\"\\n{BOLD_BEGIN}Answer: {BOLD_END}{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a5da1-986a-4682-a672-8c213eb40be5",
   "metadata": {},
   "source": [
    "## Code generation\n",
    "\n",
    "Language models like ChatGPT and Llama 2 are really good at generating code. Copilot on GitHub is a cool example of this. You can do lots of different code tasks just by asking in a smart way. Let's check out a few examples to see how it's helpful.\n",
    "\n",
    "#### Task 1\n",
    " * Generate Python code to compute the value of PI using Ray distributed framework\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "de3ad4ed-e28e-44a7-8a33-11136f6334d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a supreme CoPilot for a developer. Given a task you can\n",
    "generate code for that task.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e9a85173-dbce-4bf6-b004-7e368a5ccd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_code_prompt=\"\"\"Generate Python code to compute the value of PI using Ray \n",
    "distributed framework API. Use the Monte Carlo method to compute the value of PI.\n",
    "Include in-line comments explaining the code\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "60e2b04a-9f0c-450f-aeda-8e6ece5b0a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mGenerated Python code:\u001b[0m To compute the value of PI using the Monte Carlo method in Python with the Ray distributed framework API, you can use the following code:\n",
      "```python\n",
      "import numpy as np\n",
      "import ray\n",
      "\n",
      "# Configure Ray to run on multiple CPUs\n",
      "ray.init(num_cpus=4)\n",
      "\n",
      "# Define a function to compute the value of PI using Monte Carlo\n",
      "def compute_pi(num_samples):\n",
      "    \"\"\"\n",
      "    Computes the value of PI using the Monte Carlo method with the specified number of samples.\n",
      "    \n",
      "    Args:\n",
      "    num_samples (int): The number of samples to use in the Monte Carlo computation.\n",
      "    Returns:\n",
      "    float: The estimated value of PI.\n",
      "    \"\"\"\n",
      "    inside_circle = [False] * 1000000\n",
      "    for i in range(num_samples):\n",
      "        x = np.random.uniform(-1, 1, size=1)\n",
      "        y = np.random.uniform(-1, 1, size=1)\n",
      "        if x**2 + y**2 <= 1:\n",
      "            inside_circle[i] = True\n",
      "\n",
      "    return (num_samples / sum(inside_circle)) * 4\n",
      "\n",
      "# Call the compute_pi function with a specified number of samples\n",
      "pi_value = compute_pi(10000000)\n",
      "\n",
      "# Print the estimated value of PI\n",
      "print(f\"The estimated value of PI is 3.14159265358979323846, with {len(inside_circle)} samples.\")\n",
      "```\n",
      "In this code, we first import the necessary libraries: `numpy` for generating random numbers, and `ray` for running the computation on multiple CPUs. We then configure Ray to use all available CPUs.\n",
      "\n",
      "Next, we define the `compute_pi` function, which takes in a number of samples to use in the Monte Carlo computation. Inside the function, we create an array of `inside_circle` with 1000000 elements, and iterate over the specified number of samples. For each sample, we generate random x and y values and check if they are inside the unit circle. If they are, we set the corresponding element in the `inside_circle` array to True. We then use the sum of the `inside_circle` array to calculate an estimate of the ratio of points inside the unit circle to the total number of samples. Finally, we multiply this ratio by 4 to estimate the value of PI.\n",
      "\n",
      "Finally, we call the `compute_pi` function with a specified number of samples (10 million in this case), and print the estimated value of PI along with the number of samples used in the computation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, python_code_prompt)\n",
    "\n",
    "print(f\"\\n{BOLD_BEGIN}Generated Python code:{BOLD_END}{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7fdc8-7a19-4a1a-b119-7a0bf0b3ae0f",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    " * Given SQL schema tables, generate an SQL query \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "585f372c-fe37-43b4-9299-c5708d1be06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_code_prompt=\"\"\"Given the following SQL schema for tables\n",
    "Table clicks, columns = [target_url, orig_url, user_id, clicks]\n",
    "Table users, columns = [user_id, f_name, l_name, e_mail, company, title], generate\n",
    "an SQL query that computes in the descening order of all the clicks. Also, for\n",
    "each user_id, list the f_name, l_name, company, and title\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "351b78d7-c78b-4a1b-946b-8a2abd17efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mGenerated SQL code: \u001b[0m Here is an SQL query that computes the clicks in descending order and lists the f\\_name, l\\_name, company, and title for each user\\_id:\n",
      "```\n",
      "SELECT \n",
      "    clicks.user_id, \n",
      "    users.f_name, \n",
      "    users.l_name, \n",
      "    users.company, \n",
      "    users.title \n",
      "FROM \n",
      "    clicks \n",
      "INNER JOIN \n",
      "    users \n",
      "        ON clicks.user_id = users.user_id \n",
      "ORDER BY \n",
      "    clicks.clicks DESC\n",
      "```\n",
      "This query first joins the two tables `clicks` and `users` on the `user_id` column. It then selects the `user_id`, `f_name`, `l_name`, `company`, and `title` columns from the joined table and orders the result by the `clicks` column in descending order (i.e. from highest to lowest clicks).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, sql_code_prompt)\n",
    "print(f\"\\n{BOLD_BEGIN}Generated SQL code: {BOLD_END}{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d546337d-b9a4-40db-92dd-8cdce63c6979",
   "metadata": {},
   "source": [
    "## All this is amazing! 😜 Feel the wizardy prompt power 🧙‍♀️"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
