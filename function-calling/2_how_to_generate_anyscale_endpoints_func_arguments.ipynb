{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ec7b5c6-9d71-4fc6-a60a-ebe381c558aa",
   "metadata": {},
   "source": [
    "# How to use Anyscale function calling with LLMs\n",
    "Function calling extends the power capabilities of LLMs. It allolws you to format\n",
    "the output of an LLM response into a JSON object, which then can be fed down stream\n",
    "to an actual function as a argument to process the response.\n",
    "\n",
    "OpenAI documention states the basic steps involved in function calling: \n",
    "\n",
    "1. Call the model with the user query and a set of functions defined in the functions parameter.\n",
    "2. The model can choose to call one or more functions; if so, the content will be a stringified JSON object adhering to your custom schema (note: the model may hallucinate parameters).\n",
    "3. Parse the string into JSON in your code, and call your function with the provided arguments if they exist.\n",
    "4. Call the model again by appending the function response as a new message, and let the model summarize the results back to the user.\n",
    "\n",
    "<img src=\"./images/gpt_function_calling.png\">\n",
    "\n",
    "Let's first demonstrate how we use this feature. Let's first specify a function and use the API to generate function arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "466be216-add4-41f5-a228-13f67e17bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42924212-0e3d-439c-9c53-250e4dcf046e",
   "metadata": {},
   "source": [
    "Load our .env file with respective API keys and base url endpoints. Here you can either use OpenAI or Anyscale Endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d8c1ee2-4185-4584-a6e9-c16096893603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=mistralai/Mistral-7B-Instruct-v0.1; base=https://api.endpoints.anyscale.com/v1\n"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "warnings.filterwarnings('ignore')\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\", \"\")\n",
    "weather_api_key = os.getenv(\"WEATHER_API_KEY\", \"\")\n",
    "\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bb60abb-e999-43de-963e-b1f41eaec6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77fafc9-fe16-4583-8439-c6766beaedfd",
   "metadata": {},
   "source": [
    "## Simple case: Example 1: Query the Anyscale endpoint with Mistral \n",
    "\n",
    "Since Anyscale endpoint supports JSON response format, let's use\n",
    "Pydantic validation and base class for our response object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d50b895-28c3-4a43-ab9e-ba525af37185",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryResponse(BaseModel):\n",
    "    finalist_team: str = Field(description=\"World Cup finalist team\"),\n",
    "    winning_team: str = Field(description=\"World Cup final winner team\"),\n",
    "    final_score: str = Field(description=\"Final score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50310a5-4955-4bd3-858e-77955c8eb9e4",
   "metadata": {},
   "source": [
    "Let'send a basic query and see what result we get and its JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de81594c-3294-4c0a-918c-848fc856b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_completion = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    response_format={\n",
    "        \"type\": \"json_object\", \n",
    "        \"schema\": QueryResponse.schema_json()\n",
    "    },\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": \"You are the FIFA World Cup Soccer assistant designed to output JSON for queries\"},\n",
    "        {\"role\": \"user\", \n",
    "         \"content\": \"\"\"What national teams played in the FIFA World Cup Soccer 1998 Finals played \n",
    "                        in Francce, who was the winner and who was the loser?\"\"\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e2148da-de8f-4d83-b33d-2c5fb2447feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aa4db0-595c-478d-a90f-ac5cf77bba1b",
   "metadata": {},
   "source": [
    "#### Convert the JSON response into a dictonary\n",
    "This output matches JSON format schema defined above using Pydantic QueryResponse class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77a4ee3f-45fb-4dd3-8f9d-02733ad6646f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winning_team:France\n",
      "final_score:3-0\n",
      "finalist_team:Brazil\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "result = response.choices[0].message.content\n",
    "# Convert string into a dictionary\n",
    "json_schema = json.loads(result)\n",
    "\n",
    "for k, v in json_schema.items():\n",
    "    print(f\"{k}:{v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de274045-1e5b-4423-82a5-9e4c5c15ad0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"winning_team\": \"France\",\n",
      "  \"final_score\": \"3-0\",\n",
      "  \"finalist_team\": \"Brazil\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Convert dictionary into a printable JSON string\n",
    "print(json.dumps(json_schema, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fd3633-c622-46fd-b418-a6c5ed3493e8",
   "metadata": {},
   "source": [
    "## Example 2: Query the Anyscale endpoint with Mistral \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3041dd19-1f66-4c59-b611-0f10d5e1ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "class MathResponse(BaseModel):\n",
    "    prime_numbers: List[int] = Field(description=\"List of prime numbers between 2 and 100\")\n",
    "    sum: int = Field(description=\"Sum of the all the prime numbers between 2 and 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae93607a-23fc-4575-af02-17055fd20190",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_completion = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    response_format={\n",
    "        \"type\": \"json_object\", \n",
    "        \"schema\": MathResponse.schema_json()\n",
    "    },\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": \"\"\"You are Math tutor who can answer simple math problems and return \n",
    "         reponse in JSON format\"\"\"\n",
    "        },\n",
    "        {\"role\": \"user\", \n",
    "        \"content\": \"\"\"Generate a list of all prime numbers between 2 and 100 and add the\n",
    "        numbers in the list\"\"\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4c77eaf-3978-4b89-8cc9-8fcc63b67254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum:1\n",
      "prime_numbers:[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "result = response.choices[0].message.content\n",
    "# Convert string into a dictionary\n",
    "json_schema = json.loads(result)\n",
    "\n",
    "for k, v in json_schema.items():\n",
    "    print(f\"{k}:{v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95fdfa1f-3090-4db8-befc-b4a2f0ad1d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"sum\": 1,\n",
      "  \"prime_numbers\": [\n",
      "    2,\n",
      "    3,\n",
      "    5,\n",
      "    7,\n",
      "    11,\n",
      "    13,\n",
      "    17,\n",
      "    19,\n",
      "    23,\n",
      "    29,\n",
      "    31,\n",
      "    37,\n",
      "    41,\n",
      "    43,\n",
      "    47,\n",
      "    53,\n",
      "    59,\n",
      "    61,\n",
      "    67,\n",
      "    71,\n",
      "    73,\n",
      "    79,\n",
      "    83,\n",
      "    89,\n",
      "    97\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Convert dictionary into a printable JSON string\n",
    "print(json.dumps(json_schema, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f528387a-800f-4a38-8ee5-1f44a553fabb",
   "metadata": {},
   "source": [
    "## Example 2: Query the Anyscale endpoint with Mistral \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4b00eac-9955-42cb-acc1-6bef1d64b478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "class FractionResponse(BaseModel):\n",
    "    fractions: List[Tuple[int, int]] = Field(description=\"List of unique fractrions between 1 and 5 as Python tuples\")\n",
    "    sum: int = Field(description=\"Sum of the all unique fractrions between 1 and 5\")\n",
    "    common_denominator: int = Field(description=\"The common denominator among the unique fractions between 1 and 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73c28b5d-4b60-4a2f-b410-8aec5e732d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_completion = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    response_format={\n",
    "        \"type\": \"json_object\", \n",
    "        \"schema\": FractionResponse.schema_json()\n",
    "    },\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": \"\"\"You are Math tutor who can answer simple math problems and return \n",
    "         reponse in JSON format\"\"\"\n",
    "        },\n",
    "        {\"role\": \"user\", \n",
    "        \"content\": \"\"\"Generate a list of all unique fractions between between 1 and 5 as Python tuples,  \n",
    "        add the tuple fractions in the list, and find their common denominator\"\"\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a1f41a3-4faa-4aaf-8f4f-171aa5473294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum:12\n",
      "fractions:[[1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [2, 1], [2, 2], [2, 3], [2, 4], [2, 5], [3, 1], [3, 2], [3, 3], [3, 4], [3, 5], [4, 1], [4, 2], [4, 3], [4, 4], [4, 5], [5, 1], [5, 2], [5, 3], [5, 4], [5, 5]]\n",
      "common_denominator:60\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "result = response.choices[0].message.content\n",
    "# Convert string into a dictionary\n",
    "json_schema = json.loads(result)\n",
    "\n",
    "for k, v in json_schema.items():\n",
    "    print(f\"{k}:{v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e366dd8-2b86-4df8-bc54-83f9e27f0ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"sum\": 12,\n",
      "  \"fractions\": [\n",
      "    [\n",
      "      1,\n",
      "      1\n",
      "    ],\n",
      "    [\n",
      "      1,\n",
      "      2\n",
      "    ],\n",
      "    [\n",
      "      1,\n",
      "      3\n",
      "    ],\n",
      "    [\n",
      "      1,\n",
      "      4\n",
      "    ],\n",
      "    [\n",
      "      1,\n",
      "      5\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      1\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      2\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      3\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      4\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      5\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      1\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      2\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      3\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      4\n",
      "    ],\n",
      "    [\n",
      "      3,\n",
      "      5\n",
      "    ],\n",
      "    [\n",
      "      4,\n",
      "      1\n",
      "    ],\n",
      "    [\n",
      "      4,\n",
      "      2\n",
      "    ],\n",
      "    [\n",
      "      4,\n",
      "      3\n",
      "    ],\n",
      "    [\n",
      "      4,\n",
      "      4\n",
      "    ],\n",
      "    [\n",
      "      4,\n",
      "      5\n",
      "    ],\n",
      "    [\n",
      "      5,\n",
      "      1\n",
      "    ],\n",
      "    [\n",
      "      5,\n",
      "      2\n",
      "    ],\n",
      "    [\n",
      "      5,\n",
      "      3\n",
      "    ],\n",
      "    [\n",
      "      5,\n",
      "      4\n",
      "    ],\n",
      "    [\n",
      "      5,\n",
      "      5\n",
      "    ]\n",
      "  ],\n",
      "  \"common_denominator\": 60\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Convert dictionary into a printable JSON string\n",
    "print(json.dumps(json_schema, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220893e9-e09c-41d4-9acc-cc16a8a9770c",
   "metadata": {},
   "source": [
    "## How to generate function arguments\n",
    "For Anyscale endpoints, the idea of function calling is not that different from \n",
    "OpenAI's. Basically, according to [Anyscale function calling blog](https://www.anyscale.com/blog/anyscale-endpoints-json-mode-and-function-calling-features), it boils down to simple steps:\n",
    " 1. You send a query with functions and parameters to the LLM.\n",
    " 2. The LLM decides to either use a function or not.\n",
    " 3. If not using a function, it replies in plain text, providing an answer or asking for more information.\n",
    " 4. If using a function, it recommends an API and gives usage instructions in JSON.\n",
    " 5. You execute the API in your application.\n",
    " 6. Send the API's results back to the LLM.\n",
    " 7. The LLM analyzes these results and guides the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c312661-1b4c-4305-9c5b-9d0f87a514ff",
   "metadata": {},
   "source": [
    "#### Example 1: Extract the generated arguments\n",
    "\n",
    "Let's process generated arguments to plot a map of cities where we hold \n",
    "Ray meetups. These generated satellite coordinates, generated as a JSON object\n",
    "by the LLM, are fed into a function to generate an HTML file and map markers of\n",
    "each city.\n",
    "\n",
    "The idea is here is to nudge the LLM to generate JSON object, which can be easily converted into a Python dictionary as an argument to a function downstream to create the HTML and render a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "66a14d6f-52bc-4ce2-9225-ca31e248064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [ \n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"generate_ray_meetup_map\",\n",
    "                \"description\": \"Generate HTML map for global cities where Ray meetups are hosted\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                                \"location\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"The city name e.g., San Francisco, CA\",\n",
    "                                    },\n",
    "                                \"latitude\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"Latitude satelite coordinates\",\n",
    "                                    },\n",
    "                                \"longitude\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"Longitude satelite coordinates\",\n",
    "                                    },\n",
    "                                }\n",
    "        \n",
    "                            }\n",
    "                },\n",
    "                \"required\": [\"location, latitude, longitude\"]\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "350a0f63-036e-4494-b02c-70ac50025a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_city_map_completion(clnt: object, model: str, user_content:str) -> object:\n",
    "    chat_completion = clnt.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[ {\"role\": \"system\", \"content\": f\"You are a helpful assistant. Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"},\n",
    "                   {\"role\": \"user\", \"content\": user_content}],\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "        temperature=0.7)\n",
    "        \n",
    "    response = chat_completion.choices[0].message\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a536389d-9a0a-4590-8e1c-e3b133b94339",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_content = \"\"\"Generate satelite coordinates latitude and longitude for location of San Francisco where Ray meetup is hosted \n",
    "at Anyscale Headquaters at 55 Hawthorne Street, 9th Floor\n",
    "San Francisco, CA 94105\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "61057a12-b2b8-4d38-8a1f-e2731598d7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.endpoints.anyscale.com/v1 ...\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_dc441e9f23b942fdaed4c2b26775b030', function=Function(arguments='{\"location\": \"San Francisco\", \"latitude\": \"37.7749\", \"longitude\": \"-122.4194\"}', name='generate_ray_meetup_map'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "response_1 = generate_city_map_completion(client, MODEL, user_content)\n",
    "print(response_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a7174b4d-2e8a-49ab-9b30-c2ee6dddcbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': None,\n",
       " 'role': 'assistant',\n",
       " 'function_call': None,\n",
       " 'tool_calls': [{'id': 'call_dc441e9f23b942fdaed4c2b26775b030',\n",
       "   'function': {'arguments': '{\"location\": \"San Francisco\", \"latitude\": \"37.7749\", \"longitude\": \"-122.4194\"}',\n",
       "    'name': 'generate_ray_meetup_map'},\n",
       "   'type': 'function'}]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_arguments = response_1.dict()\n",
    "json_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa14bcef-d443-4a5e-a135-072c43007434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function name: generate_ray_meetup_map\n"
     ]
    }
   ],
   "source": [
    "# Extract specific items from the dict\n",
    "func_name = json_arguments['tool_calls'][0]['function']['name']\n",
    "print(f\"Function name: {func_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f6a2822-3b10-4f16-8e23-002635a6a5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: {'location': 'San Francisco', 'latitude': '37.7749', 'longitude': '-122.4194'}\n"
     ]
    }
   ],
   "source": [
    "funcs = json_arguments['tool_calls'][0]['function']['arguments']\n",
    "funcs_args = json.loads(funcs)\n",
    "print(f\"Arguments: {funcs_args}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f689500-de85-4777-93c3-dac1d3388e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_file_path = './world_map_nb_func_anyscale_with_cities.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf57c8ed-9886-4e20-b686-91af12afde29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from typing import Dict, Any\n",
    "\n",
    "def generate_ray_meetup_map(coordinates: Dict[str, Any]) -> None:\n",
    "    # Create a base map\n",
    "    m = folium.Map(location=[20,0], tiles=\"OpenStreetMap\", zoom_start=2)\n",
    "    # Adding markers for each city\n",
    "    folium.Marker([coordinates[\"latitude\"], coordinates[\"longitude\"]], popup=coordinates[\"location\"]).add_to(m)\n",
    "    # Display the map\n",
    "    m.save(html_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fee1e71-40c4-4e2f-a337-f4f49f2d5c51",
   "metadata": {},
   "source": [
    "#### Invoke the function from within our notebook.\n",
    "This is our downstream function being invoked with the extract arguments\n",
    "from the JSON response generated by the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f097d336-b11a-4514-be6d-7c35fc4851b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"400\"\n",
       "            src=\"./world_map_nb_func_anyscale_with_cities.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x110e9ed70>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "# Assuming the HTML file is named 'example.html' and located in the same directory as the Jupyter Notebook\n",
    "generate_ray_meetup_map(funcs_args)\n",
    "\n",
    "# Display the HTML file in the Jupyter Notebook\n",
    "IFrame(src=html_file_path, width=700, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8230ab8-f0d0-4a5f-acc6-c85ba576866f",
   "metadata": {},
   "source": [
    "#### Example 2: Generate function arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3107db04-9bfe-4c92-a287-34035308000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_data_for_cities(params:Dict[Any, Any]=None,\n",
    "                    api_base:str=\"http://api.weatherstack.com/current\") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Retrieves weather data from the OpenWeatherMap API for cities\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    url = f\"{api_base}\"\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ce6ee5f6-3ee4-43c4-a6a6-316093ab8b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_2 = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather_data_for_cities\",\n",
    "            \"description\": \"Get the current weather forecast in the cities\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The list of city names e.g., San Francisco, New York, London\"\n",
    "                            }\n",
    "                    }\n",
    "                }\n",
    "             }\n",
    "        },\n",
    "        \"required\": [\"query\"]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "896c9f4f-857b-4bf9-97c8-2613d328699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weather_forecast_completion(clnt: object, model: str, user_content:str) -> object:\n",
    "    chat_completion = clnt.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[ {\"role\": \"system\", \"content\": f\"You are a helpful assistant. Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"},\n",
    "                   {\"role\": \"user\", \"content\": user_content}],\n",
    "        tools=tools_2,\n",
    "        tool_choice=\"auto\",\n",
    "        temperature=0.7)\n",
    "        \n",
    "    response = chat_completion.choices[0].message\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a7f9c352-24b4-4d2f-b524-0b9f1329f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_content = \"\"\"\n",
    "                Generate weather forecast and temperature in Fahrenheit for \n",
    "                London, New York, San Franciso for today.\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "67631692-9d14-4da6-90d1-07d9b3458e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.endpoints.anyscale.com/v1 ...\n",
      "\n",
      "Using model: mistralai/Mistral-7B-Instruct-v0.1 ...\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_7608b90e0af34e2993a7bd59814be625', function=Function(arguments='{\"query\": [\"London\", \"New York\", \"San Francisco\"]}', name='get_weather_data_for_cities'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "print(f\"Using model: {MODEL} ...\\n\")\n",
    "weather_response = generate_weather_forecast_completion(client, MODEL, user_content)\n",
    "print(weather_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e4646a4-56bd-4768-b2eb-70b68e1ff060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': None,\n",
       " 'role': 'assistant',\n",
       " 'function_call': None,\n",
       " 'tool_calls': [{'id': 'call_7608b90e0af34e2993a7bd59814be625',\n",
       "   'function': {'arguments': '{\"query\": [\"London\", \"New York\", \"San Francisco\"]}',\n",
       "    'name': 'get_weather_data_for_cities'},\n",
       "   'type': 'function'}]}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_arguments = weather_response.dict()\n",
    "json_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8481a602-776d-4b1c-8d55-1eccbb472236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function name: get_weather_data_for_cities\n"
     ]
    }
   ],
   "source": [
    "# Extract specific items from the dict\n",
    "func_name = json_arguments['tool_calls'][0]['function']['name']\n",
    "print(f\"Function name: {func_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d570c590-9f11-4d59-92c0-d1d56611ce81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: {'query': ['London', 'New York', 'San Francisco']}\n"
     ]
    }
   ],
   "source": [
    "funcs = json_arguments['tool_calls'][0]['function']['arguments']\n",
    "funcs_args = json.loads(funcs)\n",
    "print(f\"Arguments: {funcs_args}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dc5f3d-e087-41db-a101-f96d1a43037f",
   "metadata": {},
   "source": [
    "#### Invoke the function from within our notebook.\n",
    "This is our downstream function being invoked with the extracted arguments\n",
    "from the JSON response generated by the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e57a178b-cdd5-47ca-9911-e3649f497791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over cities since we have a list\n",
    "cities = funcs_args['query']\n",
    "results = []\n",
    "for city in cities:\n",
    "    params = {'query': city,\n",
    "              'access_key': weather_api_key\n",
    "             }\n",
    "    result = get_weather_data_for_cities(params)\n",
    "    results.append(result)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "74885839-3282-4562-b536-7e32b149a0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'request': {'type': 'City',\n",
       "   'query': 'London, United Kingdom',\n",
       "   'language': 'en',\n",
       "   'unit': 'm'},\n",
       "  'location': {'name': 'London',\n",
       "   'country': 'United Kingdom',\n",
       "   'region': 'City of London, Greater London',\n",
       "   'lat': '51.517',\n",
       "   'lon': '-0.106',\n",
       "   'timezone_id': 'Europe/London',\n",
       "   'localtime': '2024-01-03 20:34',\n",
       "   'localtime_epoch': 1704314040,\n",
       "   'utc_offset': '0.0'},\n",
       "  'current': {'observation_time': '08:34 PM',\n",
       "   'temperature': 9,\n",
       "   'weather_code': 116,\n",
       "   'weather_icons': ['https://cdn.worldweatheronline.com/images/wsymbols01_png_64/wsymbol_0004_black_low_cloud.png'],\n",
       "   'weather_descriptions': ['Partly cloudy'],\n",
       "   'wind_speed': 17,\n",
       "   'wind_degree': 270,\n",
       "   'wind_dir': 'W',\n",
       "   'pressure': 995,\n",
       "   'precip': 0,\n",
       "   'humidity': 93,\n",
       "   'cloudcover': 50,\n",
       "   'feelslike': 6,\n",
       "   'uv_index': 1,\n",
       "   'visibility': 10,\n",
       "   'is_day': 'no'}},\n",
       " {'request': {'type': 'City',\n",
       "   'query': 'New York, United States of America',\n",
       "   'language': 'en',\n",
       "   'unit': 'm'},\n",
       "  'location': {'name': 'New York',\n",
       "   'country': 'United States of America',\n",
       "   'region': 'New York',\n",
       "   'lat': '40.714',\n",
       "   'lon': '-74.006',\n",
       "   'timezone_id': 'America/New_York',\n",
       "   'localtime': '2024-01-03 15:31',\n",
       "   'localtime_epoch': 1704295860,\n",
       "   'utc_offset': '-5.0'},\n",
       "  'current': {'observation_time': '08:31 PM',\n",
       "   'temperature': 6,\n",
       "   'weather_code': 122,\n",
       "   'weather_icons': ['https://cdn.worldweatheronline.com/images/wsymbols01_png_64/wsymbol_0004_black_low_cloud.png'],\n",
       "   'weather_descriptions': ['Overcast'],\n",
       "   'wind_speed': 13,\n",
       "   'wind_degree': 280,\n",
       "   'wind_dir': 'W',\n",
       "   'pressure': 1016,\n",
       "   'precip': 0,\n",
       "   'humidity': 50,\n",
       "   'cloudcover': 100,\n",
       "   'feelslike': 3,\n",
       "   'uv_index': 3,\n",
       "   'visibility': 16,\n",
       "   'is_day': 'yes'}},\n",
       " {'request': {'type': 'City',\n",
       "   'query': 'San Francisco, United States of America',\n",
       "   'language': 'en',\n",
       "   'unit': 'm'},\n",
       "  'location': {'name': 'San Francisco',\n",
       "   'country': 'United States of America',\n",
       "   'region': 'California',\n",
       "   'lat': '37.775',\n",
       "   'lon': '-122.418',\n",
       "   'timezone_id': 'America/Los_Angeles',\n",
       "   'localtime': '2024-01-03 12:34',\n",
       "   'localtime_epoch': 1704285240,\n",
       "   'utc_offset': '-8.0'},\n",
       "  'current': {'observation_time': '08:34 PM',\n",
       "   'temperature': 13,\n",
       "   'weather_code': 116,\n",
       "   'weather_icons': ['https://cdn.worldweatheronline.com/images/wsymbols01_png_64/wsymbol_0002_sunny_intervals.png'],\n",
       "   'weather_descriptions': ['Partly cloudy'],\n",
       "   'wind_speed': 11,\n",
       "   'wind_degree': 270,\n",
       "   'wind_dir': 'W',\n",
       "   'pressure': 1021,\n",
       "   'precip': 0,\n",
       "   'humidity': 72,\n",
       "   'cloudcover': 75,\n",
       "   'feelslike': 11,\n",
       "   'uv_index': 3,\n",
       "   'visibility': 16,\n",
       "   'is_day': 'yes'}}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
