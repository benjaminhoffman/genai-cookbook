{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749070e3-d395-4539-84e2-dbf76aad563e",
   "metadata": {},
   "source": [
    "## OpenAI Parallel Function calling: Query external SQLite DB\n",
    "\n",
    "<img src=\"images/gpt_parallel_function_calling_db.png\">\n",
    "\n",
    "This script demonstrates how to use the OpenAI API to call a function that queries a database.\n",
    "The model will generate a SQL query, generated form the user content in \n",
    "natural language, which will be executed against a SQLite database.\n",
    "\n",
    "All this demonstrates how to use the OpenAI API to call a function that interacts with an external data source,\n",
    "such as a database: SQLite, MySQL, PostgreSQL, etc.\n",
    "\n",
    "This is a modified version of the script from the OpenAI API cookbook. Partly based on the example [here](https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models)\n",
    "\n",
    "To use this notebook, you must follow the following steps:\n",
    "\n",
    "1. Install sqlite: `pip install sqlite3`\n",
    "2. run `python customer_sqlite_db.py`. This will create a fake `customers.db` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e113ac70-8211-41e4-b792-aed8632a639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import List\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from customer_db_utils import  execute_function_call, get_database_schema, connect_db\n",
    "from termcolor import colored  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbe73fd-e6d1-4676-ba36-41ea26cd00d9",
   "metadata": {},
   "source": [
    "#### Define some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e80fa8e3-2a5c-4a7a-b10f-d66d1911fda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(clnt:object, messages:object,\n",
    "                             tools=None, tool_choice=None, \n",
    "                             model=\"gpt4-turbo-preview\"):\n",
    "    \"\"\"\n",
    "    Send a chat completion request using the OpenAI API.\"\"\"\n",
    "    try:\n",
    "        response = clnt.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=tool_choice,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d4e8d52-fabc-47f8-9f5d-2e0c25754d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_conversation(messages: List[dict]):\n",
    "    \"\"\"\n",
    "    Print the conversation between the user, the assistant, and the function,\n",
    "    each with a different color for readability.\n",
    "    \"\"\"\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "    \n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232d933e-5dbe-4536-afdd-670fbe39af90",
   "metadata": {},
   "source": [
    "#### Load .env files for keys and models to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0762c14-162a-43fe-adb7-f907aa1ba692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-turbo-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "warnings.filterwarnings('ignore')\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89e2b32-a8e2-444d-aa3a-8567c62361f7",
   "metadata": {},
   "source": [
    "Create an OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "597a4153-0ff4-40fa-9d6d-029f2363f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "        api_key = openai.api_key,\n",
    "        base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaa1dff-6500-4270-b06e-75b7ce3676f5",
   "metadata": {},
   "source": [
    "### Step 0: Fetch the database schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fce4a38d-e798-496b-856d-4e50d5c18690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: customer_data\n",
      "Columns: customer_name, product_name, date_of_purchase, price_paid, city\n"
     ]
    }
   ],
   "source": [
    "conn = connect_db(\"customers.db\")\n",
    "database_schema_string = get_database_schema(conn)\n",
    "print(database_schema_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a7218b-6ed8-4fff-87ed-aa4018e459c2",
   "metadata": {},
   "source": [
    "### Step 1: define the function to call for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fdf7531-70a6-4a95-bb6e-cd449b3a945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"query_customer_database\",\n",
    "            \"description\": \"Use this function to answer user questions about fake customer database. Input should be a fully formed SQL query.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                         \"type\": \"string\",\n",
    "                         \"description\": f\"\"\"\n",
    "                                 SQL query extracting info to answer the user's question.\n",
    "                                 SQL should be written using this database schema: {database_schema_string}\n",
    "                                 The query should be returned in plain text, not in JSON.\n",
    "                                 \"\"\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"query\"],\n",
    "                },\n",
    "            }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5e6afc-9324-46ef-a426-04d30973329d",
   "metadata": {},
   "source": [
    "### Step 2: define the messages to send to the model\n",
    "\n",
    "The user content is expressed in natural language to query the database. This request will be converted into an SQL query and\n",
    "returned back to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb9a2dc9-f269-4b6f-938d-6bc8a1d5cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \n",
    "                 \"content\": \"\"\"\n",
    "                     Answer user questions by generating SQL queries against the Customer Database.\n",
    "                     SQL query extracting info to answer the user's question.\n",
    "                     SQL should be written using this database schema:\n",
    "                     {database_schema_string}\n",
    "                     The query should be returned in plain text, not in JSON\"\"\"})\n",
    "messages.append({\"role\": \"user\", \n",
    "                  \"content\": \"Hi, List at most five customer names, city they live in, products they bought, prices paid for the most expensive product\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fe4889-7e3c-4580-93f9-5d3c4a85a297",
   "metadata": {},
   "source": [
    "### Step 3: Send the messages and function call info to the model\n",
    "This request will generate a response (with an SQL generated by the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99b50700-0417-4fc1-9bab-aa0292b0ffe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8m5aqh3kVQbOUjoyTMBQZ8csHcCRV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_vVUF2Iyb8qE5WIY3y9pBaEWT', function=Function(arguments='{\"query\":\"SELECT customer_name, city, product_name, MAX(price_paid) AS price_paid FROM customer_data GROUP BY customer_name ORDER BY price_paid DESC LIMIT 5\"}', name='query_customer_database'), type='function')]))], created=1706471936, model='gpt-4-0125-preview', object='chat.completion', system_fingerprint='fp_376b7f78b9', usage=CompletionUsage(completion_tokens=35, prompt_tokens=211, total_tokens=246))\n"
     ]
    }
   ],
   "source": [
    "chat_response = chat_completion_request(client, messages, tools,\n",
    "                                            tool_choice={\"type\": \"function\", \n",
    "                                                          \"function\": {\"name\": \"query_customer_database\"}},\n",
    "                                            model=MODEL)\n",
    "print(chat_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f9b875f-ae12-4f37-9885-3f2562f8a352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_vVUF2Iyb8qE5WIY3y9pBaEWT', function=Function(arguments='{\"query\":\"SELECT customer_name, city, product_name, MAX(price_paid) AS price_paid FROM customer_data GROUP BY customer_name ORDER BY price_paid DESC LIMIT 5\"}', name='query_customer_database'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "# Extract the message returned by the model\n",
    "assistant_message = chat_response.choices[0].message\n",
    "print(assistant_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "194ef2a4-0e9b-4766-90f4-8da476ddc27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function(arguments='{\"query\":\"SELECT customer_name, city, product_name, MAX(price_paid) AS price_paid FROM customer_data GROUP BY customer_name ORDER BY price_paid DESC LIMIT 5\"}', name='query_customer_database')\n"
     ]
    }
   ],
   "source": [
    "# Extract the function call returned by the model\n",
    "assistant_message.content = str(assistant_message.tool_calls[0].function)\n",
    "print(assistant_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79f31a7f-356c-4a3a-ac7e-3a8c60ddcfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the function call query generated by the model with the\n",
    "# assistant role\n",
    "messages.append({\"role\": assistant_message.role, \"content\": assistant_message.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b1b985d-f6f4-4162-9c45-f077d7c619a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: \n",
      "                     Answer user questions by generating SQL queries against the Customer Database.\n",
      "                     SQL query extracting info to answer the user's question.\n",
      "                     SQL should be written using this database schema:\n",
      "                     {database_schema_string}\n",
      "                     The query should be returned in plain text, not in JSON\n",
      "\u001b[0m\n",
      "\u001b[32muser: Hi, List at most five customer names, city they live in, products they bought, prices paid for the most expensive product\n",
      "\u001b[0m\n",
      "\u001b[34massistant: Function(arguments='{\"query\":\"SELECT customer_name, city, product_name, MAX(price_paid) AS price_paid FROM customer_data GROUP BY customer_name ORDER BY price_paid DESC LIMIT 5\"}', name='query_customer_database')\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (query_customer_database): [('Virginia Clark', 'Aaronburgh', 'Laptop', 1000.0), ('Matthew Jacobs', 'Patricialand', 'Camera', 1000.0), ('Laura Brown', 'Port Denisemouth', 'Laptop', 1000.0), ('Kelli Vega', 'Port Lydiafort', 'Smartwatch', 1000.0), ('Kathryn Robinson', 'Sethtown', 'Shorts', 1000.0)]\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# check if the model wanted to call a function\n",
    "if assistant_message.tool_calls:\n",
    "    # call the function with the query generated by the model\n",
    "    results = execute_function_call(conn, assistant_message)\n",
    "    messages.append({\"role\": \"function\", \"tool_call_id\": assistant_message.tool_calls[0].id, \"name\": assistant_message.tool_calls[0].function.name, \"content\": results})\n",
    "    pretty_print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe4b7a0-8b8d-4a1f-923d-257dc77dec4c",
   "metadata": {},
   "source": [
    "### Step 4: Send more queries as messages to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44ec396b-7d1a-4fb9-8d76-fa049b1959fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"user\", \n",
    "                     \"content\": \"\"\"List all customer name, city, the product they bought, and price they paid \n",
    "                     and who live in Port Leefort, Lake Phillipview, East Deanburgh, and East Shelleyside.\"\"\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b48208-1469-4d78-991c-39f8c257af91",
   "metadata": {},
   "source": [
    "### Step 5: Send the messages and function call info to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c005b5b-a314-4bfe-ab1d-13f3d59ee642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8m5atIf2UADAZKttPCqSZo4S3Km7M', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_01Cu9wWUPDMWVxtSewirA9Ks', function=Function(arguments='{\"query\":\"SELECT customer_name, city, product_name, price_paid FROM customer_data WHERE city IN (\\'Port Leefort\\', \\'Lake Phillipview\\', \\'East Deanburgh\\', \\'East Shelleyside\\')\"}', name='query_customer_database'), type='function')]))], created=1706471939, model='gpt-4-0125-preview', object='chat.completion', system_fingerprint='fp_376b7f78b9', usage=CompletionUsage(completion_tokens=44, prompt_tokens=172, total_tokens=216))\n"
     ]
    }
   ],
   "source": [
    "chat_response = chat_completion_request(client, messages, tools,\n",
    "                                            tool_choice={\"type\": \"function\", \n",
    "                                                          \"function\": {\"name\": \"query_customer_database\"}},\n",
    "                                            model=MODEL)\n",
    "print(chat_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a196f49e-afd9-47c2-be1a-cc8b26859ecc",
   "metadata": {},
   "source": [
    "### Step 6: Get the messages returned by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08c98ad6-8954-42f2-87c8-c21c89560d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32muser: List all customer name, city, the product they bought, and price they paid \n",
      "                     and who live in Port Leefort, Lake Phillipview, East Deanburgh, and East Shelleyside.\n",
      "\u001b[0m\n",
      "\u001b[34massistant: Function(arguments='{\"query\":\"SELECT customer_name, city, product_name, price_paid FROM customer_data WHERE city IN (\\'Port Leefort\\', \\'Lake Phillipview\\', \\'East Deanburgh\\', \\'East Shelleyside\\')\"}', name='query_customer_database')\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (query_customer_database): [('Joseph Peterson', 'Port Leefort', 'Shorts', 155.94), ('Robert Rich', 'East Shelleyside', 'Pants', 647.51), ('Michael Sims', 'Lake Phillipview', 'Headphones', 43.32), ('Phyllis Moon', 'East Deanburgh', 'Laptop', 160.65), ('Matthew Estrada', 'Lake Phillipview', 'Laptop', 902.68)]\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "assistant_message = chat_response.choices[0].message\n",
    "assistant_message.content = str(assistant_message.tool_calls[0].function)\n",
    "messages.append({\"role\": assistant_message.role, \"content\": assistant_message.content})\n",
    "if assistant_message.tool_calls:\n",
    "    results = execute_function_call(conn, assistant_message)\n",
    "    messages.append({\"role\": \"function\", \"tool_call_id\": assistant_message.tool_calls[0].id, \"name\": assistant_message.tool_calls[0].function.name, \"content\": results})\n",
    "    pretty_print_conversation(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d65a7fb-882d-478d-be0d-e530450f2fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
