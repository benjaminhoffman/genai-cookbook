{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa1d759c-3fc2-4409-a40d-37e4a764e67b",
   "metadata": {},
   "source": [
    "# How to use OpenAI function calling with LLMs\n",
    "Function calling extends the power capabilities of LLMs. It allolws you to format\n",
    "the output of an LLM response into a JSON object, which then can be fed down stream\n",
    "to an actual function as a argument to process the response.\n",
    "\n",
    "OpenAI documention states the basic steps involved in function calling: \n",
    "\n",
    "1. Call the model with the user query and a set of functions defined in the functions parameter.\n",
    "2. The model can choose to call one or more functions; if so, the content will be a stringified JSON object adhering to your custom schema (note: the model may hallucinate parameters).\n",
    "3. Parse the string into JSON in your code, and call your function with the provided arguments if they exist.\n",
    "4. Call the model again by appending the function response as a new message, and let the model summarize the results back to the user.\n",
    "\n",
    "<img src=\"./images/gpt_function_calling.png\">\n",
    "\n",
    "Let's first demonstrate how we use this feature. Let's first specify a function and use the API to generate function arguments.\n",
    "\n",
    "## How to generate function arguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "62afe6cc-451f-49b3-960b-b53933c52d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3671c826-12d1-4fac-8882-8a7494290cfe",
   "metadata": {},
   "source": [
    "Load our .env file with respective API keys and base url endpoints. Here you can either use OpenAI or Anyscale Endpoints. **Note**: Function calling for Anyscale Endpoints is coming soon. Not yet ready as of writing this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c8946842-0e4b-4bf3-805f-3cd336a22b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "warnings.filterwarnings('ignore')\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faf02e1-8ac0-4ea1-b227-6d5182eb166f",
   "metadata": {},
   "source": [
    "Define some utitilty functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b3f2e800-cb7d-4e81-b4ed-3d74e57f8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d4e5ea43-460f-49f3-9711-2f526cf03529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commpletion(clnt: object, model: str, user_content:str, functions: object) -> object:\n",
    "    chat_completion = clnt.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_content}],\n",
    "        functions = [{\n",
    "            \"name\": \"add_prime_numbers\",\n",
    "            \"description\": \"Get a list 20 integer prime numbers between 2 and 100\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"prime_numbers\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"A list of 20 prime numbers\"\n",
    "                        },\n",
    "                        \"description\": \"List of of 20 prime numbers to be added\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"add_prime_numbers\"]\n",
    "            }\n",
    "        }],\n",
    "        function_call={\"name\": \"add_prime_numbers\"}\n",
    "    )\n",
    "    response = chat_completion.choices[0].message\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "be5d27c7-d70c-43b7-941c-e042ea1e8d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "def add_prime_numbers(p_numbers: Dict[str, List[int]]) -> int:\n",
    "    return sum(p_numbers[\"prime_numbers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c2f07-4a8f-440d-971f-dc46402ac8bc",
   "metadata": {},
   "source": [
    "Define the functions argument and function specification as part of the message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "06958400-d76b-4df3-b337-ee9d99b684b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_content = \"Add 20 random prime numbers between 2 and 100?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "4219f732-5b1c-4c3f-b1cd-1c96af1c998a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"prime_numbers\":[2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71]}', name='add_prime_numbers'), tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "response = get_commpletion(client, MODEL, user_content, functions)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a5b24-1e77-4c7e-86e0-a52abe13df5b",
   "metadata": {},
   "source": [
    "#### Example 1: Extract the generated arguments\n",
    "Let's generate arguments to compute the sum of random\n",
    "prime numbers between 2 and 100. These would a list fed\n",
    "into a function that can compute its sum.\n",
    "\n",
    "The idea is here is to nudge the LLM to generate JSON object, which can be easily converted into a Python dictionary, as an  argument for a function downstream to compute the sum.\n",
    "\n",
    "We can convert the resonse into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "85dcd468-65c6-4bd1-bb64-82886b135594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4b02d50f-fb76-4c27-ac04-17bf363c1e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': None,\n",
       " 'role': 'assistant',\n",
       " 'function_call': {'arguments': '{\"prime_numbers\":[2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71]}',\n",
       "  'name': 'add_prime_numbers'},\n",
       " 'tool_calls': None}"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_arguments = response.dict()\n",
    "json_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "51960367-77c3-4b32-bb70-73f776b6c413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function name: add_prime_numbers\n"
     ]
    }
   ],
   "source": [
    "#Extract specific items from the dict\n",
    "print(f\"Function name: {json_arguments['function_call']['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "985ab5e1-1466-4d43-9e14-a8f68c57cede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: {'prime_numbers': [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71]}\n"
     ]
    }
   ],
   "source": [
    "funcs = response.dict()['function_call']['arguments']\n",
    "funcs_args = json.loads(funcs)\n",
    "print(f\"Arguments: {funcs_args}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1499af1d-9f09-4756-8344-02d9b1144676",
   "metadata": {},
   "source": [
    "#### Invoke the function from within your app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ffcc917f-65c7-4009-ad6f-40134da6f5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "639"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_of_prime = add_prime_numbers(funcs_args)\n",
    "sum_of_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0af4ccd-0f7d-4333-83f8-5efcd548b0e5",
   "metadata": {},
   "source": [
    "#### Example 2: Extract the generated arguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "0d6210fa-ca89-4495-afce-f7493c80cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "def create_map(path: str) -> None:\n",
    "    # Create a base map\n",
    "    m = folium.Map(location=[20,0], tiles=\"OpenStreetMap\", zoom_start=2)\n",
    "    \n",
    "    # Adding markers for each city\n",
    "    folium.Marker([51.5074, -0.1278], popup='London').add_to(m)\n",
    "    folium.Marker([40.7128, -74.0060], popup='New York').add_to(m)\n",
    "    folium.Marker([37.7749, -122.4194], popup='San Francisco').add_to(m)\n",
    "\n",
    "    # Display the map\n",
    "    m.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2bd21987-c23e-4a26-bbac-88324003cc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"400\"\n",
       "            src=\"./world_map_with_cities.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x12c004910>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "# Assuming the HTML file is named 'example.html' and located in the same directory as the Jupyter Notebook\n",
    "html_file_path = './world_map_with_cities.html'\n",
    "create_map(html_file_path)\n",
    "\n",
    "# Display the HTML file in the Jupyter Notebook\n",
    "IFrame(src=html_file_path, width=700, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ed9b3-4e97-4d07-9796-c49f0f0f44e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
