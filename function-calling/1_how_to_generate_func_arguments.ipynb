{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa1d759c-3fc2-4409-a40d-37e4a764e67b",
   "metadata": {},
   "source": [
    "# How to use function calling with LLMs\n",
    "Function calling extends the power capabilities of LLMs. It allolws you to format\n",
    "the output of an LLM response into a JSON object, which then can be fed down stream\n",
    "to an actual function as a argument to process the response.\n",
    "\n",
    "OpenAI documention states the basic steps involved in function calling: \n",
    "\n",
    "1. Call the model with the user query and a set of functions defined in the functions parameter.\n",
    "2. The model can choose to call one or more functions; if so, the content will be a stringified JSON object adhering to your custom schema (note: the model may hallucinate parameters).\n",
    "3. Parse the string into JSON in your code, and call your function with the provided arguments if they exist.\n",
    "4. Call the model again by appending the function response as a new message, and let the model summarize the results back to the user.\n",
    "\n",
    "Let's first demonstrate how we use this feature. Let's first specify a function and use the API to generate function arguments.\n",
    "\n",
    "## How to generate function arguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62afe6cc-451f-49b3-960b-b53933c52d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3671c826-12d1-4fac-8882-8a7494290cfe",
   "metadata": {},
   "source": [
    "Load our .env file with respective API keys and base url endpoints. Here you can either use OpenAI or Anyscale Endpoints. **Note**: Function calling for Anyscale Endpoints is coming soon. Not yet ready as of writing this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8946842-0e4b-4bf3-805f-3cd336a22b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "warnings.filterwarnings('ignore')\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faf02e1-8ac0-4ea1-b227-6d5182eb166f",
   "metadata": {},
   "source": [
    "Define some utitilty functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3f2e800-cb7d-4e81-b4ed-3d74e57f8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e5ea43-460f-49f3-9711-2f526cf03529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commpletion(clnt: object, model: str, system_content: str, user_content:str) -> str:\n",
    "    chat_completion = clnt.chat.completions.create(\n",
    "        model=model,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_content},\n",
    "              {\"role\": \"user\", \"content\": user_content}],\n",
    "    temperature = 0.8)\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c2f07-4a8f-440d-971f-dc46402ac8bc",
   "metadata": {},
   "source": [
    "Define the tools argument and function specification as part of the message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "857162be-3e27-42cf-982b-683c39c54e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"sum_prime_numbers\",\n",
    "            \"description\": \"Compute the list of prime numbers\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"numbers\": {\n",
    "                        \"type\": \"list\",\n",
    "                        \"description\": \"list of ten integer prime numbers between 2 and 100\",\n",
    "                    },\n",
    "                    \"format\": {\n",
    "                        \"type\": \"list\",\n",
    "                        \"description\": \"list of ten integer prime numbers between 2 and 100\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"numbers\", \"format\"],\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06958400-d76b-4df3-b337-ee9d99b684b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"Don't make assumptions about what values to plug into functions. \n",
    "                    If the request is ambigous ask for clarification.\n",
    "                 \"\"\"\n",
    "user_content = \"\"\"Generate a list of ten random prime numbers between 2 and 100. Do generate \n",
    "Python code. Instead return a list of 10 random prime numbers and put them in a list.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4219f732-5b1c-4c3f-b1cd-1c96af1c998a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: https://api.openai.com/v1 ...\n",
      "\n",
      "Certainly! Here is a list of ten random prime numbers between 2 and 100:\n",
      "\n",
      "[3, 17, 41, 67, 73, 89, 37, 23, 59, 97]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {openai.api_base} ...\\n\")\n",
    "response = get_commpletion(client, MODEL, system_content, user_content)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0505965-32ac-4479-a000-482645c9e49b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
