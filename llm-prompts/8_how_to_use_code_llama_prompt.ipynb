{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326936b2-05db-465d-846c-b07f2ace8000",
   "metadata": {},
   "source": [
    "Meta AI released a series of [Code Llama models](https://ai.meta.com/blog/code-llama-large-language-model-coding/). \n",
    "\n",
    "Using any of the model series shows the path used for its respective\n",
    "training.\n",
    "\n",
    "<img src=\"images/meta_code_llama_series.png\" height=\"30%\" width=\"60%\">\n",
    "\n",
    "This notebook shows some cases how to prompt the LLM to generate \n",
    "Python and SQL code using the Anyscale Endpoints.\n",
    "\n",
    "<img src=\"images/codllama70b.png\"  height=\"25%\" width=\"50%\">\n",
    "\n",
    "**Note**: \n",
    "To run any of these relevant notebooks you will need an account on Anyscale Endpoints, Anthropic, or OpenAI, depending on what model you elect, along with the respective environment file. Use the template environment files to create respective `.env` file for either Anyscale Endpoints, Anthropic, or OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7920f30d-45d3-4ed6-a11b-745973d22fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16843632-a590-4624-850f-bf619dd2122a",
   "metadata": {},
   "source": [
    "Load the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbd1b858-df9e-45c2-a502-1ef501b4de31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=codellama/CodeLlama-70b-Instruct-hf; base=https://api.endpoints.anyscale.com/v1\n"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "warnings.filterwarnings('ignore')\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6df4a141-61d2-4729-9cba-e7cc1954184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OpenAI client, which can be used transparently with Anyscale \n",
    "# Endpoints too\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b210270-a724-4546-900d-f85bb1e3cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to send and fetch response\n",
    "\n",
    "def get_commpletion(clnt: object, model: str, system_content: str, user_content:str) -> str:\n",
    "    chat_completion = clnt.chat.completions.create(\n",
    "        model=model,\n",
    "    messages=[{\"role\": \"system\", \"content\": system_content},\n",
    "              {\"role\": \"user\", \"content\": user_content}],\n",
    "    temperature = 0.8)\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26fe78f3-6250-4c39-afeb-cbbcdaba7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOLD_BEGIN = \"\\033[1m\"\n",
    "BOLD_END = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0602d78e-e70c-4f67-9f6a-73d3551de252",
   "metadata": {},
   "source": [
    "#### Example 1: Generate a Python code to compute the value of PI\n",
    "\n",
    "Use the [CO-STAR](https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41) framework for prompting\n",
    "\n",
    "1. **Context** - provide the background\n",
    "2. **Objective** (or Task) - define the task to be performed\n",
    "3. **Style** - instruct a writing style. Kind of sentences; formal, informal, magazine sytle, colloqiual, or allude to a know style.\n",
    "4. **Audience** - who's it for?\n",
    "5. **Response** - format, Text, Python, SQL, JSON, etc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d38fa3-9405-43d3-89df-8e334dee6903",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are supreme repository of knowledge, and assistant\n",
    "code Co-pilot for developer to assist them in generating sample code, inclding\n",
    "in langauges such as Python, JavaScript, Java, C, C++, and shell script.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2461dd5c-6afd-4635-b710-e7cee97f2218",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "# CONTEXT #\n",
    "I want to generate Python code to showcase our product feature for\n",
    "serving open source large language models such as Code Llama series\n",
    "on Anyscale Endpoints. The product feature is Anyscale Endpoints, which \n",
    "serves all Llama series models and the Mistral series too. For this\n",
    "instance, we want to show case Code Llama 70B just released by Meta AI, and \n",
    "now hosted by Anyscale Endpoints\n",
    "\n",
    "#############\n",
    "\n",
    "# OBJECTIVE # \n",
    "Create a Python code to compute the value of PI using monte carlo method.\n",
    "\n",
    "#############\n",
    "\n",
    "# STYLE #\n",
    "Use the Google style of formating Python code.\n",
    "\n",
    "#############\n",
    "\n",
    "# AUDIENCE #\n",
    "Your code should be well commented and aimed at both beginner and\n",
    "intermediate Python programers. \n",
    "\n",
    "#############\n",
    "\n",
    "# RESPONSE #\n",
    "Generate the entire code that can be easily copy and pasted into file: 'compute_pi.py'. Also,\n",
    "provide specific instructions how to compile the code, run it, and any \n",
    "additional python packages it needs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d730cfe-544c-4947-b767-0b3b2924eeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAnswer - Python code\u001b[0m:\n",
      " \n",
      "```python\n",
      "#!/usr/bin/env python\n",
      "\n",
      "# compute_pi.py\n",
      "# by Anyscale Team\n",
      "# This Python script computes the value of PI using the Monte Carlo method.\n",
      "# It's aimed at beginners and intermediate Python developers.\n",
      "\n",
      "# Let's import the necessary Python modules\n",
      "# We'll use random to generate random points and math to compute the value of PI\n",
      "import random\n",
      "import math\n",
      "\n",
      "# We'll also import pytest to run tests on our code\n",
      "# Skip this if you're not familiar with pytest\n",
      "import pytest\n",
      "\n",
      "# This function generates a random point on a unit square\n",
      "def random_point():\n",
      "    x = random.random()\n",
      "    y = random.random()\n",
      "    return x, y\n",
      "\n",
      "# This function checks if a point lies inside a circle with a radius of 1\n",
      "def point_inside_circle(point):\n",
      "    x, y = point\n",
      "    return x**2 + y**2 < 1\n",
      "\n",
      "# This function computes the value of PI using the Monte Carlo method\n",
      "# It takes the number of iterations as input\n",
      "def compute_pi(n_iterations):\n",
      "    n_inside_circle = 0\n",
      "\n",
      "    for _ in range(n_iterations):\n",
      "        point = random_point()\n",
      "        if point_inside_circle(point):\n",
      "            n_inside_circle += 1\n",
      "\n",
      "    pi = 4 * n_inside_circle / n_iterations\n",
      "    return pi\n",
      "\n",
      "# This function tests the accuracy of our 'compute_pi()' function\n",
      "# It checks if the computed value of PI lies within 1% of the actual value\n",
      "def test_compute_pi():\n",
      "    n_iterations = 1000000\n",
      "    computed_pi = compute_pi(n_iterations)\n",
      "    assert abs(computed_pi - math.pi) < 0.01 * math.pi\n",
      "\n",
      "# This is the main function that runs our script\n",
      "def main():\n",
      "    n_iterations = 1000000\n",
      "    computed_pi = compute_pi(n_iterations)\n",
      "\n",
      "    print(\"Approximate value of PI using Monte Carlo method:\", computed_pi)\n",
      "    print(\"Actual value of PI:\", math.pi)\n",
      "\n",
      "# This is the entry point of our script\n",
      "# It runs the main function if this script is executed directly\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "Here's a brief explanation of the code:\n",
      "\n",
      "*   `random_point()`: This function generates a random point on a unit square by generating two random numbers between 0 and 1.\n",
      "*   `point_inside_circle()`: This function checks if a point lies inside a circle with a radius of 1.\n",
      "*   `compute_pi()`: This function computes the value of PI using the Monte Carlo method by generating multiple random points and checking if they lie inside the circle.\n",
      "*   `test_compute_pi()`: This function tests the accuracy of our `compute_pi()` function by checking if the computed value of PI lies within 1% of the actual value.\n",
      "*   `main()`: This is the main function that runs our script. It computes PI using `compute_pi()` and prints the result.\n",
      "\n",
      "To run this code, you'll need to install the `pytest` package:\n",
      "\n",
      "```\n",
      "pip install pytest\n",
      "```\n",
      "\n",
      "Then, you can run the code by executing the script:\n",
      "\n",
      "```\n",
      "python compute_pi.py\n",
      "```\n",
      "\n",
      "The output should be something like this:\n",
      "\n",
      "```\n",
      "Approximate value of PI using Monte Carlo method: 3.141186\n",
      "Actual value of PI: 3.141592653589793\n",
      "```\n",
      "\n",
      "If you want to run the test, you can execute:\n",
      "\n",
      "```\n",
      "pytest compute_pi.py\n",
      "```\n",
      "\n",
      "The output should be something like this:\n",
      "\n",
      "```\n",
      "=============================================== test session starts ================================================\n",
      "platform linux -- Python 3.6.13, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "rootdir: /home/anyscale/code\n",
      "collected 1 item\n",
      "\n",
      "compute_pi.py .                                                                                              [100%]\n",
      "\n",
      "============================================= 1 passed in 1.38s =============================================\n",
      "```\n",
      "\n",
      "This test checks if the computed value of PI lies within 1% of the actual value (3.141592653589793). If the computed value is outside this range, the test will fail.\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, user_prompt)\n",
    "print(f\"\\n{BOLD_BEGIN}Answer - Python code{BOLD_END}:\\n {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d4de9f-462e-43ee-bbd0-1c1209d15dfe",
   "metadata": {},
   "source": [
    "### Example 2: Generate a Python code generate fractions\n",
    "\n",
    "Generate Python code that a) generates fractions between 1 and 10, finds and common denominator, and computes the sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff4491a2-8adb-41ec-9cc0-0af6168349d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "# CONTEXT #\n",
    "I want to generate Python code to showcase our product feature for\n",
    "serving open source large language models such as Code Llama series\n",
    "on Anyscale Endpoints. The product feature is Anyscale Endpoints, which \n",
    "serves all Llama series models and the Mistral series too. For this\n",
    "instance, we want to show case Code Llama 70B just released by Meta AI, and \n",
    "now hosted by Anyscale Endpoints\n",
    "\n",
    "#############\n",
    "\n",
    "# OBJECTIVE # \n",
    "Create a Python code that generates a list of fractions between 1 and 10.\n",
    "It then generates a common denominator, and adds the sum of all fractions.\n",
    "\n",
    "#############\n",
    "\n",
    "# STYLE #\n",
    "Use the Google style of formating Python code.\n",
    "\n",
    "#############\n",
    "\n",
    "# AUDIENCE #\n",
    "Your code should be well commented and aimed at both beginner and\n",
    "intermediate Python programers. \n",
    "\n",
    "#############\n",
    "\n",
    "# RESPONSE #\n",
    "Generate the entire code that can be easily copy and pasted into file: 'add_fractions.py'. Also,\n",
    "provide specific instructions how to compile the code, run it, and any \n",
    "additional python packages it needs. The final output of the code\n",
    "should be a list of fractions genetated, their sum, and their common denominator.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb76dc03-8f1b-4570-96b2-a65f949941fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAnswer - Python code\u001b[0m:\n",
      " 1. Install dependencies:\n",
      "    * We will use the `fractions` module in Python 3 to generate fractions. Run the following command to install the module:\n",
      "    ```\n",
      "    pip install fractions\n",
      "    ```\n",
      "2. Create a file named `add_fractions.py`.\n",
      "3. Copy and paste the following code:\n",
      "\n",
      "```python\n",
      "# add_fractions.py\n",
      "\n",
      "from fractions import Fraction\n",
      "\n",
      "# Create a list of fractions between 1 and 10\n",
      "fractions = [Fraction(i, 10) for i in range(1, 10)]\n",
      "\n",
      "# Calculate the sum of all fractions\n",
      "sum_fractions = sum(fractions, 0)\n",
      "\n",
      "# Calculate the common denominator\n",
      "common_denominator = sum_fractions.denominator\n",
      "\n",
      "# Print the result\n",
      "print(\"Fractions:\")\n",
      "for f in fractions:\n",
      "    print(f\" - {f}\")\n",
      "print()\n",
      "print(f\"Sum: {sum_fractions}\")\n",
      "print(f\"Common Denominator: {common_denominator}\")\n",
      "```\n",
      "\n",
      "4. Run the code using the command:\n",
      "\n",
      "```\n",
      "python add_fractions.py\n",
      "```\n",
      "\n",
      "Example output:\n",
      "\n",
      "```\n",
      "$ python add_fractions.py\n",
      "Fractions:\n",
      " - 1/10\n",
      " - 1/5\n",
      " - 3/10\n",
      " - 2/5\n",
      " - 1/2\n",
      " - 3/5\n",
      " - 7/10\n",
      " - 4/5\n",
      " - 9/10\n",
      "\n",
      "Sum: 59/50\n",
      "Common Denominator: 50\n",
      "```\n",
      "\n",
      "5. We can further simplify the code by removing the `fractions` list and calculating the sum directly as follows:\n",
      "\n",
      "```python\n",
      "# add_fractions_simplified.py\n",
      "\n",
      "from fractions import Fraction\n",
      "\n",
      "# Calculate the sum of all fractions\n",
      "sum_fractions = sum(Fraction(i, 10) for i in range(1, 10))\n",
      "\n",
      "# Calculate the common denominator\n",
      "common_denominator = sum_fractions.denominator\n",
      "\n",
      "# Print the result\n",
      "print(f\"Sum: {sum_fractions}\")\n",
      "print(f\"Common Denominator: {common_denominator}\")\n",
      "```\n",
      "\n",
      "6. Run the simplified code using the command:\n",
      "\n",
      "```\n",
      "python add_fractions_simplified.py\n",
      "```\n",
      "\n",
      "Example output:\n",
      "\n",
      "```\n",
      "$ python add_fractions_simplified.py\n",
      "Sum: 59/50\n",
      "Common Denominator: 50\n",
      "```\n",
      "\n",
      "7. Now, we can add some extra code to generate the Code Llama 70B model and serve it using Anyscale Endpoints. Here's a sample code with inline comments:\n",
      "\n",
      "```python\n",
      "# add_fractions_with_llama_70b.py\n",
      "\n",
      "# Import necessary libraries\n",
      "from fractions import Fraction\n",
      "from meta.pretrain.featurize.featurize import Featurizer  # This is a Meta AI library\n",
      "from anyscale.sdk import Model  # This is an Anyscale Endpoints library\n",
      "\n",
      "# Load the Code Llama 70B model\n",
      "llama_70b = Model.from_pretrained(\"code-llama-70B\")\n",
      "\n",
      "# Create a list of fractions between 1 and 10\n",
      "fractions = [Fraction(i, 10) for i in range(1, 10)]\n",
      "\n",
      "# Calculate the sum of all fractions\n",
      "sum_fractions = sum(fractions, 0)\n",
      "\n",
      "# Calculate the common denominator\n",
      "common_denominator = sum_fractions.denominator\n",
      "\n",
      "# Print the result\n",
      "print(\"Fractions:\")\n",
      "for f in fractions:\n",
      "    print(f\" - {f}\")\n",
      "print()\n",
      "print(f\"Sum: {sum_fractions}\")\n",
      "print(f\"Common Denominator: {common_denominator}\")\n",
      "\n",
      "\n",
      "#---------------Serve the model using Anyscale Endpoints----------------------\n",
      "\n",
      "# Initialize the Anyscale Endpoints model\n",
      "endpoint = Endpoint(\"Code Llama 70B\")\n",
      "\n",
      "# Specify the input and output format\n",
      "input_format = \"string\"\n",
      "output_format = \"string\"\n",
      "\n",
      "# Define the endpoint's predict function\n",
      "def predict(input_str):\n",
      "    # Convert input to tokens\n",
      "    input_tokens = Featurizer.featurize(input_str)\n",
      "    \n",
      "    # Run the model\n",
      "    prediction = llama_70b(input_tokens)\n",
      "    \n",
      "    # Convert output to string\n",
      "    output_str = str(prediction)\n",
      "    \n",
      "    return output_str\n",
      "\n",
      "# Deploy the model\n",
      "endpoint.deploy(predict, input_format, output_format)\n",
      "\n",
      "# Print the endpoint URL for accessing the model\n",
      "print(f\"Endpoint URL: {endpoint.url}\")\n",
      "```\n",
      "\n",
      "8. Run the code using the command:\n",
      "\n",
      "```\n",
      "python add_fractions_with_llama_70b.py\n",
      "```\n",
      "\n",
      "Example output:\n",
      "\n",
      "```\n",
      "$ python add_fractions_with_llama_70b.py\n",
      "Fractions:\n",
      " - 1/10\n",
      " - 1/5\n",
      " - 3/10\n",
      " - 2/5\n",
      " - 1/2\n",
      " - 3/5\n",
      " - 7/10\n",
      " - 4/5\n",
      " - 9/10\n",
      "\n",
      "Sum: 59/50\n",
      "Common Denominator: 50\n",
      "Endpoint URL: https://api.anyscale.com/<your_token>/Code-Llama-70B/v0/predict\n",
      "```\n",
      "\n",
      "9. Now, you can access the model hosted on Anyscale Endpoints by sending HTTP requests to the endpoint URL. The model takes a string as input and returns the result as a string.\n",
      "\n",
      "Please note that this is just a sample code and you may need to modify it according to your specific requirements.\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, user_prompt)\n",
    "print(f\"\\n{BOLD_BEGIN}Answer - Python code{BOLD_END}:\\n {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d07e61-bb71-4540-a9ab-efaaf37a8773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
