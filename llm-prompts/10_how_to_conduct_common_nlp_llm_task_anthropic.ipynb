{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39330ca8-0778-405c-8d1f-2c31e190ebde",
   "metadata": {},
   "source": [
    "## Natural language processing (NLP) LLM Tasks\n",
    "This notebook goes a bit futher with diverse examples to demonstrate various tasks, emphasizing effective usage of prompt engineering through practical instances and using [CO-STAR prompt framework](https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41) for \n",
    "eliciting the best response from the LLM\n",
    "\n",
    "The tasks explored in this notebook, using sophiscated prompting techniques, show *how-to* code examples for common natural language understanfing capabilites of a generalized LLM, such as ChatGPT and Llama 2 series:\n",
    "\n",
    " * Text generation or completion\n",
    " * Text summarization\n",
    " * Text extraction\n",
    " * Text classification or sentiment analysis\n",
    " * Text categorization\n",
    " * Text transformation and translation\n",
    " * Simple and complex reasoning\n",
    "\n",
    "<img src=\"./images/llm_prompt_req_resp.png\" height=\"35%\" width=\"%65\">\n",
    "\n",
    "**Note**: \n",
    "To run any of these relevant notebooks you will need an account on Anyscale Endpoints, Anthropic, or OpenAI, depending on what model you elect, along with the respective environment file. Use the template environment files to create respective `.env` file for either Anyscale Endpoints, Anthropic, or OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798bde8f-44a7-4e9f-ba30-0ffccd1d4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "from anthropic import Anthropic\n",
    "from llm_clnt_factory_api import ClientFactory, get_commpletion\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d617225a-eb51-4d76-a324-bc1547759d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOLD_BEGIN = \"\\033[1m\"\n",
    "BOLD_END = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249c0446-7d74-402b-b7a5-9ab6f1d59224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=claude-3-opus-20240229; base=Anthropic\n"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "warnings.filterwarnings('ignore')\n",
    "api_key = os.getenv(\"ANTHROPIC_API_KEY\", None)\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={'Anthropic'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffe0749-0dfa-4eb5-b4d1-78c93c56f406",
   "metadata": {},
   "source": [
    "#### Creat an anthropic client using our factory class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b45071b3-6e6e-497b-9126-ab592053d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_factory = ClientFactory()\n",
    "client_type = \"anthropic\"\n",
    "client_factory.register_client(client_type, Anthropic)\n",
    "client_kwargs = {\"api_key\": api_key}\n",
    "# create the client\n",
    "client = client_factory.create_client(client_type, **client_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f06061-ea86-4e09-b006-9a0c61f92e33",
   "metadata": {},
   "source": [
    "## Text generation or completion\n",
    "In this simple task, we use an LLM to generate text by finishing an incomplete user content provided in the prompt. For example,\n",
    "by providing an incomplete prompt such as \"On a cold winter night, the stray dog ...\". \n",
    "\n",
    "Let's try a few text generation or completion tasks by providing partial prompts in the user content. You will surprised at its fluency and coherency in the generated text.\n",
    "\n",
    "For prompting, we use the C0-STAR framework.\n",
    "\n",
    "<img src=\"./images/co-star-framework.png\" height=\"35%\" width=\"%65\">\n",
    "\n",
    "\n",
    "**(C): Context: Provide background and information on the task**\n",
    "\n",
    "**(O): Objective: Define the task that you want the LLM to perform**\n",
    "\n",
    "**(S): Style: Specify the writing style you want the LLM to use**\n",
    "\n",
    "**(T): Set the attidue of the response**\n",
    "\n",
    "**(A): Audience: Idenfiy who the response is for**\n",
    "\n",
    "**(R): Provide the response format**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07fbcbf8-0ccc-4fd4-a27d-a27c1ad14ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are master of all knowledge, and a helpful sage.\n",
    "                    You must complete any incomplete sentence by drawing from your vast\n",
    "                    knowledge about history, literature, science, social science, philosophy, religion, economics, \n",
    "                    sports, etc. Do not make up any responses.\n",
    "                  \"\"\"\n",
    "\n",
    "user_prompts =  [\"On cold winter nights, the wolves in Siberia ...\",\n",
    "                 \"On the day Franklin Benjamin realized his passion for printer, ...\",\n",
    "                 \"During the final World Cup 1998 when France beat Brazil in Paris, ...\",\n",
    "                 \"Issac Newton set under a tree when an apple fell...\"\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c39358d-f343-4596-bd28-5f36a3ba85d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Anthropic ...\n",
      "\n",
      "\n",
      "\u001b[1mPrompt:\u001b[0m On cold winter nights, the wolves in Siberia ...\n",
      "\n",
      "\u001b[1mAnswer:\u001b[0m On cold winter nights, the wolves in Siberia howl in unison, their eerie chorus echoing across the frozen tundra. These resilient creatures, adapted to survive in one of the harshest environments on Earth, form tight-knit packs to hunt prey and protect their territory. Their thick, insulating fur allows them to withstand temperatures that plummet to -50°C (-58°F), while their keen senses help them navigate the vast, snow-covered landscape. Siberian wolves, primarily a subspecies of grey wolf, play a crucial role in maintaining the balance of the ecosystem by controlling the populations of large herbivores such as elk and reindeer. Despite their fearsome reputation, these majestic animals are an integral part of the Siberian wilderness, embodying the untamed spirit of the region.\n",
      "\n",
      "\u001b[1mPrompt:\u001b[0m On the day Franklin Benjamin realized his passion for printer, ...\n",
      "\n",
      "\u001b[1mAnswer:\u001b[0m Here is my attempt at completing the paragraph:\n",
      "\n",
      "\n",
      "On the day Franklin Benjamin realized his passion for printing, his life changed forever. As a young apprentice in his brother's print shop, Franklin discovered the power of the printed word to spread ideas and shape opinions. He threw himself into mastering the craft, spending long hours setting type and operating the printing press. Franklin's sharp mind and tireless work ethic allowed him to quickly surpass his peers and establish his own successful printing business. This early passion laid the foundation for Franklin's later accomplishments as an inventor, scientist, statesman and Founding Father of the United States.\n",
      "\n",
      "\n",
      "The paragraph provides relevant details about Franklin's early life as a printer's apprentice, how this experience ignited his passion, and the later impact this had on his storied career. It uses a mix of simple, compound and complex sentences to convey the information in a concise, engaging style appropriate for a literary magazine targeting curious college students. Please let me know if you would like me to modify anything in the paragraph.\n",
      "\n",
      "\u001b[1mPrompt:\u001b[0m During the final World Cup 1998 when France beat Brazil in Paris, ...\n",
      "\n",
      "\u001b[1mAnswer:\u001b[0m During the final World Cup 1998 when France beat Brazil in Paris, the host nation celebrated its first-ever World Cup victory. France's 3-0 triumph over the defending champions was a momentous occasion, as the French team, led by captain Didier Deschamps and star player Zinedine Zidane, put on a dominant performance. The match, played at the Stade de France in front of a capacity crowd of 80,000 spectators, saw Zidane score two goals in the first half, while Emmanuel Petit added a third in the closing minutes. The victory marked a significant milestone for French football and sparked nationwide celebrations, with an estimated one million people gathering on the Champs-Élysées to revel in the historic achievement.\n",
      "\n",
      "\u001b[1mPrompt:\u001b[0m Issac Newton set under a tree when an apple fell...\n",
      "\n",
      "\u001b[1mAnswer:\u001b[0m Isaac Newton sat under a tree when an apple fell on his head, inspiring his groundbreaking insight into the fundamental force of gravity. This serendipitous event led Newton to formulate the universal law of gravitation, which states that every particle in the universe attracts every other particle with a force proportional to the product of their masses and inversely proportional to the square of the distance between them. Newton's discovery revolutionized our understanding of the physical world, explaining the motion of objects on Earth and in the heavens, from falling apples to orbiting planets. His work laid the foundation for classical mechanics and remains a cornerstone of modern physics.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {'Anthropic'} ...\\n\")\n",
    "for user_prompt in user_prompts:\n",
    "    prompt = f\"\"\"\n",
    "    # CONTEXT #\n",
    "    I want to write a complete and cohesive paragpraph for \n",
    "    magazine: Things to know.\n",
    "\n",
    "    #############\n",
    "    \n",
    "    # OBJECTIVE #\n",
    "    Compete the text ```{user_prompt}``` between three backticks to the best \n",
    "    of your acquired knowledge.\n",
    "\n",
    "    #############\n",
    "\n",
    "    # STYLE #\n",
    "    You will use simple, compound, and compound-complex sentences for all your responses, \n",
    "    and no more than one paragraph and no more than five sentences.\n",
    "\n",
    "    Adhere to a litrary magazine writing style. Keep your sentences succinct and cohesive.\n",
    "\n",
    "    #############\n",
    "\n",
    "    # TONE #\n",
    "    Maintain an editorial tone.\n",
    "\n",
    "    #############\n",
    "\n",
    "    # AUDIENCE #\n",
    "    Our audience are generally curious first to second year college\n",
    "    students.\n",
    "\n",
    "    #############\n",
    "\n",
    "    # RESPONSE #\n",
    "    Finally, keep the response concise and succinct.\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    response = response.replace(\"```\", \"\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Prompt:{BOLD_END} {user_prompt}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Answer:{BOLD_END} {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e03d54-6200-4664-9a6d-13fe8297e0cb",
   "metadata": {},
   "source": [
    "## Text summarization\n",
    "\n",
    "A common task in natural langauge processing is text summiarization. A common use case\n",
    "is summarizing large articles or documents, for a quick and easy-to-absorb summaries.\n",
    "\n",
    "You can instruct LLM to generate the response in a preferable style, and comprehensibility. For example, use simple language aimed for a certain grade level, keep the orginal style of the article, use different sentence sytles (as we have done in few of examples in this notebook and previous one).\n",
    "\n",
    "Let's try a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85736577-b4ee-466e-90c8-a810849fe172",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are master of all knowledge about history, literature, science, philosophy, religion, \n",
    "                    economics, sports, etc. Respond to only answers\n",
    "                    you know of. Do not make up answers\"\"\" \n",
    "                \n",
    "user_prompts = [\n",
    "    \"\"\" The emergence of large language models (LLMs) has marked a significant \n",
    "         breakthrough in natural language processing (NLP), leading to remarkable \n",
    "         advancements in text understanding and generation. \n",
    "         \n",
    "         Nevertheless, alongside these strides, LLMs exhibit a critical tendency \n",
    "         to produce hallucinations, resulting in content that is inconsistent with \n",
    "         real-world facts or user inputs. This phenomenon poses substantial challenges \n",
    "         to their practical deployment and raises concerns over the reliability of LLMs \n",
    "         in real-world scenarios, which attracts increasing attention to detect and \n",
    "         mitigate these hallucinations. In this survey, we aim to provide a thorough and \n",
    "         in-depth  overview of recent advances in the field of LLM hallucinations. \n",
    "         \n",
    "         We begin with an innovative taxonomy of LLM hallucinations, then delve into the \n",
    "         factors contributing to hallucinations. Subsequently, we present a comprehensive\n",
    "         overview of hallucination detection methods and benchmarks. \n",
    "         Additionally, representative approaches designed to mitigate hallucinations \n",
    "         are introduced accordingly. \n",
    "         \n",
    "         Finally, we analyze the challenges that highlight the current limitations and \n",
    "         formulate open questions, aiming to delineate pathways for future  research on \n",
    "         hallucinations in LLMs.\"\"\",\n",
    "    \"\"\"  Can a Large Language Model (LLM) solve simple abstract reasoning problems?\n",
    "         We explore this broad question through a systematic analysis of GPT on the \n",
    "         Abstraction and Reasoning Corpus (ARC), a representative benchmark of abstract \n",
    "         reasoning ability from limited examples in which solutions require some \n",
    "         \"core knowledge\" of concepts such as objects, goal states, counting, and \n",
    "         basic geometry. GPT-4 solves only 13/50 of the most straightforward ARC \n",
    "         tasks when using textual encodings for their two-dimensional input-output grids. \n",
    "         Our failure analysis reveals that GPT-4's capacity to identify objects and \n",
    "         reason about them is significantly influenced by the sequential nature of \n",
    "         the text that represents an object within a text encoding of a task. \n",
    "         To test this hypothesis, we design a new benchmark, the 1D-ARC, which \n",
    "         consists of one-dimensional (array-like) tasks that are more conducive \n",
    "         to GPT-based reasoning, and where it indeed performs better than on \n",
    "         the (2D) ARC. To alleviate this issue, we propose an object-based \n",
    "         representation that is obtained through an external tool, resulting in \n",
    "         nearly doubling the performance on solved ARC tasks and near-perfect scores \n",
    "         on the easier 1D-ARC. Although the state-of-the-art GPT-4 is unable to \n",
    "         \"reason\" perfectly within non-language domains such as the 1D-ARC or a \n",
    "         simple ARC subset, our study reveals that the use of object-based representations \n",
    "         can significantly improve its reasoning ability. Visualizations, GPT logs, and \n",
    "         data are available at this https URL.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a884cb94-0c4a-40bc-a847-1d5eb354cafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Anthropic ...\n",
      "\n",
      "\n",
      "\u001b[1mOriginal content:\u001b[0m  The emergence of large language models (LLMs) has marked a significant \n",
      "         breakthrough in natural language processing (NLP), leading to remarkable \n",
      "         advancements in text understanding and generation. \n",
      "         \n",
      "         Nevertheless, alongside these strides, LLMs exhibit a critical tendency \n",
      "         to produce hallucinations, resulting in content that is inconsistent with \n",
      "         real-world facts or user inputs. This phenomenon poses substantial challenges \n",
      "         to their practical deployment and raises concerns over the reliability of LLMs \n",
      "         in real-world scenarios, which attracts increasing attention to detect and \n",
      "         mitigate these hallucinations. In this survey, we aim to provide a thorough and \n",
      "         in-depth  overview of recent advances in the field of LLM hallucinations. \n",
      "         \n",
      "         We begin with an innovative taxonomy of LLM hallucinations, then delve into the \n",
      "         factors contributing to hallucinations. Subsequently, we present a comprehensive\n",
      "         overview of hallucination detection methods and benchmarks. \n",
      "         Additionally, representative approaches designed to mitigate hallucinations \n",
      "         are introduced accordingly. \n",
      "         \n",
      "         Finally, we analyze the challenges that highlight the current limitations and \n",
      "         formulate open questions, aiming to delineate pathways for future  research on \n",
      "         hallucinations in LLMs.\n",
      "\n",
      "\u001b[1mSummary  content:\u001b[0m Large language models (LLMs) have revolutionized natural language processing, enabling remarkable advancements in text understanding and generation. However, LLMs are prone to producing hallucinations, generating content inconsistent with real-world facts or user inputs, which poses significant challenges to their practical deployment and raises concerns about their reliability. This survey provides an in-depth overview of recent advances in LLM hallucinations, introducing a taxonomy, exploring contributing factors, presenting detection methods and benchmarks, and discussing mitigation approaches, while also highlighting current limitations and outlining future research directions.\n",
      "\n",
      "\u001b[1mOriginal content:\u001b[0m   Can a Large Language Model (LLM) solve simple abstract reasoning problems?\n",
      "         We explore this broad question through a systematic analysis of GPT on the \n",
      "         Abstraction and Reasoning Corpus (ARC), a representative benchmark of abstract \n",
      "         reasoning ability from limited examples in which solutions require some \n",
      "         \"core knowledge\" of concepts such as objects, goal states, counting, and \n",
      "         basic geometry. GPT-4 solves only 13/50 of the most straightforward ARC \n",
      "         tasks when using textual encodings for their two-dimensional input-output grids. \n",
      "         Our failure analysis reveals that GPT-4's capacity to identify objects and \n",
      "         reason about them is significantly influenced by the sequential nature of \n",
      "         the text that represents an object within a text encoding of a task. \n",
      "         To test this hypothesis, we design a new benchmark, the 1D-ARC, which \n",
      "         consists of one-dimensional (array-like) tasks that are more conducive \n",
      "         to GPT-based reasoning, and where it indeed performs better than on \n",
      "         the (2D) ARC. To alleviate this issue, we propose an object-based \n",
      "         representation that is obtained through an external tool, resulting in \n",
      "         nearly doubling the performance on solved ARC tasks and near-perfect scores \n",
      "         on the easier 1D-ARC. Although the state-of-the-art GPT-4 is unable to \n",
      "         \"reason\" perfectly within non-language domains such as the 1D-ARC or a \n",
      "         simple ARC subset, our study reveals that the use of object-based representations \n",
      "         can significantly improve its reasoning ability. Visualizations, GPT logs, and \n",
      "         data are available at this https URL.\n",
      "\n",
      "\u001b[1mSummary  content:\u001b[0m GPT-4, a state-of-the-art large language model, struggles to solve abstract reasoning problems from the Abstraction and Reasoning Corpus (ARC) benchmark when using textual encodings for two-dimensional input-output grids. The model's ability to identify and reason about objects is significantly influenced by the sequential nature of the text representation. However, when tested on a new benchmark called 1D-ARC, which consists of one-dimensional tasks more conducive to GPT-based reasoning, the model performs better than on the original 2D-ARC. Furthermore, using an object-based representation obtained through an external tool nearly doubles GPT-4's performance on solved ARC tasks and leads to near-perfect scores on the easier 1D-ARC, revealing that object-based representations can significantly improve the model's reasoning ability.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {'Anthropic'} ...\\n\")\n",
    "for user_prompt in user_prompts:\n",
    "    prompt = f\"\"\"\n",
    "\n",
    "    # CONTEXT #\n",
    "    I want to write a summarize cohesively into at most two paragpraphs for \n",
    "    my magazine: Things to know quickly\n",
    "\n",
    "    #############\n",
    "    \n",
    "    # OBJECTIVE #\n",
    "    Summarize the text ```{user_prompt}``` between three backticks to the best \n",
    "    of your acquired knowledge.\n",
    "\n",
    "     #############\n",
    "\n",
    "    # STYLE #\n",
    "    You will use simple, compound, and compound-complex sentences for all your responses, \n",
    "    and no more than one paragraph and no more than five sentences.\n",
    "\n",
    "    Adhere to a litrary magazine writing style. Keep your sentences succinct and cohesive.\n",
    "\n",
    "    # TONE #\n",
    "    Maintain the same tone as the text supplied.\n",
    "\n",
    "    #############\n",
    "\n",
    "    # AUDIENCE #\n",
    "    Our audience are generally curious first to second year college\n",
    "    students.\n",
    "\n",
    "    #############\n",
    "\n",
    "     # RESPONSE #\n",
    "    Finally, keep the response concise and succinct\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Original content:{BOLD_END} {user_prompt}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Summary  content:{BOLD_END} {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affe9c30-bf89-49ee-80c8-c5d260b91914",
   "metadata": {},
   "source": [
    "## Text or information extraction\n",
    "\n",
    "Another natural langauge capability, similar to summarization or text completion, is extracting key idea or infromation from an article, blog, or a paragraph. For example,\n",
    "given a set of text, you can ask LLM to extract key ideas or topics or subjects. Or even\n",
    "better enumerate key takeways for you, saving time if you are in a hurry.\n",
    "\n",
    "Let's see *how-to* do it by first looking at a simple example, and then progressing into a more complex one, all along keepin \n",
    "the [CO-STAR prompting framework](https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41) in mind.\n",
    "\n",
    "### Task 1: \n",
    " * summarize the product review\n",
    " * extract any information about shipping and packaging for shipping department\n",
    " * classify the sentiment of the review: positive or negative.\n",
    " * use precise, specific prompt to acheive the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21406dcc-e9b1-4028-8281-297ae762b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are master of all knowledge about history, literature, science, social science, \n",
    "philosophy, religion, economics, sports, etc.\n",
    "\"\"\"\n",
    "\n",
    "product_review = \"\"\"I got this Australian Bush Baby with soft fur for my niece's birthday,\n",
    "and she absolutely loves it, carrying it around everywhere. The fur is exceptionally soft,\n",
    "and its adorable face gives off a friendly vibe. While I find it a bit smaller than \n",
    "anticipated for the price, my niece's joy makes it worthwhile. What pleasantly surprised \n",
    "me was the early arrival; it came a day earlier than expected. \n",
    "I appreciated the prompt delivery, and the packaging was secure, ensuring the \n",
    "Bush Baby with soft fur arrived in perfect condition. This allowed me to play with \n",
    "it myself before presenting it to my niece.\n",
    "\"\"\"     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "384515f8-a970-421a-86bb-be3ea8800bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "# CONTEXT #\n",
    "In our customer service department, we value customer feedback and want to\n",
    "analyze their reviews by summarizing their review assessing, labeling or categorizing\n",
    "and its idenfitying its sentiment. \n",
    "\n",
    "#############\n",
    "\n",
    "# OBJECTIVE #\n",
    "Your task is to generate a short summary of a product \n",
    "review from an Australian e-commerce site to offer feedback to the \n",
    "shipping deparmtment. Follow the steps below:\n",
    "\n",
    "First, generate a short summary of review below, delimited by triple \n",
    "backticks, in two sentences: a simple and compound sentence. \n",
    "\n",
    "Second, focus on any aspects of packaging or shipping of the product, and label it as \n",
    "\"Shipping Department:\".  \n",
    "\n",
    "Third, indicate if the review is positive or negative, and label it as \"Sentiment:\".\n",
    "Do not provide any preamble, only a simple two words: Positive or negative\n",
    "Review: ```{product_review}``` \n",
    "\n",
    "#############\n",
    "\n",
    "# STYLE #\n",
    "You will use simple, compound, and compound-complex sentences for all your responses, \n",
    "and no more than one paragraph and no more than five sentences.\n",
    "\n",
    "#############\n",
    "\n",
    "# TONE #\n",
    "Maintain a professional tone for internal communications\n",
    "\n",
    "#############\n",
    "\n",
    " # AUDIENCE #\n",
    "Our audience are internal departments in customer success to ensure we can\n",
    "improve our customer service\n",
    "\n",
    "#############\n",
    "\n",
    "# RESPONSE #\n",
    "Finally, keep the response concise and succinct\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0056f55-c3aa-4a4e-bd11-fec330436af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Anthropic ...\n",
      "\n",
      "\n",
      "\u001b[1mSummary:\u001b[0m GPT-4, a state-of-the-art large language model, struggles to solve abstract reasoning problems from the Abstraction and Reasoning Corpus (ARC) when using textual encodings for two-dimensional input-output grids. The model's ability to identify and reason about objects is significantly influenced by the sequential nature of the text representation, as evidenced by its improved performance on a newly designed one-dimensional benchmark called 1D-ARC. However, using object-based representations obtained through an external tool nearly doubles GPT-4's performance on solved ARC tasks and leads to near-perfect scores on the easier 1D-ARC, revealing that such representations can significantly enhance the model's reasoning ability within non-language domains.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {'Anthropic'} ...\\n\")\n",
    "response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "print(f\"\"\"\\n{BOLD_BEGIN}Summary:{BOLD_END} {response.replace(\"```\", \"\")}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb0d62-e2a7-4669-9792-57f20ed95980",
   "metadata": {},
   "source": [
    "### Task 2\n",
    " * Given a passage from an article, extract the main theme of the passage and label it as the `Subjects`, if more than one, separated by comma.\n",
    " * Identify three key takeways and enumerate them in simple sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cdcd4d4-62c7-4dea-b98a-58070552c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"You are master of all knowledge about history, literature, science, social science, philosophy, religion, economics, sports, etc.\"\n",
    "            \n",
    "user_prompts = [\"\"\"Isaac Newton sat under a tree when an apple fell, an event that, \n",
    "                according to popular legend, led to his contemplation of the forces\n",
    "                of gravity. Although this story is often regarded as apocryphal or at \n",
    "                least exaggerated, it serves as a powerful symbol of Newton's insight \n",
    "                into the universal law that governs celestial and earthly bodies alike. \n",
    "                His formulation of the law of universal gravitation was revolutionary, \n",
    "                as it provided a mathematical explanation for both the motion of planets \n",
    "                and the phenomena observed on Earth. Newton's work in physics, captured \n",
    "                in his seminal work Philosophiæ Naturalis Principia Mathematica, laid the \n",
    "                groundwork for classical mechanics. His influence extended beyond his own \n",
    "                time, shaping the course of scientific inquiry for centuries to come.\n",
    "                \"\"\"\n",
    "               ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7e16e2f-14ec-4bfd-9687-294683ad5c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Anthropic ...\n",
      "\n",
      "\n",
      "\u001b[1mOriginal content:\u001b[0m  The emergence of large language models (LLMs) has marked a significant \n",
      "         breakthrough in natural language processing (NLP), leading to remarkable \n",
      "         advancements in text understanding and generation. \n",
      "         \n",
      "         Nevertheless, alongside these strides, LLMs exhibit a critical tendency \n",
      "         to produce hallucinations, resulting in content that is inconsistent with \n",
      "         real-world facts or user inputs. This phenomenon poses substantial challenges \n",
      "         to their practical deployment and raises concerns over the reliability of LLMs \n",
      "         in real-world scenarios, which attracts increasing attention to detect and \n",
      "         mitigate these hallucinations. In this survey, we aim to provide a thorough and \n",
      "         in-depth  overview of recent advances in the field of LLM hallucinations. \n",
      "         \n",
      "         We begin with an innovative taxonomy of LLM hallucinations, then delve into the \n",
      "         factors contributing to hallucinations. Subsequently, we present a comprehensive\n",
      "         overview of hallucination detection methods and benchmarks. \n",
      "         Additionally, representative approaches designed to mitigate hallucinations \n",
      "         are introduced accordingly. \n",
      "         \n",
      "         Finally, we analyze the challenges that highlight the current limitations and \n",
      "         formulate open questions, aiming to delineate pathways for future  research on \n",
      "         hallucinations in LLMs.\n",
      "\n",
      " \u001b[1mExtracted answers: \u001b[0m Subject: Hallucinations in Large Language Models (LLMs)\n",
      "\n",
      "Takeaways:\n",
      "1. LLMs have made significant progress in natural language processing but are prone to generating hallucinations.\n",
      "2. Hallucinations in LLMs pose challenges to their practical use and reliability.\n",
      "3. The survey provides an overview of hallucination taxonomy, contributing factors, detection methods, and mitigation approaches.\n",
      "\n",
      "\u001b[1mOriginal content:\u001b[0m   Can a Large Language Model (LLM) solve simple abstract reasoning problems?\n",
      "         We explore this broad question through a systematic analysis of GPT on the \n",
      "         Abstraction and Reasoning Corpus (ARC), a representative benchmark of abstract \n",
      "         reasoning ability from limited examples in which solutions require some \n",
      "         \"core knowledge\" of concepts such as objects, goal states, counting, and \n",
      "         basic geometry. GPT-4 solves only 13/50 of the most straightforward ARC \n",
      "         tasks when using textual encodings for their two-dimensional input-output grids. \n",
      "         Our failure analysis reveals that GPT-4's capacity to identify objects and \n",
      "         reason about them is significantly influenced by the sequential nature of \n",
      "         the text that represents an object within a text encoding of a task. \n",
      "         To test this hypothesis, we design a new benchmark, the 1D-ARC, which \n",
      "         consists of one-dimensional (array-like) tasks that are more conducive \n",
      "         to GPT-based reasoning, and where it indeed performs better than on \n",
      "         the (2D) ARC. To alleviate this issue, we propose an object-based \n",
      "         representation that is obtained through an external tool, resulting in \n",
      "         nearly doubling the performance on solved ARC tasks and near-perfect scores \n",
      "         on the easier 1D-ARC. Although the state-of-the-art GPT-4 is unable to \n",
      "         \"reason\" perfectly within non-language domains such as the 1D-ARC or a \n",
      "         simple ARC subset, our study reveals that the use of object-based representations \n",
      "         can significantly improve its reasoning ability. Visualizations, GPT logs, and \n",
      "         data are available at this https URL.\n",
      "\n",
      " \u001b[1mExtracted answers: \u001b[0m Subject: GPT-4's abstract reasoning ability on the Abstraction and Reasoning Corpus (ARC)\n",
      "\n",
      "Takeaways:\n",
      "1. GPT-4 struggles to solve even the simplest tasks in the ARC benchmark when using textual encodings of the input-output grids.\n",
      "2. The sequential nature of text representations hinders GPT-4's ability to identify and reason about objects within the tasks.\n",
      "3. Using object-based representations obtained through an external tool significantly improves GPT-4's performance on both ARC and the newly designed 1D-ARC benchmark.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {'Anthropic'} ...\\n\")\n",
    "for text in user_prompts:\n",
    "    prompt = f\"\"\" Given ```{text}``` delimited with triple backticks, identify a single key idea being discussed, \n",
    "    and label its 'Subject'. Next, enumerate at most three takeways. \n",
    "    Use short, simple sentences. \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Original content:{BOLD_END} {text}\")\n",
    "    print(f\"\\n {BOLD_BEGIN}Extracted answers: {BOLD_END} {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113abb50-6a73-4101-8846-e8f26d85bb9c",
   "metadata": {},
   "source": [
    "Let's try another example to extract more than one subject or topic being\n",
    "discussed in the text, and enumerate three takeways.\n",
    "\n",
    "(Incidentally, I'm reading biography of Benjamin Franklin by Issac Stevenson, and all this seems to align with his career path and passion.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f34ceebf-c1b6-495b-8c78-81d2fc45baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stories = [\"\"\"\"\n",
    "'The Printer'\n",
    "    He that has a Trade has an Office of Profit and Honour’ Poor Richard’s Almanack\n",
    "Benjamin Franklin had an affinity with print and books throughout his life. \n",
    "Apprenticed as a child to his brother James, a printer, he mastered all aspects of\n",
    "the trade, from typesetting to engraving, learning the latest techniques during his\n",
    "first visit to London.  An avid reader, Franklin saved money to buy books by \n",
    "temporarily turning vegetarian and, once settled in Philadelphia, founded the \n",
    "Library Company, the first subscription library in the colonies.  As an elder\n",
    "statesman, he even bought type and kept a press during his stay in France. \n",
    "After working as a printer’s journeyman, he set up his own Philadelphian printing \n",
    "office in 1728.  His success with the Pennslyannia Gazette and Poor Richard’s\n",
    "Almanack helped to provide Franklin with the financial means to retire from\n",
    "business, retaining a stake in his print shop and founding others throughout the \n",
    "colonies.  Print also gave him a public voice: Franklin preferred the printed word, \n",
    "rather than public rhetoric, influencing political and public opinion as a brilliant\n",
    "journalist and pamphleteer.\n",
    "\n",
    "'Silence Dogood and the New­England Courant'\n",
    "    When James Franklin lost the contract to print the Boston Gazette, he determined\n",
    "to begin his own newspaper, launching the New­England Courant in 1721.\n",
    "Benjamin, who had been indentured secretly to James, helped to print the weekly \n",
    "paper.  One night he slipped a composition under the door, beginning the series\n",
    "of ‘Silence Dogood’ letters, the purported epistles of a vocal widower, with strong \n",
    "opinions on drunks, clergymen, foolish fashions and Boston nightlife. Owing no\n",
    "little debt to the satire of the London Spectator, the letters represented a \n",
    "remarkable literary achievement for the 16­year old.  The British Library’s copy has \n",
    "been uniquely annotated in what appears to be Franklin’s hand. The first \n",
    "‘Dogood’ letter appears on the bottom right.\n",
    "\n",
    "‘The Main Design of the Weekly Paper will be to Entertain the Town’\n",
    "    Benjamin’s brother, James, began the New­England Courant in the face of\n",
    "opposition from the Boston Establishment.  He soon irritated them with his squibs\n",
    "and satires on the great and the good, attacking the influential clergyman Cotton\n",
    "Mather’s pet project of small pox inoculation and the authorities’ weak response \n",
    "to piracy. Twice arrested, James temporally left the paper in Benjamin’s hands, and \n",
    "then continued to publish it under Benjamin’s name to escape a ban on\n",
    "publication.  This issue is the first printed item to carry the imprint ‘B. Franklin’ (on\n",
    "the rear).  Franklin announces his intention to ‘Entertain the Town’ on this page.\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1909a1b5-68fa-449c-9d40-0d4494b75b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Anthropic ...\n",
      "\n",
      "\n",
      "\u001b[1mOriginal Story:\u001b[0m \"\n",
      "'The Printer'\n",
      "    He that has a Trade has an Office of Profit and Honour’ Poor Richard’s Almanack\n",
      "Benjamin Franklin had an affinity with print and books throughout his life. \n",
      "Apprenticed as a child to his brother James, a printer, he mastered all aspects of\n",
      "the trade, from typesetting to engraving, learning the latest techniques during his\n",
      "first visit to London.  An avid reader, Franklin saved money to buy books by \n",
      "temporarily turning vegetarian and, once settled in Philadelphia, founded the \n",
      "Library Company, the first subscription library in the colonies.  As an elder\n",
      "statesman, he even bought type and kept a press during his stay in France. \n",
      "After working as a printer’s journeyman, he set up his own Philadelphian printing \n",
      "office in 1728.  His success with the Pennslyannia Gazette and Poor Richard’s\n",
      "Almanack helped to provide Franklin with the financial means to retire from\n",
      "business, retaining a stake in his print shop and founding others throughout the \n",
      "colonies.  Print also gave him a public voice: Franklin preferred the printed word, \n",
      "rather than public rhetoric, influencing political and public opinion as a brilliant\n",
      "journalist and pamphleteer.\n",
      "\n",
      "'Silence Dogood and the New­England Courant'\n",
      "    When James Franklin lost the contract to print the Boston Gazette, he determined\n",
      "to begin his own newspaper, launching the New­England Courant in 1721.\n",
      "Benjamin, who had been indentured secretly to James, helped to print the weekly \n",
      "paper.  One night he slipped a composition under the door, beginning the series\n",
      "of ‘Silence Dogood’ letters, the purported epistles of a vocal widower, with strong \n",
      "opinions on drunks, clergymen, foolish fashions and Boston nightlife. Owing no\n",
      "little debt to the satire of the London Spectator, the letters represented a \n",
      "remarkable literary achievement for the 16­year old.  The British Library’s copy has \n",
      "been uniquely annotated in what appears to be Franklin’s hand. The first \n",
      "‘Dogood’ letter appears on the bottom right.\n",
      "\n",
      "‘The Main Design of the Weekly Paper will be to Entertain the Town’\n",
      "    Benjamin’s brother, James, began the New­England Courant in the face of\n",
      "opposition from the Boston Establishment.  He soon irritated them with his squibs\n",
      "and satires on the great and the good, attacking the influential clergyman Cotton\n",
      "Mather’s pet project of small pox inoculation and the authorities’ weak response \n",
      "to piracy. Twice arrested, James temporally left the paper in Benjamin’s hands, and \n",
      "then continued to publish it under Benjamin’s name to escape a ban on\n",
      "publication.  This issue is the first printed item to carry the imprint ‘B. Franklin’ (on\n",
      "the rear).  Franklin announces his intention to ‘Entertain the Town’ on this page.\n",
      "\n",
      "\n",
      " \u001b[1mExtracted entities:\u001b[0m Subjects: printing, journalism, satire, apprenticeship, family\n",
      "\n",
      "Takeways:\n",
      "1. Benjamin Franklin learned the printing trade as an apprentice to his brother James.\n",
      "2. Franklin wrote satirical letters under the pseudonym \"Silence Dogood\" for his brother's newspaper.\n",
      "3. James Franklin faced opposition and legal troubles for the content of his newspaper, the New-England Courant.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {'Anthropic'} ...\\n\")\n",
    "for story in user_stories:\n",
    "    prompt = f\"\"\" Extract five subjects that are being discussed in the \n",
    "                  following text, which is delimited by triple backticks.\n",
    "                  Format your response as a list of subjects \n",
    "                  \"Subjects:\" separate each subject by a comma.\n",
    "                  Make each subject at most two words long, not longer. \n",
    "                  Next, enumerate  as a list three takeways, and label them as \"Takeways:\" \n",
    "                  Use short, simple sentences for your takeways.\n",
    "                  Text sample: '''{story}'''\n",
    "                  \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Original Story:{BOLD_END} {story}\")\n",
    "    print(f\"\\n {BOLD_BEGIN}Extracted entities:{BOLD_END} {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08da3189-e9d0-42c9-9f70-d403df9e0dc5",
   "metadata": {},
   "source": [
    "## Text classification or sentiment analysis\n",
    "\n",
    "Unlike classical or traditional machine learning, where you'll have to do supervised learning to collect data, label it, and train for hours, depending on how much data,classifying text using LLM is simple.\n",
    "\n",
    "In short, you'll have to build an ML model to understand text and classify its sentiments as positive, negative or neutral. \n",
    "\n",
    "This onus task is easily done with LLM via clever prompting. \n",
    "\n",
    "Let's see what I mean in this *how-to* idenfity sentiments in text. But first let's \n",
    "generatre some sentiments as our ground truth, and supply them to LLM to observe if\n",
    "LLM identifies them correctly. This bit is not needed, for I'm just curious.\n",
    "\n",
    "*Positive*: \"This movie is a true cinematic gem, blending an engaging plot with superb performances and stunning visuals. A masterpiece that leaves a lasting impression.\"\n",
    "\n",
    "*Negative*: \"Regrettably, the film failed to live up to expectations, with a convoluted storyline, lackluster acting, and uninspiring cinematography. A disappointment overall.\"\n",
    "\n",
    "*Neutral*: \"The movie had its moments, offering a decent storyline and average performances. While not groundbreaking, it provided an enjoyable viewing experience.\"\n",
    "\n",
    "*Positive*: \"This city is a vibrant tapestry of culture, with friendly locals, historic landmarks, and a lively atmosphere. An ideal destination for cultural exploration.\"\n",
    "\n",
    "*Negative*: \"The city's charm is overshadowed by traffic congestion, high pollution levels, and a lack of cleanliness. Not recommended for a peaceful retreat.\"\n",
    "\n",
    "*Neutral*: \"The city offers a mix of experiences, from bustling markets to serene parks. An interesting but not extraordinary destination for exploration.\"\n",
    "\n",
    "*Positive*: \"This song is a musical masterpiece, enchanting listeners with its soulful lyrics, mesmerizing melody, and exceptional vocals. A timeless classic.\"\n",
    "\n",
    "*Negative*: \"The song fails to impress, featuring uninspiring lyrics, a forgettable melody, and lackluster vocals. It lacks the creativity to leave a lasting impact.\"\n",
    "\n",
    "*Neutral*: \"The song is decent, with a catchy tune and average lyrics. While enjoyable, it doesn't stand out in the vast landscape of music.\"\n",
    "\n",
    "*Positive*: \"A delightful cinematic experience that seamlessly weaves together a compelling narrative, strong character development, and breathtaking visuals.\"\n",
    "\n",
    "*Negative*: \"This film, unfortunately, falls short with a disjointed plot, subpar performances, and a lack of coherence. A disappointing viewing experience.\"\n",
    "\n",
    "*Neutral*: \"While not groundbreaking, the movie offers a decent storyline and competent performances, providing an overall satisfactory viewing experience.\"\n",
    "\n",
    "*Positive*: \"This city is a haven for culture enthusiasts, boasting historical landmarks, a rich culinary scene, and a welcoming community. A must-visit destination.\"\n",
    "\n",
    "*Negative*: \"The city's appeal is tarnished by overcrowded streets, noise pollution, and a lack of urban planning. Not recommended for a tranquil getaway.\"\n",
    "\n",
    "*Neutral*: \"The city offers a diverse range of experiences, from bustling markets to serene parks. An intriguing destination for those seeking a mix of urban and natural landscapes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26fba25e-e40b-40fc-84b5-0a86df748b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a prominent critic of landscapes, architecture, cities, movies, songs, \n",
    "                    entertainment, and a cultural ombudsman. \"\"\"\n",
    "\n",
    "user_sentiments = [ \"This movie is a true cinematic gem, blending an engaging plot with superb performances and stunning visuals. A masterpiece that leaves a lasting impression.\",\n",
    "                    \"Regrettably, the film failed to live up to expectations, with a convoluted storyline, lackluster acting, and uninspiring cinematography. A disappointment overall.\",\n",
    "                    \"The movie had its moments, offering a decent storyline and average performances. While not groundbreaking, it provided an enjoyable viewing experience.\",\n",
    "                    \"This city is a vibrant tapestry of culture, with friendly locals, historic landmarks, and a lively atmosphere. An ideal destination for cultural exploration.\",\n",
    "                    \"The city's charm is overshadowed by traffic congestion, high pollution levels, and a lack of cleanliness. Not recommended for a peaceful retreat.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bae549c-fa32-46e8-af19-83f923222e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Anthropic ...\n",
      "\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m This movie is a true cinematic gem, blending an engaging plot with superb performances and stunning visuals. A masterpiece that leaves a lasting impression.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m positive\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m Regrettably, the film failed to live up to expectations, with a convoluted storyline, lackluster acting, and uninspiring cinematography. A disappointment overall.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m negative\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m The movie had its moments, offering a decent storyline and average performances. While not groundbreaking, it provided an enjoyable viewing experience.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m neutral\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m This city is a vibrant tapestry of culture, with friendly locals, historic landmarks, and a lively atmosphere. An ideal destination for cultural exploration.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m positive\n",
      "\n",
      "\u001b[1mSentiment:\u001b[0m The city's charm is overshadowed by traffic congestion, high pollution levels, and a lack of cleanliness. Not recommended for a peaceful retreat.\n",
      "\n",
      "\u001b[1mLabel    :\u001b[0m negative\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {'Anthropic'} ...\\n\")\n",
    "for user_sentiment in user_sentiments:\n",
    "    prompt = f\"\"\"Classify the sentiment in the ```{user_sentiment}`` which is delimited \n",
    "        with triple backticks? Classify the given text into single label as \n",
    "        neutral, negative or positive. Do not expand on your response. \n",
    "        Use single words: positive, negative, neutral\n",
    "        If you cannot classify do not guess, do not ask for more info,\n",
    "        just classify as NA.\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Sentiment:{BOLD_END} {user_sentiment}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Label    :{BOLD_END} {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f520fec-af04-4b97-8e66-3187e34b5566",
   "metadata": {},
   "source": [
    "## Text categorization\n",
    "Like sentiment analysis, given a query, an LLM can identify from its context how to classify and route customer queries to respective departments. Also, note that LLM can detect foul language and respond politely. Text categorization can be employed to automate customer on-line queries.\n",
    "\n",
    "Let's look at how we can achieve that with smart and deliberate prompting.\n",
    "\n",
    "<img src=\"./images/category_resp.png\" height=\"35%\" width=\"%65\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75b9307f-a2b3-4393-8e5a-5d7af520ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a smart and helful Assistant who can route customer queries to \n",
    "                    respective customer service departments.\n",
    "                    \"\"\"\n",
    "\n",
    "customer_queries = [\"\"\"My modem has stop working. I tried to restart but the orange light keep flashing. It never turns green.\"\"\",\n",
    "                    \"\"\"I just moved into town, and I need Internet service\"\"\",\n",
    "                    \"\"\"Why does my bill include an extra $20 a month for cable TV when I don't use a television?\"\"\",\n",
    "                    \"\"\"I need to change my user name and password since someone is using my credentials. I cannot access my account.\"\"\",\n",
    "                    \"\"\"What days this week are we having a general upgrades to the cable models?\"\"\",\n",
    "                    # \"\"\"What day is the best day to call customer service so that I can avoid talking to a bot!\"\"\",\n",
    "                    # \"\"\"Your company is full of incompetent morons and fools!\"\"\",\n",
    "                    # \"\"\"I hate your worthless services. Cancel my stupid account or else I'll sue you!\"\"\"\n",
    "                   ]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36fe82a0-9486-4e8c-b573-3bb71d7a71b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Anthropic ...\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m My modem has stop working. I tried to restart but the orange light keep flashing. It never turns green.\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m Technical support\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m I just moved into town, and I need Internet service\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m New Customer\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m Why does my bill include an extra $20 a month for cable TV when I don't use a television?\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m Billing\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m I need to change my user name and password since someone is using my credentials. I cannot access my account.\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m Technical support\n",
      "\n",
      "\n",
      "\u001b[1mQuery:\u001b[0m What days this week are we having a general upgrades to the cable models?\n",
      "\n",
      "\u001b[1mRoute to:\u001b[0m General inquiry\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {'Anthropic'} ...\\n\")\n",
    "for query in customer_queries:\n",
    "    prompt = f\"\"\" \n",
    "    We are an Internet Service provider in a big metropolitan city. We want to \n",
    "    improve our customer service support by building a routing system so\n",
    "    that customer inquiries are routed responsively, respectfully, and actively to\n",
    "    appropriate company departments. Your task is to classify each customer's {query} \n",
    "    into one of the the following five categories:\n",
    "    1. Technical support\n",
    "    2. Billing \n",
    "    3. Account Management\n",
    "    4. New Customer  \n",
    "    5. General inquiry\n",
    "    \n",
    "    Do not expand or explain your response. Do not include backticks or quotes \n",
    "    in your response. Do not choose more than one category in your response from these categories: \n",
    "    Technical support, Billing, Account Management, New Customer, General inquiry\n",
    "    Do not include the {query} in your response.\n",
    "    If you can't classify the {query}, default to \"General inquiry.\"\n",
    "    If customer {query} uses a foul language, then respond with \n",
    "    \"No need for foul language. Please be respectful.\"\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Query:{BOLD_END} {query}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Route to:{BOLD_END} {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05333b92-c3fb-4341-b59d-82eeb7a65071",
   "metadata": {},
   "source": [
    "## Text transation and transformation\n",
    "\n",
    "Language translation by far is the most common use case for natural language processing. \n",
    "We have seen its early uses in Google translation, but with the emergence of multi-lingual LLMs, this task is simply achieved by exact prompting. \n",
    "\n",
    "In this section, we'll explore tasks in how to use LLMs for text translations, langugage identication, text transformation, spelling and grammar checking, tone adjustment, and format conversion.\n",
    "\n",
    "### Task 1:\n",
    " * Given an English text, translate into French, Spanish, and German.\n",
    " * Given a foreign language text, idenfify the language, and translate to English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e9dcecd-8c00-45d6-af45-af19ee7bffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content= \"\"\"You are a world reknowned supreme lingiust and a universal translator. You are a polglot, and fluently speak many global languages\"\"\"\n",
    "\n",
    "english_texts = [\"\"\" Welcome to New York for the United Nations General Council Meeting. Today\n",
    "is a special day for us to celeberate all our achievments since this global institute's formation.\n",
    "But more importantly, we want to address how we can mitigate global conflict with conversation\n",
    "and promote deterence, detente, and discussion.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad8986d5-3ade-4264-a29b-77dbf7b0ef8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Anthropic ...\n",
      "\n",
      "\n",
      "\u001b[1mEnglish Text:\u001b[0m  Welcome to New York for the United Nations General Council Meeting. Today\n",
      "is a special day for us to celeberate all our achievments since this global institute's formation.\n",
      "But more importantly, we want to address how we can mitigate global conflict with conversation\n",
      "and promote deterence, detente, and discussion.\n",
      "\n",
      "\u001b[1mTranslation: \u001b[0mHere are the translations of the given English text into Spanish, French, German, and Mandarin:\n",
      "\n",
      "Spanish:\n",
      "''' Bienvenidos a Nueva York para la Reunión del Consejo General de las Naciones Unidas. Hoy\n",
      "es un día especial para celebrar todos nuestros logros desde la formación de este instituto global.\n",
      "Pero lo que es más importante, queremos abordar cómo podemos mitigar los conflictos globales con la conversación\n",
      "y promover la disuasión, la distensión y el diálogo.'''\n",
      "\n",
      "French:\n",
      "''' Bienvenue à New York pour la réunion du Conseil général des Nations Unies. Aujourd'hui\n",
      "est un jour spécial pour célébrer toutes nos réalisations depuis la formation de cet institut mondial.\n",
      "Mais plus important encore, nous voulons aborder comment nous pouvons atténuer les conflits mondiaux par la conversation\n",
      "et promouvoir la dissuasion, la détente et la discussion.'''\n",
      "\n",
      "German:\n",
      "''' Willkommen in New York zur Tagung des Generalrats der Vereinten Nationen. Heute\n",
      "ist ein besonderer Tag, an dem wir alle unsere Errungenschaften seit der Gründung dieses globalen Instituts feiern.\n",
      "Aber was noch wichtiger ist, wir wollen ansprechen, wie wir globale Konflikte durch Gespräche entschärfen können\n",
      "und Abschreckung, Entspannung und Diskussion fördern.'''\n",
      "\n",
      "Mandarin:\n",
      "''' 欢迎来到纽约参加联合国大会。今天\n",
      "是我们庆祝这个全球机构成立以来所有成就的特殊日子。\n",
      "但更重要的是，我们要讨论如何通过对话缓解全球冲突\n",
      "并促进威慑、缓和与讨论。'''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {'Anthropic'} ...\\n\")\n",
    "for english_text in english_texts:\n",
    "    prompt = f\"\"\"\"Given an English text in triple ticks '''{english_text}'''. Translate into\n",
    "three languases: Spanish, French, German, and Mandarin. \n",
    "Label each translation with the langauge Name: followed by translation on a seperate line.\"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}English Text:{BOLD_END} {english_text}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Translation: {BOLD_END}{response}\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dae09d-5198-42a6-896b-347f260fe3eb",
   "metadata": {},
   "source": [
    "Given a foreing language, identify the language and translate into English.\n",
    "\n",
    "This is the reverse of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a366e171-38b6-4d8d-928a-a36ec0137a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_texts = [\"\"\"Bienvenidos a Nueva York para la Reunión del Consejo General de las Naciones Unidas. Hoy\n",
    "es un día especial para celebrar todos nuestros logros desde la formación de este instituto global.\n",
    "Pero más importante aún, queremos abordar cómo podemos mitigar el conflicto global con conversaciones\n",
    "y promover la disuasión, la distensión y el diálogo.\"\"\",\n",
    "            \"\"\"Willkommen in New York zur Sitzung des Allgemeinen Rates der Vereinten Nationen. Heute\n",
    "ist ein besonderer Tag für uns, um all unsere Errungenschaften seit der Gründung dieses globalen Instituts zu feiern.\n",
    "Aber wichtiger ist, dass wir ansprechen möchten, wie wir globale Konflikte durch Gespräche mildern können\n",
    "und Abschreckung, Entspannung und Diskussion fördern.\"\"\",\n",
    "                  \"\"\"Bienvenue à New York pour la réunion du Conseil Général des Nations Unies. Aujourd'hui,\n",
    "c'est un jour spécial pour nous pour célébrer toutes nos réalisations depuis la formation de cette institution mondiale.\n",
    "Mais plus important encore, nous voulons aborder comment nous pouvons atténuer les conflits mondiaux grâce à la conversation\n",
    "et promouvoir la dissuasion, la détente et la discussion.\"\"\",\n",
    "                  \"\"\"欢迎来到纽约参加联合国大会议。今天对我们来说是一个特别的日子，我们将庆祝自该全球机构成立以来取得的所有成就。但更重要的是，我们想要讨论如何通过对话来缓解全球冲突，并促进遏制、缓和和讨论。\n",
    "\"\"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44a86628-4641-4283-8bba-9d2961451915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Anthropic ...\n",
      "\n",
      "\n",
      "\u001b[1m Language Text: \u001b[0m Bienvenidos a Nueva York para la Reunión del Consejo General de las Naciones Unidas. Hoy\n",
      "es un día especial para celebrar todos nuestros logros desde la formación de este instituto global.\n",
      "Pero más importante aún, queremos abordar cómo podemos mitigar el conflicto global con conversaciones\n",
      "y promover la disuasión, la distensión y el diálogo.\n",
      "\n",
      "\u001b[1mTranslation: \u001b[0m Language Name: Spanish\n",
      "\n",
      "English translation:\n",
      "Welcome to New York for the United Nations General Council Meeting. Today\n",
      "is a special day to celebrate all our achievements since the formation of this global institute.\n",
      "But more importantly, we want to address how we can mitigate global conflict with conversations\n",
      "and promote deterrence, détente, and dialogue.\n",
      "\n",
      "\n",
      "\u001b[1m Language Text: \u001b[0m Willkommen in New York zur Sitzung des Allgemeinen Rates der Vereinten Nationen. Heute\n",
      "ist ein besonderer Tag für uns, um all unsere Errungenschaften seit der Gründung dieses globalen Instituts zu feiern.\n",
      "Aber wichtiger ist, dass wir ansprechen möchten, wie wir globale Konflikte durch Gespräche mildern können\n",
      "und Abschreckung, Entspannung und Diskussion fördern.\n",
      "\n",
      "\u001b[1mTranslation: \u001b[0m Language Name: German\n",
      "\n",
      "English translation:\n",
      "Welcome to New York for the meeting of the United Nations General Assembly. Today\n",
      "is a special day for us to celebrate all our achievements since the founding of this global institution.\n",
      "But more importantly, we want to address how we can mitigate global conflicts through talks\n",
      "and promote deterrence, de-escalation, and discussion.\n",
      "\n",
      "\n",
      "\u001b[1m Language Text: \u001b[0m Bienvenue à New York pour la réunion du Conseil Général des Nations Unies. Aujourd'hui,\n",
      "c'est un jour spécial pour nous pour célébrer toutes nos réalisations depuis la formation de cette institution mondiale.\n",
      "Mais plus important encore, nous voulons aborder comment nous pouvons atténuer les conflits mondiaux grâce à la conversation\n",
      "et promouvoir la dissuasion, la détente et la discussion.\n",
      "\n",
      "\u001b[1mTranslation: \u001b[0m Language Name: French\n",
      "\n",
      "English translation:\n",
      "Welcome to New York for the United Nations General Council meeting. Today is a special day for us to celebrate all our achievements since the formation of this global institution. But more importantly, we want to address how we can mitigate global conflicts through conversation and promote deterrence, détente, and discussion.\n",
      "\n",
      "\n",
      "\u001b[1m Language Text: \u001b[0m 欢迎来到纽约参加联合国大会议。今天对我们来说是一个特别的日子，我们将庆祝自该全球机构成立以来取得的所有成就。但更重要的是，我们想要讨论如何通过对话来缓解全球冲突，并促进遏制、缓和和讨论。\n",
      "\n",
      "\n",
      "\u001b[1mTranslation: \u001b[0m Language Name: Chinese (Simplified)\n",
      "\n",
      "English translation:\n",
      "Welcome to New York to attend the United Nations General Assembly. Today is a special day for us as we celebrate all the achievements made since the establishment of this global organization. But more importantly, we want to discuss how to alleviate global conflicts through dialogue and promote containment, mitigation, and discussion.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {'Anthropic'} ...\\n\")\n",
    "for language_text in languages_texts:\n",
    "    prompt = f\"\"\"\"Given a language text in triple ticks '''{language_text}'''. Idenfity\n",
    "    the language with the langauge Name: followed by an English translation on a seperate line, labeled as English translation:\"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN} Language Text: {BOLD_END} {language_text}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Translation: {BOLD_END} {response}\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8740e21-ea45-4b38-a0f7-753ef48a02aa",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    " * Given an English text, proof read it and correct any grammatical and usage errors.\n",
    " * Given a Pirate text, correct its tone to standard English.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a31e6bb8-83dd-4f0a-9036-a58e305e7d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a fastidious grammarian. You can proofread any English text and convert to \n",
    "its grammtical correct and usage form.\"\"\"\n",
    "\n",
    "bad_english_texts = [\"\"\"I don't know nothing about them big words and grammar rules. Me and my friend, we was talking, and he don't agree with me. We ain't never gonna figure it out, I reckon. His dog don't listen good, always running around and don't come when you call.\"\"\",\n",
    "                     \"\"\"Yesterday, we was at the park, and them kids was playing. She don't like the way how they acted, but I don't got no problem with it. We seen a movie last night, and it was good, but my sister, she don't seen it yet. Them books on the shelf, they ain't interesting to me.\"\"\"\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e4f0a39-e951-4e69-b547-cb969ea8250c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Anthropic ...\n",
      "\n",
      "\n",
      "\u001b[1mOriginal Text:\u001b[0m I don't know nothing about them big words and grammar rules. Me and my friend, we was talking, and he don't agree with me. We ain't never gonna figure it out, I reckon. His dog don't listen good, always running around and don't come when you call.\n",
      "\n",
      "\u001b[1mCorrected  Text:\u001b[0m Here is the corrected version of the text with standard usage and grammar:\n",
      "\n",
      "'''I don't know anything about those big words and grammar rules. My friend and I were talking, and he doesn't agree with me. We are never going to figure it out, I reckon. His dog doesn't listen well, always running around and not coming when you call.'''\n",
      "\n",
      "The main corrections made were:\n",
      "\n",
      "1. \"I don't know nothing\" changed to \"I don't know anything\" (double negative corrected)\n",
      "2. \"them big words\" changed to \"those big words\" (pronoun agreement)\n",
      "3. \"Me and my friend\" changed to \"My friend and I\" (subject pronoun)\n",
      "4. \"we was talking\" changed to \"were talking\" (subject-verb agreement)\n",
      "5. \"he don't agree\" changed to \"he doesn't agree\" (subject-verb agreement) \n",
      "6. \"We ain't never gonna\" changed to \"We are never going to\" (non-standard usage of \"ain't\" and \"gonna\" corrected)\n",
      "7. \"don't listen good\" changed to \"doesn't listen well\" (subject-verb agreement and adverb form)\n",
      "8. \"don't come when you call\" changed to \"not coming when you call\" (parallel structure)\n",
      "\n",
      "\n",
      "\u001b[1mOriginal Text:\u001b[0m Yesterday, we was at the park, and them kids was playing. She don't like the way how they acted, but I don't got no problem with it. We seen a movie last night, and it was good, but my sister, she don't seen it yet. Them books on the shelf, they ain't interesting to me.\n",
      "\n",
      "\u001b[1mCorrected  Text:\u001b[0m Here is the corrected version of the text with standard usage and grammar:\n",
      "\n",
      "'''\n",
      "Yesterday, we were at the park, and those kids were playing. She doesn't like the way they acted, but I don't have a problem with it. We saw a movie last night, and it was good, but my sister hasn't seen it yet. The books on the shelf aren't interesting to me.\n",
      "'''\n",
      "\n",
      "The main corrections made:\n",
      "\n",
      "1. \"we was\" changed to \"we were\" (past tense of \"to be\")\n",
      "2. \"them kids\" changed to \"those kids\" (demonstrative pronoun)\n",
      "3. \"kids was\" changed to \"kids were\" (past tense of \"to be\") \n",
      "4. \"She don't\" changed to \"She doesn't\" (third-person singular present tense)\n",
      "5. \"the way how they acted\" changed to \"the way they acted\" (redundant use of \"how\")\n",
      "6. \"I don't got no\" changed to \"I don't have a\" (double negative and non-standard verb usage)\n",
      "7. \"We seen\" changed to \"We saw\" (past tense of \"to see\")\n",
      "8. \"she don't seen it\" changed to \"she hasn't seen it\" (present perfect tense)\n",
      "9. \"Them books\" changed to \"The books\" (demonstrative pronoun)\n",
      "10. \"they ain't\" changed to \"they aren't\" (non-standard contraction of \"are not\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {'Anthropic'} ...\\n\")\n",
    "for bad_english_text in bad_english_texts:\n",
    "    prompt = f\"\"\"\"Proofread and correct the text provided in triple ticks '''{bad_english_text}'''.\n",
    "    Use standard usage and remedy any incorect grammar usage.\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Original Text:{BOLD_END} {bad_english_text}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Corrected  Text:{BOLD_END} {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01c28033-8175-427b-93d2-69db740060e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pirate_texts = [\"\"\"Arrr matey! I be knowin' nuthin' 'bout them fancy words and grammatical rules. Me and me heartie, we be chattin', and he don't be agreein' with me. We ain't never gonna figure it out, I reckon. His scallywag of a dog don't be listenin' well, always runnin' around and not comin' when ye call.\"\"\"\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f09b26f1-b370-4cd3-9079-b5b78df502d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Anthropic ...\n",
      "\n",
      "\n",
      "\u001b[1mOriginal Text:\u001b[0m Arrr matey! I be knowin' nuthin' 'bout them fancy words and grammatical rules. Me and me heartie, we be chattin', and he don't be agreein' with me. We ain't never gonna figure it out, I reckon. His scallywag of a dog don't be listenin' well, always runnin' around and not comin' when ye call.\n",
      "\n",
      "\u001b[1mCorrected  Text:\u001b[0m Here is the text converted to standard English with proper grammar and usage, dropping the Pirate greetings and expressions:\n",
      "\n",
      "I don't know anything about those fancy words and grammatical rules. My friend and I were chatting, and he doesn't agree with me. We're never going to figure it out, I suppose. His mischievous dog doesn't listen well, always running around and not coming when you call.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {'Anthropic'} ...\\n\")\n",
    "for pirate_text in pirate_texts:\n",
    "    prompt = f\"\"\"\"Convert the Pirate text provided in triple ticks '''{pirate_text}'''.\n",
    "    Use standard usage and remedy any incorect grammar usage, dropping all Pirate greetings.\n",
    "    \"\"\"\n",
    "    response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "    print(f\"\\n{BOLD_BEGIN}Original Text:{BOLD_END} {pirate_text}\")\n",
    "    print(f\"\\n{BOLD_BEGIN}Corrected  Text:{BOLD_END} {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e48460-00a6-4a7f-9e54-b1e25e00860d",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "* Given some text in a particular format, convert it into JSON format.\n",
    "* For example, we LLM to producce names of three top shoes, but we want them it product and its items in JSON format. This JSON format can be fed downstream into another application that may process it.\n",
    "\n",
    "Let's have go at it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab5b7a40-5d26-4bb0-816e-08f04462d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You have knowledge of all sporting goods and will provide knowledge answers\n",
    "to queries about sporting goods.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f77a87f-cf8a-486a-8c43-38a9e5f0c708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Endpoints: Anthropic ...\n",
      "\n",
      "\n",
      " \u001b[1mJSON response:\u001b[0m Here is a JSON object containing five distinct training shoe products with the requested information:\n",
      "\n",
      "{\n",
      "  \"products\": [\n",
      "    {\n",
      "      \"Brand\": \"Nike\",\n",
      "      \"Description\": \"Nike Air Zoom Pegasus 38 Running Shoes - Lightweight, breathable mesh upper with responsive cushioning for long runs and training sessions\",\n",
      "      \"Size\": \"7-15\",\n",
      "      \"Gender\": \"Male\",\n",
      "      \"Price\": 129.99,\n",
      "      \"Reviews\": [\n",
      "        \"Great shoes for daily training and long runs. The Zoom Air unit provides excellent cushioning.\",\n",
      "        \"These shoes are incredibly comfortable right out of the box. No break-in period needed!\",\n",
      "        \"The Pegasus 38 is a reliable, durable shoe that performs well for various running distances.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"Brand\": \"Adidas\",\n",
      "      \"Description\": \"Adidas Ultraboost 21 Running Shoes - Primeknit upper with Boost midsole for energy return and adaptive fit\",\n",
      "      \"Size\": \"5-12\",\n",
      "      \"Gender\": \"Female\",\n",
      "      \"Price\": 179.99,\n",
      "      \"Reviews\": [\n",
      "        \"The Ultraboost 21 is my go-to shoe for long runs. The Boost midsole is incredibly responsive.\",\n",
      "        \"I love the snug, adaptive fit of the Primeknit upper. It feels like a second skin.\",\n",
      "        \"These shoes are worth the investment. They provide excellent support and comfort.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"Brand\": \"ASICS\",\n",
      "      \"Description\": \"ASICS Gel-Kayano 28 Running Shoes - Engineered mesh upper with Gel cushioning and Dynamic DuoMax support system\",\n",
      "      \"Size\": \"6-14\",\n",
      "      \"Gender\": \"Unisex\",\n",
      "      \"Price\": 159.99,\n",
      "      \"Reviews\": [\n",
      "        \"The Gel-Kayano 28 is a fantastic stability shoe. It provides great support for overpronators.\",\n",
      "        \"I've been wearing Kayanos for years, and the 28 does not disappoint. It's comfortable and supportive.\",\n",
      "        \"If you need a reliable stability shoe, the Kayano 28 is an excellent choice.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"Brand\": \"New Balance\",\n",
      "      \"Description\": \"New Balance Fresh Foam 880v11 Running Shoes - Hypoknit upper with Fresh Foam midsole for soft, responsive cushioning\",\n",
      "      \"Size\": \"7-15\",\n",
      "      \"Gender\": \"Male\",\n",
      "      \"Price\": 129.99,\n",
      "      \"Reviews\": [\n",
      "        \"The Fresh Foam 880v11 is a great daily trainer. It's comfortable and provides a smooth ride.\",\n",
      "        \"I appreciate the roomy toe box and the soft, responsive cushioning of the Fresh Foam midsole.\",\n",
      "        \"New Balance has done it again with the 880v11. It's a reliable, well-cushioned shoe for daily training.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"Brand\": \"Saucony\",\n",
      "      \"Description\": \"Saucony Ride 14 Running Shoes - FORMFIT upper with PWRRUN cushioning for a responsive, comfortable ride\",\n",
      "      \"Size\": \"5-12\",\n",
      "      \"Gender\": \"Female\",\n",
      "      \"Price\": 129.99,\n",
      "      \"Reviews\": [\n",
      "        \"The Ride 14 is a versatile shoe that performs well for both short and long runs.\",\n",
      "        \"I love the comfortable, secure fit of the FORMFIT upper. It adapts to my foot's shape.\",\n",
      "        \"Saucony has created a winner with the Ride 14. It's a great all-around shoe for various workouts.\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Endpoints: {'Anthropic'} ...\\n\")\n",
    "prompt = f\"\"\"Generate five distinct products on training shoes. Generate products and format them all as a \n",
    "            in a single JSON object. For each product, the JSON object should contain items: Brand, Description, Size, Gender: Male \n",
    "            or Female or Unisex, Price, and at least three customer reviews as Review \n",
    "            item\"\"\"\n",
    "response = get_commpletion(client, MODEL, system_content, prompt)\n",
    "print(f\"\\n {BOLD_BEGIN}JSON response:{BOLD_END} {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6496b00-0a1d-4a57-9783-11f2dcf09c5a",
   "metadata": {},
   "source": [
    "## Simple and complex reasoning \n",
    "\n",
    "An import characteristic of LLM is that it's not only general respository of compressed\n",
    "knowledge garned from large corpus of text, but can be employed as a simple and complex reasoning engine. With use of precise prompt, you can instruct LLM to think trough a problem in a step by step fashion.\n",
    "\n",
    "Let's look at some tasks as examples.\n",
    " * **Task 1**: given a list of numbers identify the prime numbers, add the prime numbers and check if the sum is even or odd.\n",
    " * **Task 2**: given an hourly rate of wages, compute your yearly income if you work 30 hours a week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47be9101-2af8-4074-a970-b6cdadc692d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a reasoning engine. Given a problem think through the problem logically\n",
    "in a step by step manner.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c0b6b93-5218-4239-9db4-674e6b8dbd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 prompt\n",
    "prime_number_prompt = f\"\"\"given a list of numbers 1,2,3,4,5,7,8, 11,13,17,19,23,24,29 identify the prime numbers, add the prime numbers, \n",
    "and check if the sum is even or odd. Explain each step how you solved the problem\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f0bd7a7-9c8b-4c97-85b3-8f83a0ca61b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 2 prompt\n",
    "hourly_wages_prompt = f\"\"\"If my hourly rate is $117.79 per hour and 30 hours a week, what\n",
    "is my yearly income? Break the problem into simple steps and explain in each step how you arrive \n",
    "to the answer. If you don't know, simple say I don't know. Do not make up answers\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e36694e-5634-4aee-9a00-e677da6baa5d",
   "metadata": {},
   "source": [
    "#### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4ecb495-ee6f-4033-8fa7-7c364d79ffbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAnswer: \u001b[0mGreat! Let's solve this problem step by step. We need to identify the prime numbers from the given list, add them together, and determine if the sum is even or odd.\n",
      "\n",
      "Given list: 1, 2, 3, 4, 5, 7, 8, 11, 13, 17, 19, 23, 24, 29\n",
      "\n",
      "Step 1: Identify the prime numbers in the list.\n",
      "A prime number is a number greater than 1 that has no positive divisors other than 1 and itself.\n",
      "\n",
      "1 is not a prime number.\n",
      "2 is a prime number.\n",
      "3 is a prime number.\n",
      "4 is not a prime number (divisible by 2).\n",
      "5 is a prime number.\n",
      "7 is a prime number.\n",
      "8 is not a prime number (divisible by 2 and 4).\n",
      "11 is a prime number.\n",
      "13 is a prime number.\n",
      "17 is a prime number.\n",
      "19 is a prime number.\n",
      "23 is a prime number.\n",
      "24 is not a prime number (divisible by 2, 3, 4, 6, 8, and 12).\n",
      "29 is a prime number.\n",
      "\n",
      "The prime numbers in the list are: 2, 3, 5, 7, 11, 13, 17, 19, 23, and 29.\n",
      "\n",
      "Step 2: Add the prime numbers.\n",
      "2 + 3 + 5 + 7 + 11 + 13 + 17 + 19 + 23 + 29 = 129\n",
      "\n",
      "Step 3: Check if the sum is even or odd.\n",
      "A number is even if it is divisible by 2 without a remainder. If there is a remainder, the number is odd.\n",
      "\n",
      "129 ÷ 2 = 64 remainder 1\n",
      "Since there is a remainder of 1, the sum (129) is an odd number.\n",
      "\n",
      "Therefore, the sum of the prime numbers in the given list is 129, which is an odd number.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, prime_number_prompt)\n",
    "print(f\"\\n{BOLD_BEGIN}Answer: {BOLD_END}{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bd2c6e-bfa7-45cc-804d-acaf4797f8f3",
   "metadata": {},
   "source": [
    "#### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5651b79b-997e-4524-b17b-14f413e850a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAnswer: \u001b[0mTo calculate your yearly income, let's break it down into simple steps:\n",
      "\n",
      "Step 1: Calculate your weekly income.\n",
      "Weekly income = Hourly rate × Hours worked per week\n",
      "Weekly income = $117.79 × 30 = $3,533.70\n",
      "\n",
      "Step 2: Calculate the number of weeks in a year.\n",
      "There are approximately 52 weeks in a year.\n",
      "\n",
      "Step 3: Calculate your yearly income.\n",
      "Yearly income = Weekly income × Number of weeks in a year\n",
      "Yearly income = $3,533.70 × 52 = $183,752.40\n",
      "\n",
      "Therefore, if your hourly rate is $117.79 per hour and you work 30 hours a week, your yearly income would be approximately $183,752.40, assuming you work all 52 weeks in a year without any unpaid time off.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, hourly_wages_prompt)\n",
    "print(f\"\\n{BOLD_BEGIN}Answer: {BOLD_END}{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a5da1-986a-4682-a672-8c213eb40be5",
   "metadata": {},
   "source": [
    "## Code generation\n",
    "\n",
    "Language models like ChatGPT and Llama 2 are really good at generating code. Copilot on GitHub is a cool example of this. You can do lots of different code tasks just by asking in a smart way. Let's check out a few examples to see how it's helpful.\n",
    "\n",
    "#### Task 1\n",
    " * Generate Python code to compute the value of PI using Ray distributed framework\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de3ad4ed-e28e-44a7-8a33-11136f6334d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a supreme CoPilot for a developer. Given a task you can\n",
    "generate code for that task.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9a85173-dbce-4bf6-b004-7e368a5ccd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_code_prompt=\"\"\"Generate Python code to compute the value of PI using Ray \n",
    "distributed framework API. Use the Monte Carlo method to compute the value of PI.\n",
    "Include in-line comments explaining the code\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60e2b04a-9f0c-450f-aeda-8e6ece5b0a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mGenerated Python code:\u001b[0mHere's the Python code to compute the value of PI using the Monte Carlo method with the Ray distributed framework API, along with in-line comments explaining the code:\n",
      "\n",
      "```python\n",
      "import ray\n",
      "import random\n",
      "import math\n",
      "\n",
      "# Initialize Ray\n",
      "ray.init()\n",
      "\n",
      "# Define the number of total points to generate\n",
      "NUM_POINTS = 10000000\n",
      "\n",
      "# Define a remote function to generate points and count the ones inside the unit circle\n",
      "@ray.remote\n",
      "def monte_carlo_pi(num_points):\n",
      "    inside_count = 0\n",
      "    for _ in range(num_points):\n",
      "        # Generate random x and y coordinates between -1 and 1\n",
      "        x = random.uniform(-1, 1)\n",
      "        y = random.uniform(-1, 1)\n",
      "        \n",
      "        # Check if the point lies inside the unit circle\n",
      "        if x**2 + y**2 <= 1:\n",
      "            inside_count += 1\n",
      "    \n",
      "    return inside_count\n",
      "\n",
      "# Define the number of parallel tasks to run\n",
      "NUM_TASKS = 10\n",
      "\n",
      "# Split the total number of points among the tasks\n",
      "points_per_task = NUM_POINTS // NUM_TASKS\n",
      "\n",
      "# Launch parallel tasks to compute the count of points inside the unit circle\n",
      "results = [monte_carlo_pi.remote(points_per_task) for _ in range(NUM_TASKS)]\n",
      "\n",
      "# Retrieve the results from the parallel tasks\n",
      "inside_counts = ray.get(results)\n",
      "\n",
      "# Sum up the counts from all the tasks\n",
      "total_inside_count = sum(inside_counts)\n",
      "\n",
      "# Calculate the approximation of PI\n",
      "pi_approx = 4 * total_inside_count / NUM_POINTS\n",
      "\n",
      "# Print the approximated value of PI\n",
      "print(f\"Approximated value of PI: {pi_approx}\")\n",
      "print(f\"Actual value of PI: {math.pi}\")\n",
      "```\n",
      "\n",
      "Explanation of the code:\n",
      "\n",
      "1. We import the necessary libraries: `ray` for distributed computing, `random` for generating random numbers, and `math` for comparing the approximated value of PI with the actual value.\n",
      "\n",
      "2. We initialize Ray using `ray.init()` to start the Ray runtime.\n",
      "\n",
      "3. We define the total number of points to generate (`NUM_POINTS`) for the Monte Carlo simulation.\n",
      "\n",
      "4. We define a remote function `monte_carlo_pi` using the `@ray.remote` decorator. This function generates a specified number of random points and counts the number of points that lie inside the unit circle.\n",
      "\n",
      "5. Inside the `monte_carlo_pi` function, we generate random x and y coordinates between -1 and 1 using `random.uniform()`. We then check if the generated point lies inside the unit circle by calculating the distance from the origin (0, 0) using the equation `x^2 + y^2 <= 1`. If the point is inside the circle, we increment the `inside_count`.\n",
      "\n",
      "6. We define the number of parallel tasks to run (`NUM_TASKS`) and calculate the number of points to be generated by each task (`points_per_task`).\n",
      "\n",
      "7. We launch parallel tasks using a list comprehension and the `monte_carlo_pi.remote()` function, passing `points_per_task` as an argument to each task.\n",
      "\n",
      "8. We retrieve the results from the parallel tasks using `ray.get(results)`, which returns a list of `inside_counts` from each task.\n",
      "\n",
      "9. We sum up the `inside_counts` from all the tasks to get the total count of points inside the unit circle.\n",
      "\n",
      "10. We calculate the approximation of PI using the formula: `4 * total_inside_count / NUM_POINTS`.\n",
      "\n",
      "11. Finally, we print the approximated value of PI and compare it with the actual value of PI using `math.pi`.\n",
      "\n",
      "This code demonstrates how to use the Ray distributed framework to parallelize the Monte Carlo simulation for approximating the value of PI. By distributing the workload across multiple tasks, we can leverage the power of parallel computing to speed up the calculation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, python_code_prompt)\n",
    "\n",
    "print(f\"\\n{BOLD_BEGIN}Generated Python code:{BOLD_END}{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7fdc8-7a19-4a1a-b119-7a0bf0b3ae0f",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    " * Given SQL schema tables, generate an SQL query \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "585f372c-fe37-43b4-9299-c5708d1be06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_code_prompt=\"\"\"Given the following SQL schema for tables\n",
    "Table clicks, columns = [target_url, orig_url, user_id, clicks]\n",
    "Table users, columns = [user_id, f_name, l_name, e_mail, company, title], generate\n",
    "an SQL query that computes in the descening order of all the clicks. Also, for\n",
    "each user_id, list the f_name, l_name, company, and title\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "351b78d7-c78b-4a1b-946b-8a2abd17efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mGenerated SQL code: \u001b[0mHere's the SQL query that computes the total clicks in descending order and lists the first name, last name, company, and title for each user:\n",
      "\n",
      "```sql\n",
      "SELECT \n",
      "    u.user_id,\n",
      "    u.f_name,\n",
      "    u.l_name,\n",
      "    u.company,\n",
      "    u.title,\n",
      "    COALESCE(SUM(c.clicks), 0) AS total_clicks\n",
      "FROM \n",
      "    users u\n",
      "    LEFT JOIN clicks c ON u.user_id = c.user_id\n",
      "GROUP BY \n",
      "    u.user_id,\n",
      "    u.f_name,\n",
      "    u.l_name,\n",
      "    u.company,\n",
      "    u.title\n",
      "ORDER BY \n",
      "    total_clicks DESC;\n",
      "```\n",
      "\n",
      "Let's break down the query:\n",
      "\n",
      "1. The `SELECT` clause specifies the columns we want to retrieve:\n",
      "   - `u.user_id`: The user ID from the `users` table.\n",
      "   - `u.f_name`: The first name from the `users` table.\n",
      "   - `u.l_name`: The last name from the `users` table.\n",
      "   - `u.company`: The company from the `users` table.\n",
      "   - `u.title`: The title from the `users` table.\n",
      "   - `COALESCE(SUM(c.clicks), 0) AS total_clicks`: Calculates the total clicks for each user. The `COALESCE` function is used to handle cases where a user has no clicks, returning 0 instead of NULL.\n",
      "\n",
      "2. The `FROM` clause specifies the main table, which is the `users` table aliased as `u`.\n",
      "\n",
      "3. The `LEFT JOIN` clause joins the `clicks` table (aliased as `c`) with the `users` table based on the `user_id` column. It ensures that all users are included in the result, even if they have no corresponding clicks.\n",
      "\n",
      "4. The `GROUP BY` clause groups the result by the specified columns:\n",
      "   - `u.user_id`\n",
      "   - `u.f_name`\n",
      "   - `u.l_name`\n",
      "   - `u.company`\n",
      "   - `u.title`\n",
      "   This allows us to calculate the total clicks for each unique combination of user ID, first name, last name, company, and title.\n",
      "\n",
      "5. The `ORDER BY` clause sorts the result in descending order based on the `total_clicks` column, so users with the highest number of clicks appear first.\n",
      "\n",
      "This query will return a result set with columns: `user_id`, `f_name`, `l_name`, `company`, `title`, and `total_clicks`, sorted in descending order of `total_clicks`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, sql_code_prompt)\n",
    "print(f\"\\n{BOLD_BEGIN}Generated SQL code: {BOLD_END}{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d546337d-b9a4-40db-92dd-8cdce63c6979",
   "metadata": {},
   "source": [
    "## All this is amazing! 😜 Feel the wizardy prompt power 🧙‍♀️"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
