{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f470274a-56a3-447e-9bd3-2dbb9c858f55",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"./images/llm_prompt_req_resp.png\" height=\"35%\" width=\"%65\">\n",
    "\n",
    "## Zero-shot prompting\n",
    "\n",
    "Zero-prompt learning is a challenging yet fascinating area where models are trained to perform tasks without explicit learning examples in the input prompt. Here are some notable examples:\n",
    "\n",
    "GPT-3 and Llama Language Model:\n",
    "\n",
    "GPT-3, Llama 2, and Claude are powerful language models. The have demonstrated zero-shot learning. That is, without specific learning prompts or examples, it can generate coherent and contextually relevant responses, showcasing its ability to understand and respond to diverse queries.\n",
    "\n",
    "### Named Entity Recognition (NER):\n",
    "\n",
    "Models trained with zero-prompt learning for NER can identify and categorize named entities in text without being explicitly provided with examples for each specific entity.\n",
    "\n",
    "### Dialogue Generation:\n",
    "\n",
    "Zero-shot dialogue generation models can engage in conversations and respond appropriately to user input without being given explicit dialogues as training examples.\n",
    "\n",
    "In our prompt engineering notebooks, we saw examples of zero-shot prompting: Text generation, summarization, translation, etc. None of the prompts were given any language examples to learn from; they model has prior learned knowledge of the language. \n",
    "\n",
    "Let's demonstrate how you can do NER and Dialogue generation with zero-shot learning.\n",
    "\n",
    "**Note**: \n",
    "To run any of these relevant notebooks you will need an account on Anyscale Endpoints, Anthropic, or OpenAI, depending on what model you elect, along with the respective environment file. Use the template environment files to create respective `.env` file for either Anyscale Endpoints, Anthropic, or OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b31635bd-4004-49c5-bab3-7280670e67d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from llm_clnt_factory_api import ClientFactory, get_commpletion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7691d3a2-7c62-4c2c-98d4-90da68ccb472",
   "metadata": {},
   "source": [
    "#### Based on .env file use the appropriate LLM service provider APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25750774-ecc5-45b9-b8d8-840263034029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=claude-3-opus-20240229; base=anthropic\n"
     ]
    }
   ],
   "source": [
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "warnings.filterwarnings('ignore')\n",
    "llm_client_service_provider = os.getenv(\"LLM_SERVICE_PROVIDER\", None)\n",
    "if llm_client_service_provider not in ['anyscale', 'openai', 'anthropic']:\n",
    "    raise ValueError(f\"Client {'LLM_SERVICE_PROVIDER'} missing in the .env file.\")\n",
    "elif llm_client_service_provider == \"openai\" or llm_client_service_provider == \"anyscale\":                                   \n",
    "    openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "    openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "    MODEL = os.getenv(\"MODEL\")\n",
    "    print(f\"Using MODEL={MODEL}; base={openai.api_base}\")\n",
    "else: \n",
    "    api_key = os.getenv(\"ANTHROPIC_API_KEY\", None)\n",
    "    MODEL = os.getenv(\"MODEL\")\n",
    "    print(f\"Using MODEL={MODEL}; base={llm_client_service_provider}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf86c5ba-0a7c-4517-bbb7-b816e1bf1fb5",
   "metadata": {},
   "source": [
    "#### Creat the respective client using our factory class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ab2521c-a808-41a3-9afb-572e2d99dfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<anthropic.Anthropic object at 0x109560610>\n"
     ]
    }
   ],
   "source": [
    "client_type = llm_client_service_provider\n",
    "client_kwargs = {}\n",
    "client = None\n",
    "client_factory = ClientFactory()\n",
    "if client_type == \"openai\" or client_type == \"anyscale\":\n",
    "    client_factory.register_client(client_type, OpenAI)\n",
    "    client_kwargs = {\"api_key\": openai.api_key,\n",
    "                     \"base_url\": openai.api_base}\n",
    "else:\n",
    "    client_factory.register_client(client_type, Anthropic)\n",
    "    client_kwargs = {\"api_key\": api_key}\n",
    "\n",
    "# create respective client\n",
    "client = client_factory.create_client(client_type, **client_kwargs)\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c9661d6-0d2a-470d-8ead-946c4f8b1950",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are master of all knowledge, and a helpful sage.\n",
    "                    You must complete any incomplete sentence by drawing from your vast\n",
    "                    knowledge about history, literature, science, social science, philosophy, religion, economics, sports, etc.\n",
    "                    You can also identify and categorize named entities.\n",
    "                    You are also an helpful assitant to converse in a dialogue.\n",
    "                  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5186876d-310c-4255-8f22-0f30863e8834",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (NER):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f27d673-7d09-47c5-b0ad-fc9b0c43c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_text = \"\"\"Tesla, headquartered in Palo Alto, was founded by Elon Musk. \n",
    "The company recently announced a collaboration with NASA to explore sustainable technologies for space travel.\"\"\"\n",
    "\n",
    "zero_learning_prompt = f\"\"\"Analyze the text provided in three ticks and identify the named entities present. \n",
    "Categorize them into types such as persons, organizations, and locations. \n",
    "'''{user_text}'''.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "917cce3b-db4d-40e3-996e-2f6ff556b629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the analysis of the text with named entities identified and categorized:\n",
      "\n",
      "Persons:\n",
      "1. Elon Musk\n",
      "\n",
      "Organizations:\n",
      "1. Tesla\n",
      "2. NASA \n",
      "\n",
      "Locations:\n",
      "1. Palo Alto\n",
      "\n",
      "The text mentions that Tesla, a company founded by Elon Musk and headquartered in Palo Alto, California, has announced a partnership with NASA to develop sustainable technologies for space exploration.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, zero_learning_prompt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34a99958-94da-4420-84ad-aca486c6b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_text = \"\"\" In the year 1969, Neil Armstrong became the first person to walk on the moon during the Apollo 11 mission. \n",
    "NASA, headquartered in Washington D.C., spearheaded this historic achievement. \n",
    "Armstrong's fellow astronaut, Buzz Aldrin, joined him in this extraordinary venture. \n",
    "The event took place on July 20, 1969, forever marking a significant milestone in human history.\"\n",
    "\"\"\"\n",
    "zero_learning_prompt = f\"\"\"Analyze the text provided in three ticks and identify the named entities present. \n",
    "Categorize them into types such as persons, organizations, and locations. \n",
    "'''{user_text}'''.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cad62ffd-65cc-48d5-860a-e26a01e6be33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the analysis of the named entities in the provided text, categorized into types:\n",
      "\n",
      "Persons:\n",
      "1. Neil Armstrong\n",
      "2. Buzz Aldrin\n",
      "\n",
      "Organizations:\n",
      "1. NASA (National Aeronautics and Space Administration)\n",
      "\n",
      "Locations:\n",
      "1. Washington D.C.\n",
      "2. Moon\n",
      "\n",
      "Events:\n",
      "1. Apollo 11 mission\n",
      "\n",
      "Dates:\n",
      "1. 1969\n",
      "2. July 20, 1969\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, zero_learning_prompt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69be938c-37d3-406b-8c6e-159c8e9e6a93",
   "metadata": {},
   "source": [
    "## Dialogue Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "762eb764-429f-4128-ad6d-b9779e772017",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_text = \"\"\"Hello, I've been experiencing issues with the software. It keeps crashing whenever I try to open a specific file. \n",
    "Can you help?\n",
    "\"\"\"\n",
    "dialogue_zero_learning_promt = f\"\"\"Generate a conversation between a customer and a support agent discussing a technical issue related to a software product\n",
    "provided in the {user_text}. \n",
    "Note that the model has not been provided with specific examples of this dialogue during training\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "818823d5-b0ed-4559-926c-eee27c5423ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a sample conversation between a customer and support agent about a software issue:\n",
      "\n",
      "Customer: Hello, I've been experiencing issues with the software. It keeps crashing whenever I try to open a specific file. Can you help?\n",
      "\n",
      "Support Agent: Hello, I'm sorry to hear you're having trouble with the software crashing. I'd be happy to assist you with this issue. Can you please provide some more details about the problem? What type of file are you trying to open when the crash occurs?\n",
      "\n",
      "Customer: It's a large Excel spreadsheet, about 15MB in size. The software starts to open the file but then unexpectedly quits after about 10 seconds. I don't have any issues with smaller Excel files, only this one large spreadsheet.\n",
      "\n",
      "Support Agent: Thank you for those details. It sounds like the software may be having trouble handling such a large file size. As a first troubleshooting step, could you please try opening the file on a different computer to see if the crash still occurs? That will help determine if it's an issue with that specific Excel file or with the software installation on your machine.\n",
      "\n",
      "Customer: I just tried on my colleague's computer and had the same issue there - the software crashed when trying to open this large Excel file. So it doesn't seem to be specific to my computer. \n",
      "\n",
      "Support Agent: Okay, thanks for testing that. Since the issue is happening on multiple machines, the problem likely lies with either the Excel file itself being corrupted in some way, or a bug with how our software handles larger files. Let's try a couple things:\n",
      "\n",
      "1. If possible, could you try saving that Excel spreadsheet as a new file and see if the newly saved version can be opened in our software without crashing? Sometimes re-saving can resolve corruption.\n",
      "\n",
      "2. If a re-saved file doesn't work, I'd like to get a copy of that spreadsheet so our development team can use it to diagnose the issue and develop a fix. Could you please upload the Excel file to this secure link? I'll open a ticket with development to investigate further.\n",
      "\n",
      "Customer: I just tried re-saving the spreadsheet as a new Excel file, but the software is still crashing when I try to open it. I have now uploaded the file to the link you provided. Please let me know once the developers are able to find a solution. This spreadsheet contains important data for my weekly reports, so I need to be able to open it as soon as possible.\n",
      "\n",
      "Support Agent: I completely understand the urgency and we'll make this a priority to resolve for you. I've downloaded the file you provided and opened a ticket with our development team, marked as high priority. They'll work to identify the root cause and develop a patch to fix the crashing issue. I've also noted the business impact this is having on your weekly reporting.\n",
      "\n",
      "Our standard SLA for high priority bugs is 2 business days for a patch to be released. I will monitor the ticket closely and reach out to development for any updates. Once a fix is available, I will contact you immediately with instructions to update your software. In the meantime, please let me know if you have any other questions or if there is anything else I can assist with.\n",
      "\n",
      "Customer: Thank you for escalating this to your development team so quickly. I appreciate you understanding the urgency and business impact. I look forward to hearing from you once a fix is available. I don't have any other questions at this time.\n",
      "\n",
      "Support Agent: You're welcome! I'm happy I could help get this resolved for you. I'll be in touch soon once I have an update from development. In the meantime, please don't hesitate to contact me if you need anything else. Thank you for your patience and understanding. Have a great rest of your day!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, dialogue_zero_learning_promt)\n",
    "print(f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179b3682-fac7-44e3-8526-5bcb2f421daf",
   "metadata": {},
   "source": [
    "## All this is amazing! 😜 Feel the wizardy prompt power 🧙‍♀️"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
