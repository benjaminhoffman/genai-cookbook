{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0030bcd2-4557-40d6-8bdf-7c21f1090f88",
   "metadata": {},
   "source": [
    "# Simple Retrieval Augmenation Generation (RAG) \n",
    "\n",
    "<img src=\"images/simple_rag_flow.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bc56f7d-04c8-43fb-9503-29e85988eff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.insert(0, \"../llm-prompts\")\n",
    "\n",
    "from rag_utils import read_pdf_chunks, extract_matches, print_matches\n",
    "import os\n",
    "from anthropic import Anthropic\n",
    "from tqdm.auto import tqdm\n",
    "from llm_clnt_factory_api import ClientFactory, get_commpletion\n",
    "from rag_utils import print_matches, extract_matches\n",
    "from pinecone import Pinecone, PodSpec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf30f3b-0c04-4bb5-adeb-8e6e6080c2fc",
   "metadata": {},
   "source": [
    "1. Setup  global variables\n",
    "2. Load the environment file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a60efa-4527-4f10-a707-9c2aad3de469",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 5\n",
    "INDEX_NAME = \"starter-index\"\n",
    "BOLD_BEGIN = \"\\033[1m\"\n",
    "BOLD_END   =   \"\\033[0m\"\n",
    "PINECONE_ENVIRONMENT = \"gcp-starter\"\n",
    "PDF_DIRECTORY = \"pdfs\"\n",
    "VERBOSE = True\n",
    "CHUNK_SIZE = 500\n",
    "CHUNK_OVERLAP = 20\n",
    "DIR_PATH = os.path.join(os.getcwd(),PDF_DIRECTORY)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# create a model for creating embeddings\n",
    "MODEL = model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76906d5-c73a-4342-8640-53d953b22ccf",
   "metadata": {},
   "source": [
    "Set up Pinecone environment. Use the .env file to load the Pinecone API key\n",
    "and the environment name, which is \"gcp-starter\" in this case, for the GCP starter environment community edition of Pinecone is also available for free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a137b7e-8ed7-424d-85a6-574ca2aec582",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "if pinecone_api_key is None:\n",
    "    raise ValueError(\"Please set the PINECONE_API_KEY environment\")\n",
    "pc = Pinecone(api_key=pinecone_api_key,\n",
    "              environment=\"gcp-starter\",\n",
    "              spec=PodSpec(environment=\"gcp-starter\")\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c563f7d-53a3-4e61-8b88-7a017eb15b2c",
   "metadata": {},
   "source": [
    "Check if the Pinecone index exisits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a64f832-e4da-49cc-bb69-07de1ce31807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index starter-index already exists. Deleting it ...\n"
     ]
    }
   ],
   "source": [
    "existing_indexes = [\n",
    "    index_info[\"name\"] for index_info in pc.list_indexes() \n",
    "]\n",
    "\n",
    "if INDEX_NAME in existing_indexes:\n",
    "    print(f\"Index {INDEX_NAME} already exists. Deleting it ...\")\n",
    "    pc.delete_index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c86b2-88bd-4879-a109-008cc96e3423",
   "metadata": {},
   "source": [
    "### Step 1: Create a new index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6a4bb9d-22ab-4378-8575-3bc2677fbcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new index starter-index...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Creating a new index {INDEX_NAME}...\")\n",
    "pc.create_index(name=INDEX_NAME,\n",
    "                metric=\"cosine\",\n",
    "                dimension=384,\n",
    "                spec=PodSpec(environment=\"gcp-starter\")\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6316621a-d606-4a17-b2c3-e56180b21c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect or get a handle to the index\n",
    "pindex = pc.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "715e4402-aba5-4153-9ffc-7b8af30ae5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83f7827fb39414b9b903e90cb9503df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /Users/julesdamji/git-repos/genai-cookbook/rags/pdfs/HAI_AI-Index-Report_2023.pdf\n",
      "Upserting batch id: 0-HAI_AI-Index-Report_2023.pdf\n",
      "Upserting batch id: 100-HAI_AI-Index-Report_2023.pdf\n",
      "Upserting batch id: 200-HAI_AI-Index-Report_2023.pdf\n",
      "Upserting batch id: 300-HAI_AI-Index-Report_2023.pdf\n",
      "Upserting batch id: 400-HAI_AI-Index-Report_2023.pdf\n",
      "Upserting batch id: 500-HAI_AI-Index-Report_2023.pdf\n",
      "Upserting batch id: 600-HAI_AI-Index-Report_2023.pdf\n",
      "Upserting batch id: 700-HAI_AI-Index-Report_2023.pdf\n",
      "Upserting batch id: 800-HAI_AI-Index-Report_2023.pdf\n",
      "Upserting batch id: 900-HAI_AI-Index-Report_2023.pdf\n",
      "Upserting batch id: 1000-HAI_AI-Index-Report_2023.pdf\n",
      "Upserting batch id: 1100-HAI_AI-Index-Report_2023.pdf\n",
      "Upserting batch id: 1200-HAI_AI-Index-Report_2023.pdf\n",
      "Upserting batch id: 1300-HAI_AI-Index-Report_2023.pdf\n",
      "Upserting batch id: 1400-HAI_AI-Index-Report_2023.pdf\n"
     ]
    }
   ],
   "source": [
    "# read each file in the directory\n",
    "for filename in tqdm(os.listdir(DIR_PATH)):\n",
    "    if filename.endswith('.pdf'):\n",
    "        file_path = os.path.join(DIR_PATH, filename)\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        for i, chunk in enumerate(read_pdf_chunks(file_path, \n",
    "                    CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)):\n",
    "            # Process each chunk (e.g., create vector embeddings)\n",
    "            embeddings = model.encode(chunk)\n",
    "\n",
    "            # create a metadata batch\n",
    "            c_id = \"\".join([str(i), '-', filename])\n",
    "            sample_doc = [\n",
    "                { \"id\":  c_id ,\n",
    "                    \"values\": embeddings.tolist(),\n",
    "                    \"metadata\": {\n",
    "                        \"text\": chunk\n",
    "                    }\n",
    "                 }\n",
    "            ]\n",
    "            if VERBOSE:\n",
    "                if i % 100 == 0:\n",
    "                     print(f\"Upserting batch id: { c_id}\")\n",
    "                        \n",
    "                # upsert to Pinecone\n",
    "                pindex.upsert(sample_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce06e2f-1ea8-477b-866d-b770201eef2a",
   "metadata": {},
   "source": [
    "### Step 2: Search the index \n",
    "\n",
    "Get the matching documents for a user query from the Pinecone index. This\n",
    "step is the retriever bit. We will use this as part of our context and query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e724727c-eaf1-4114-81b7-464b82903529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a semantic search...\n",
      "Query: What are the key takeaways for AI in 2023?\n",
      "Top 5 results for the query:\n",
      "Score  : 0.69\n",
      "Matches: Figure 4.3.20advertising and marketing (8.8%) (Figure 4.3.20). \n",
      "Compared to 2018, some of the less prevalent \n",
      "AI-related themes in 2022 included deep learning \n",
      "(4.8%), autonomous vehicles (3.1%), and data \n",
      "storage and management (3.0%).\n",
      "Score  : 0.68\n",
      "Matches: broader range of societal actors. This yearâ€™s AI Index paints a picture of where we are so far with AI, in order to \n",
      "highlight what might await us in the future.\n",
      "Jack Clark and Ray Perrault\n",
      "Score  : 0.67\n",
      "Matches: Table of Contents\n",
      " 267\n",
      "Artificial Intelligence\n",
      "Index Report 2023 Chapter 6 PreviewIn the last 10 years, AI governance discussions have accelerated, resulting in numerous policy proposals in various legislative bodies. This \n",
      "section begins by exploring the legislative initiatives related to AI that have been suggested or enacted in different countries and regions,\n",
      "Score  : 0.66\n",
      "Matches: increased nearly 6.5 times since 2016.When it comes to AI, \n",
      "policymakers have  \n",
      "a lot of thoughts.   \n",
      "A qualitative analysis of the \n",
      "parliamentary proceedings of a \n",
      "diverse group of nations reveals \n",
      "that policymakers think about AI \n",
      "from a wide range of perspectives. \n",
      "For example, in 2022, legislators in \n",
      "the United Kingdom discussed the \n",
      "risks of AI-led automation; those \n",
      "in Japan considered the necessity \n",
      "of safeguarding human rights in \n",
      "the face of AI; and those in Zambia\n",
      "Score  : 0.65\n",
      "Matches: generation of text, image, and code unimagined a decade ago, and they outperform the state of the art on many \n",
      "benchmarks, old and new. However, they are prone to hallucination, routinely biased, and can be tricked into \n",
      "serving nefarious aims, highlighting the complicated ethical challenges associated with their deployment.\n",
      "Although 2022 was the first year in a decade where private AI investment decreased, AI is still a topic of great\n"
     ]
    }
   ],
   "source": [
    "print(\"Running a semantic search...\")\n",
    "query = \"What are the key takeaways for AI in 2023?\"\n",
    "print(f\"Query: {query}\")\n",
    "query_embedding = model.encode(query).tolist()\n",
    "results = pindex.query(vector=query_embedding, top_k=TOP_K,\n",
    "                        include_values=False, \n",
    "                        include_metadata=True)\n",
    "\n",
    "print(f\"Top {TOP_K} results for the query:\")\n",
    "print_matches(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a8433b-dc47-4ee0-92e8-8e2122637488",
   "metadata": {},
   "source": [
    "### Extract the context from the matching results for an LLM query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d25f338d-8098-4628-bf3c-d46051f3bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\".join(extract_matches(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9017e1a2-b360-466b-bfb3-b871abc5a361",
   "metadata": {},
   "source": [
    "### Construct our query \n",
    "Plus the matches returned from the vector db for the LLM model to finalize\n",
    "the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93222628-d618-40f7-b84a-38d98f0566a0",
   "metadata": {},
   "source": [
    "### Step 3: Create an Anthropic client instance\n",
    "\n",
    "Using our client factory method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7169d189-659a-4e92-ae84-353ff5a5636d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=claude-3-opus-20240229; base=Anthropic\n"
     ]
    }
   ],
   "source": [
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={'Anthropic'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd7637f1-dea1-47f7-8143-23c677b27ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_factory = ClientFactory()\n",
    "client_type = \"anthropic\"\n",
    "client_factory.register_client(client_type, Anthropic)\n",
    "client_kwargs = {\"api_key\": anthropic_api_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2aa4cde7-c88e-4794-b66c-40f4178e21b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the client\n",
    "client = client_factory.create_client(client_type, **client_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f56840-421c-4ef3-a516-cdbd1f9ff339",
   "metadata": {},
   "source": [
    "### Step 4: Create system and user prompt for the LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97923c81-cf4b-404e-a940-7933c42c1aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are master of all knowledge, and a helpful sage.\n",
    "                        You must summarize content given to you by drawing from your vast\n",
    "                        knowledge about history, literature, science, social science, philosophy, religion, economics, \n",
    "                        sports, etc. Do not make up any responses. Only provide information that is true and verifiable\n",
    "                        and use the given context to provide the response.\n",
    "                     \"\"\"\n",
    "    \n",
    "user_content = f\"\"\"What are the key takeaways for AI in 2023 from the HAI_AI Index Report_2023?,\n",
    "                        given the {context}. Only provide information that is true and verifiable\n",
    "                        and use the given context to provide the response.\n",
    "                     \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c65187-d795-4302-80a6-0dbfb3f38b82",
   "metadata": {},
   "source": [
    "### Step 5: Send the query + context to the LLM model\n",
    "This is the final step in the diagram above where we\n",
    "take the matching documents that our Pinecone search\n",
    "retriever fetched, combine it with our LLM query as\n",
    "part of the context, create a prompt, and the fetch\n",
    "the summarized results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cacd0da-2cae-4544-8a67-25b907ccc587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mPrompt:\u001b[0m What are the key takeaways for AI in 2023 from the HAI_AI Index Report_2023?,\n",
      "                        given the Figure 4.3.20advertising and marketing (8.8%) (Figure 4.3.20). \n",
      "Compared to 2018, some of the less prevalent \n",
      "AI-related themes in 2022 included deep learning \n",
      "(4.8%), autonomous vehicles (3.1%), and data \n",
      "storage and management (3.0%).broader range of societal actors. This yearâ€™s AI Index paints a picture of where we are so far with AI, in order to \n",
      "highlight what might await us in the future.\n",
      "Jack Clark and Ray PerraultTable of Contents\n",
      " 267\n",
      "Artificial Intelligence\n",
      "Index Report 2023 Chapter 6 PreviewIn the last 10 years, AI governance discussions have accelerated, resulting in numerous policy proposals in various legislative bodies. This \n",
      "section begins by exploring the legislative initiatives related to AI that have been suggested or enacted in different countries and regions,increased nearly 6.5 times since 2016.When it comes to AI, \n",
      "policymakers have  \n",
      "a lot of thoughts.   \n",
      "A qualitative analysis of the \n",
      "parliamentary proceedings of a \n",
      "diverse group of nations reveals \n",
      "that policymakers think about AI \n",
      "from a wide range of perspectives. \n",
      "For example, in 2022, legislators in \n",
      "the United Kingdom discussed the \n",
      "risks of AI-led automation; those \n",
      "in Japan considered the necessity \n",
      "of safeguarding human rights in \n",
      "the face of AI; and those in Zambiageneration of text, image, and code unimagined a decade ago, and they outperform the state of the art on many \n",
      "benchmarks, old and new. However, they are prone to hallucination, routinely biased, and can be tricked into \n",
      "serving nefarious aims, highlighting the complicated ethical challenges associated with their deployment.\n",
      "Although 2022 was the first year in a decade where private AI investment decreased, AI is still a topic of great. Only provide information that is true and verifiable\n",
      "                        and use the given context to provide the response.\n",
      "                     \n",
      "\n",
      "\u001b[1mAnswer:\u001b[0m Based on the excerpts provided from the HAI AI Index Report 2023, some key takeaways about AI in 2023 include:\n",
      "\n",
      "1. AI governance discussions and legislative initiatives related to AI have accelerated significantly in the last 10 years across many countries. Parliamentary proceedings show policymakers are thinking about AI from diverse perspectives like automation risks, safeguarding human rights, and economic impacts.\n",
      "\n",
      "2. Large language models have made remarkable progress, enabling generation of text, image and code at levels unimagined a decade ago. However, they still have issues like hallucination, bias, and potential for misuse, highlighting ethical challenges in deploying them.\n",
      "\n",
      "3. While 2022 saw the first decrease in private AI investment in a decade, AI remains a major focus of interest and investment. The number of AI-related publications increased nearly 6.5 times since 2016, showing strong ongoing research activity.\n",
      "\n",
      "4. Compared to 2018, some less prevalent AI topics in 2022 included deep learning, autonomous vehicles, and data storage/management. Advertising and marketing made up 8.8% of AI-related themes in 2022.\n",
      "\n",
      "So in summary, the report depicts accelerating governance efforts, remarkable technical progress yet ongoing challenges with language models, sustained investment and research interest, and some shifting focus in AI application areas in recent years. The overall picture is of a transformative technology that is advancing rapidly but also raising important policy questions.\n"
     ]
    }
   ],
   "source": [
    "response = get_commpletion(client, MODEL, system_content, user_content)\n",
    "response = response.replace(\"```\", \"\")\n",
    "print(f\"\\n{BOLD_BEGIN}Prompt:{BOLD_END} {user_content}\")\n",
    "print(f\"\\n{BOLD_BEGIN}Answer:{BOLD_END} {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
