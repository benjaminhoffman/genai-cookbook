{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17597541-28b7-443c-8ecf-f34e5eb27b19",
   "metadata": {},
   "source": [
    "# OpenAI Assistants APIs\n",
    "\n",
    "The Assistants' API lets you create AI assistants in your applications. These assistants follow instructions and use models, tools, and knowledge to answer user questions. In this notebook we are going to use one of the tools, retriever,\n",
    "to query against two pdf documents we will upload.\n",
    "\n",
    "The architeture and data flow diagram below depicts the interaction among all components that comprise OpenAI Assistant APIs. Central to understand is the Threads and Runtime that executes anyschronously, adding and reading messages to the Threads.\n",
    "\n",
    "For integrating the Assistants API:\n",
    "\n",
    "1. Creat an Assistant with custom instructions and select a model. Optionally, enable tools like Code Interpreter, Retrieval, and Function Calling.\n",
    "\n",
    "2. Initiate a Thread for each user conversation.\n",
    "    \n",
    "3. Add user queries as Messages to the Thread.\n",
    "\n",
    "4.  Run the Assistant on the Thread for responses, which automatically utilizes the enabled tools\n",
    "\n",
    "Below we follow those steps to demonstrate how to integrate Assistants API, using function tool, to ask our Assistant to interact with an external webservice, such\n",
    "as Google Search. This external service could be any external [API Webserivce](https://apilayer.com/)\n",
    "\n",
    "The OpenAI documentation describes in details [how Assistants work](https://platform.openai.com/docs/assistants/how-it-works).\n",
    "\n",
    "<img src=\"./images/assistant_ai_tools_functions_google.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a0aeea-916b-4141-800e-3a4252d50f38",
   "metadata": {},
   "source": [
    "## How to use Assistant API using Tools: Function calling\n",
    "In this example, we will use an external service. That is,\n",
    "our function will call an external web service: Google Search API\n",
    "to fetch the results of the query requested. \n",
    "\n",
    "This is an example of how an Assistant can employ an external tool, such as a webservice. Our query could be part of a larger\n",
    "application using LLM and Assitant to respond to user query, and then using the results fetched to use downstream.\n",
    "\n",
    "Let's see how we can do it. The steps are not dissimilar to our\n",
    "previous notebook. The only difference here is that our function is make an external webservice call and we have a different function JSON definition to match the the arguments to our function call, which it can use to pass to an external webservice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7221e33e-a4b4-4471-b0fd-f39352dc1007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import List, Dict, Any\n",
    "from assistant_utils import print_thread_messages, upload_files, \\\n",
    "                            loop_until_completed, create_assistant_run\n",
    "from function_utils import add_prime_numbers\n",
    "from google_search_utils import google_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85b5deb-62d9-4830-ab6b-b603013a8ade",
   "metadata": {},
   "source": [
    "Load our .env file with respective API keys and base url endpoints. Here you can either use OpenAI or Anyscale Endpoints. **Note**: Assistant API calling for Anyscale Endpoints (which serves only OS modles) is not yet aviable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d357f146-9ef1-4793-9c50-6909186016d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\", \"\")\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "452ee529-e60f-4396-b513-52ff251b950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114533c0-b541-45a1-b7bd-58cc0dd825af",
   "metadata": {},
   "source": [
    "### Step 1: Create our custom function definition\n",
    "This our JSON object definiton for our function:\n",
    "* name of the function\n",
    "* parameters for the funtion\n",
    "* type of arguments\n",
    "* descriptions for function and each parameter type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee903bfb-77d3-498e-b3cf-32592d6ee985",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_google_query = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"google_search\",\n",
    "        \"description\": \"A function takes in a search query, api key, and optionly num of results specified. \",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\" : {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\" : \"The search query to send to the Google Search Engine\"\n",
    "                },\n",
    "                \"api_key\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\" : \"Google Search API key\"\n",
    "    \n",
    "                },\n",
    "                \"num_results\" : {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\" : \"number of results. This is a optional one, default is 1\"\n",
    "    \n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"query\", \"api_key\"]\n",
    "}\n",
    "tools = [search_google_query]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0e616e-ff1d-4917-9b2c-26838cd92878",
   "metadata": {},
   "source": [
    "### Step 2: Create an Assistant \n",
    "Before you can start interacting with the Assistant to carry out any tasks, you need an AI assistant object. Supply the Assistant with a model to use, tools, i.e., functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "992306fb-0a4c-4278-a555-6ebf923bdf69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assistant(id='asst_5WPKgzaukL3knNYPmNqBwgWb', created_at=1703729998, description=None, file_ids=[], instructions='You are a knowledgeable and helpful chatbot trained to resolve Google interact\\nwith external webservices such as Google via help of function calls\\n', metadata={}, model='gpt-4-1106-preview', name='AI Assistant for Web services', object='assistant', tools=[ToolFunction(function=FunctionDefinition(name='google_search', description='A function takes in a search query, api key, and optionly num of results specified. ', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query to send to the Google Search Engine'}, 'api_key': {'type': 'string', 'description': 'Google Search API key'}, 'num_results': {'type': 'integer', 'description': 'number of results. This is a optional one, default is 1'}}}), type='function')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = \"\"\"You are a knowledgeable and helpful chatbot trained to resolve Google interact\n",
    "with external webservices such as Google via help of function calls\n",
    "\"\"\"\n",
    "assistant = client.beta.assistants.create(name=\"AI Assistant for Web services\",\n",
    "                                           instructions=instructions,\n",
    "                                           model=MODEL,\n",
    "                                           tools=tools)\n",
    "assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e4c263-0111-447f-a196-6fc2bea6e8b2",
   "metadata": {},
   "source": [
    "### Step 3: Create an empty thread \n",
    "As the diagram above shows, the Thread is the object with which the AI Assistant runs will interact with, by fetching messages and putting messages to it. Think of a thread as a \"conversation session between an Assistant and a user. Threads store Messages and automatically handle truncation to fit content into a modelâ€™s context window.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b52376b5-2bb1-446a-adfa-7fa679ecf321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thread(id='thread_TNdi96188xqHn9ijf9f7pIJz', created_at=1703729998, metadata={}, object='thread')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7834e0-8a1d-4337-963a-6615d0b4c0f3",
   "metadata": {},
   "source": [
    "### Step 4: Add your message query to the thread for the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be6ff8a4-492f-42f1-8074-d5bf10b46014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreadMessage(id='msg_vEIS0XnjGGtSS0c6r8UrzyOY', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Search Google for the top 5 Italian resturants in San Francisco.\\n    '), type='text')], created_at=1703729998, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_TNdi96188xqHn9ijf9f7pIJz')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = \"\"\"Search Google for the top 5 Italian resturants in San Francisco.\n",
    "    \"\"\"\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id, \n",
    "    role=\"user\",\n",
    "    content=content\n",
    ")\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce5092f-9cc1-4798-92b9-66465fae29e8",
   "metadata": {},
   "source": [
    "### Step 5: Create a Run for the Assistant\n",
    "A Run is an invocation of an Assistant on a Thread. The Assistant uses itâ€™s configuration and the Threadâ€™s Messages to perform tasks by calling models and tools. As part of a Run, the Assistant appends Messages to the Thread.\n",
    "\n",
    "Note that Assistance will run asychronously: the run has the following\n",
    "lifecycle and states: [*expired, completed, requires, failed, cancelled*]. Run objects can have multiple statuses.\n",
    "\n",
    "<img src=\"https://cdn.openai.com/API/docs/images/diagram-1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "307efd65-4b73-4164-8628-3182580c0bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"run_u8jlqfAvXnAI9FE1JrSSh4pD\",\n",
      "  \"assistant_id\": \"asst_5WPKgzaukL3knNYPmNqBwgWb\",\n",
      "  \"cancelled_at\": null,\n",
      "  \"completed_at\": null,\n",
      "  \"created_at\": 1703729999,\n",
      "  \"expires_at\": 1703730599,\n",
      "  \"failed_at\": null,\n",
      "  \"file_ids\": [],\n",
      "  \"instructions\": \"Search Google for the top 5 Italian resturants in San Francisco.\\n    \",\n",
      "  \"last_error\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4-1106-preview\",\n",
      "  \"object\": \"thread.run\",\n",
      "  \"required_action\": null,\n",
      "  \"started_at\": null,\n",
      "  \"status\": \"queued\",\n",
      "  \"thread_id\": \"thread_TNdi96188xqHn9ijf9f7pIJz\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"function\": {\n",
      "        \"name\": \"google_search\",\n",
      "        \"description\": \"A function takes in a search query, api key, and optionly num of results specified. \",\n",
      "        \"parameters\": {\n",
      "          \"type\": \"object\",\n",
      "          \"properties\": {\n",
      "            \"query\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"The search query to send to the Google Search Engine\"\n",
      "            },\n",
      "            \"api_key\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"Google Search API key\"\n",
      "            },\n",
      "            \"num_results\": {\n",
      "              \"type\": \"integer\",\n",
      "              \"description\": \"number of results. This is a optional one, default is 1\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"type\": \"function\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "instruction_msg = content\n",
    "run = create_assistant_run(client, assistant, thread, instruction_msg)\n",
    "print(run.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f1dcf3-cebd-4c88-b686-67cc3c97176c",
   "metadata": {},
   "source": [
    "### Step 6: Retrieve the status and loop until the Assistant run status is `completed`\n",
    "Loop until run status is **required_action**, which is a trigger notification to extract arguments generated by the LLM model and carry onto the next step: invoke the function with the generated arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8e5c272-c369-40f1-80a8-eb15d55550dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_progress\n",
      "Assistant state: in_progress waiting Assistant to process...\n",
      "requires_action\n",
      "Assistant taking required action: Function calling...\n",
      "in_progress\n",
      "Assistant state: in_progress waiting Assistant to process...\n",
      "in_progress\n",
      "Assistant state: in_progress waiting Assistant to process...\n",
      "in_progress\n",
      "Assistant state: in_progress waiting Assistant to process...\n",
      "in_progress\n",
      "Assistant state: in_progress waiting Assistant to process...\n",
      "completed\n",
      "\n",
      "Final output from the run:\n",
      "\n",
      "('assistant:Here are five sources where you can find top Italian restaurants '\n",
      " 'in San Francisco:\\n'\n",
      " '\\n'\n",
      " '1. [Eater San '\n",
      " 'Francisco](https://sf.eater.com/maps/best-italian-restaurants-san-francisco) '\n",
      " 'lists \"15 Primo Italian Restaurants in San Francisco\", including Original '\n",
      " \"Joe's and A16.\\n\"\n",
      " '\\n'\n",
      " '2. '\n",
      " '[TripAdvisor](https://www.tripadvisor.com/Restaurants-g60713-c26-San_Francisco_California.html) '\n",
      " \"features Italian restaurants in San Francisco, with Luisa's Restaurant Wine \"\n",
      " 'Bar and Molinari Delicatessen mentioned.\\n'\n",
      " '\\n'\n",
      " '3. [The '\n",
      " 'Infatuation](https://www.theinfatuation.com/san-francisco/guides/best-italian-restaurants-san-francisco) '\n",
      " 'provides a guide to \"The 16 Best Italian Restaurants In San Francisco\" for '\n",
      " 'various Italian dishes.\\n'\n",
      " '\\n'\n",
      " \"4. A discussion on [Fodor's \"\n",
      " 'Travel](https://www.fodors.com/community/united-states/best-italian-restaurant-in-san-francisco-723908/) '\n",
      " 'talks about top Italian restaurants including Perbacco and Acquerello.\\n'\n",
      " '\\n'\n",
      " '5. The subreddit '\n",
      " '[r/AskSF](https://www.reddit.com/r/AskSF/comments/13awfnm/best_italian_food/) '\n",
      " 'on Reddit where users discuss the best Italian food in the area, mentioning '\n",
      " 'Acqurello and Trattoria Contadina.\\n'\n",
      " '\\n'\n",
      " 'Please note that these sources may list more than five restaurants, and the '\n",
      " 'restaurants are not ranked in any particular order. You can visit the links '\n",
      " \"provided to explore your options and decide which Italian restaurants you'd \"\n",
      " 'like to try.')\n",
      "'user:Search Google for the top 5 Italian resturants in San Francisco.\\n    '\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Wait for 2.5 seconds\n",
    "    time.sleep(2.5)\n",
    "\n",
    "    # Retrieve the run status\n",
    "    run_status = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "    print(run_status.status)\n",
    "    \n",
    "    # If run is completed, get all the messages\n",
    "    # on the thread, inserted by the Assistant's run\n",
    "    if run_status.status == 'completed':\n",
    "        messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id)\n",
    "\n",
    "        # Loop through messages and print content based on role\n",
    "        # and break out of the while loop\n",
    "        print(\"\\nFinal output from the run:\")\n",
    "        print_thread_messages(client, thread)        \n",
    "        break\n",
    "    elif run_status.status == 'requires_action':\n",
    "        print(\"Assistant taking required action: Function calling...\")\n",
    "        required_actions = run_status.required_action.submit_tool_outputs.model_dump()\n",
    "        \n",
    "        # Aggregate output from any function\n",
    "        tool_outputs = []\n",
    "        \n",
    "        import json\n",
    "        for action in required_actions[\"tool_calls\"]:\n",
    "            func_name = action['function']['name']\n",
    "            func_args = json.loads(action['function']['arguments'])\n",
    "            if func_name == \"google_search\":\n",
    "                params = {\n",
    "                    \"query\": func_args[\"query\"],\n",
    "                    \"api_key\": google_api_key,\n",
    "                    \"num_results\": func_args[\"num_results\"]}\n",
    "                search_results = google_search(params)\n",
    "                output = f\"Top Five Italian resturants: {search_results}\"\n",
    "                tool_outputs.append({\n",
    "                    \"tool_call_id\": action['id'],\n",
    "                    \"output\": output})\n",
    "                \n",
    "            else:\n",
    "                raise ValueError(f\"Unknown function: {func_name}\")\n",
    "            \n",
    "        # Sending outputs from the function call back to the Assistant\n",
    "        client.beta.threads.runs.submit_tool_outputs(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "            tool_outputs=tool_outputs)\n",
    "    else:\n",
    "        print(f\"Assistant state: {run_status.status} waiting Assistant to process...\")\n",
    "        time.sleep(2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1df2df-5314-4b89-9b9c-5e0ec8fc0237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the assistant. \n",
    "response = client.beta.assistants.delete(assistant.id)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
