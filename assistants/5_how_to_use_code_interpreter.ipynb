{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "826ff3ac-4219-46f9-831e-96127fad305c",
   "metadata": {},
   "source": [
    "# OpenAI Assistants APIs\n",
    "\n",
    "The Assistants' API lets you create AI assistants in your applications. These assistants follow instructions. They use models, tools, and knowledge to answer user questions. In this notebook we are going to use one of the tools, retriever, to query against a couple pdf documents we will upload.\n",
    "\n",
    "The architecture and data flow diagram below depicts the interaction among all components that comprise OpenAI Assistant APIs. Central to understand is the Threads and Runtime that executes asynchronously, adding and reading messages to the Threads.\n",
    "\n",
    "For integrating the Assistants API:\n",
    "\n",
    "1. Creat an Assistant with custom instructions and select a model. Optionally, enable tools like Code Interpreter, Retrieval, and Function Calling.\n",
    "\n",
    "2. Initiate a Thread for each user conversation.\n",
    "    \n",
    "3. Add user queries as Messages to the Thread.\n",
    "\n",
    "4. Run the Assistant on the Thread for responses, which automatically utilizes the enabled tools\n",
    "\n",
    "Below we follow those steps to demonstrate how to integrate Assistants API, using function tool, to ask our Assistant to interact with an external web services, such as Google Search, Weather Stacks, and OpenAI too.\n",
    "\n",
    "This external service could be any external [API Webserivce](https://apilayer.com/)\n",
    "\n",
    "The OpenAI documentation describes in details [how Assistants work](https://platform.openai.com/docs/assistants/how-it-works).\n",
    "\n",
    "<img src=\"images/assistant_ai_tools_code_interpreter.png\">\n",
    "\n",
    "**Note**: Much of the code and diagrams are inspired from  Randy Michak of [Empowerment AI](https://www.youtube.com/watch?v=yzNG3NnF0YE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eb4198-3419-4168-a4d8-07a23abfb875",
   "metadata": {},
   "source": [
    "## How to use Assistant API using Tools: Python code interpreter\n",
    "In this example, we will use Python Code interpreter. That is,\n",
    "our Assistant will be asked to analyse an uploaded file, generate an image,\n",
    "and a python script. We can ask Assistant questions about the data file loaded, and it will generate a Python script to run it.\n",
    "\n",
    "This is an example of how an Assistant can employ an external tool, such as a Python code interpreter.  Our query could be part of a larger application using LLM and Assitant to respond to user queries to generate Python scripts \n",
    "that can be used downstream.\n",
    "\n",
    "Let's see how we can do it. The steps are not dissimilar to our\n",
    "previous notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab6d5b5-a637-4533-a043-6f363448dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import List, Dict, Any\n",
    "from assistant_utils import print_thread_messages, upload_files, \\\n",
    "                            create_assistant_run "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727bebb5-1ddb-4bca-8a01-857f8b875e42",
   "metadata": {},
   "source": [
    "Load our .env file with respective API keys and base url endpoints. Here you can either use OpenAI or Anyscale Endpoints. **Note**: Assistant API calling for Anyscale Endpoints (which serves only OS models) is not yet aviable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a7eac9-705d-47cf-adac-fc99f0510cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a9cc10-4e3d-4c10-9a5f-8a780167f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24be959d-6808-4ffb-bf9e-a7812a7510ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS_TO_LOAD = [\"docs/ray_meetups_data.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1864f3d-3ff3-45a5-a401-c68e574158d4",
   "metadata": {},
   "source": [
    "### Step 1: Create our knowledgebase\n",
    "This entails uploading your files for the Assistant to use.\n",
    "\n",
    "The Python interpreter will use these files to answer your user \n",
    "queries regarding the darta in the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24db1c1-e763-4ee2-891b-ffbcb4addf99",
   "metadata": {},
   "source": [
    "Upload the data file from your storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddbe8e7a-82d2-4ad5-ba73-cf718d3d342b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FileObject(id='file-GNARwRd3gCXpZrzx7t0UbGSA', bytes=612, created_at=1706048233, filename='ray_meetups_data.csv', object='file', purpose='assistants', status='processed', status_details=None)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_objects = upload_files(client, DOCS_TO_LOAD)\n",
    "file_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baf6ca1c-a382-46b8-a34e-293b61862c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file-GNARwRd3gCXpZrzx7t0UbGSA']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract file ids \n",
    "file_obj_ids = []\n",
    "for f_obj in file_objects:\n",
    "    file_obj_ids.append(file_objects[0].id)\n",
    "file_obj_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3a7399-da99-4ae2-aabd-fa572600828a",
   "metadata": {},
   "source": [
    "### Step 2: Create an Assistant \n",
    "Before you can start interacting with the Assistant to carry out any tasks, you need an AI assistant object. Supply the Assistant with a model to use, tools, i.e., Code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b32910b-e5d8-44ab-b2fa-9fe80aecdd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assistant(id='asst_1CyCdjnO7cKACqcv15BMlwUA', created_at=1706048258, description=None, file_ids=['file-GNARwRd3gCXpZrzx7t0UbGSA'], instructions=\"You are a knowledgeable chatbot trained to respond \\n                                               inquires on documents CSV data files.\\n                                               Use a neutral, professional advisory tone, and only respond by consulting the \\n                                               knowledge base or files you are granted access to. \\n                                               Do not make up answers. If you don't know answer, respond with 'Sorry, I'm afraid\\n                                               I don't have access to that information.'\", metadata={}, model='gpt-4-1106-preview', name='Data Analyst', object='assistant', tools=[ToolCodeInterpreter(type='code_interpreter')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant = client.beta.assistants.create(name=\"Data Analyst\",\n",
    "                                           instructions=\"\"\"You are a knowledgeable chatbot trained to respond \n",
    "                                               inquires on documents CSV data files.\n",
    "                                               Use a neutral, professional advisory tone, and only respond by consulting the \n",
    "                                               knowledge base or files you are granted access to. \n",
    "                                               Do not make up answers. If you don't know answer, respond with 'Sorry, I'm afraid\n",
    "                                               I don't have access to that information.'\"\"\",\n",
    "                                           model=MODEL,\n",
    "                                           tools = [{\"type\": \"code_interpreter\"}],  # use the Code Interpreter tool\n",
    "                                           file_ids=file_obj_ids # use these CSV files uploaded as part of your knowledge base\n",
    ")                                        \n",
    "assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c4a1a5-da10-4abb-822d-f6964010f369",
   "metadata": {},
   "source": [
    "### Step 3: Create a thread \n",
    "As the diagram above shows, the Thread is the conversational object with which the Assistant runs will interact with, by fetching messages (queries) and putting messages (responses) to it. Think of a thread as a \"conversation session\" between an Assistant and a user. Threads store Messages and automatically handle truncation to fit content into a modelâ€™s context window.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca2ffd4-fe2b-4077-90e9-400c4f72cb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thread(id='thread_zxVJj7FgIn9dJz04tH5RCPGg', created_at=1706048263, metadata={}, object='thread')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8c45f-37d9-4530-8946-f5166c525e20",
   "metadata": {},
   "source": [
    "### Step 4: Add your message query to the thread for the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0a2409d-5b55-4654-88c4-ad93a2a0ebf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_dau1qvCMR2SR9IPYqPPBFMbY',\n",
       " 'assistant_id': None,\n",
       " 'content': [{'text': {'annotations': [],\n",
       "    'value': 'Show me the Ray meetup membership growth over the years as linear chart. Save \\n    it as ray_growth_meeetup.png\". Create two wide bar chartsfor the RSVPs and Attended respectively. \\n    Use the x-axis as meetup dates and y-axis as meetup members. Plot bar charts in a stack manner into a single file. \\n    Save it as rsvp_attended.png. Finally, generate the Python code to accomplish this task, and save as code_gen.py'},\n",
       "   'type': 'text'}],\n",
       " 'created_at': 1706048268,\n",
       " 'file_ids': [],\n",
       " 'metadata': {},\n",
       " 'object': 'thread.message',\n",
       " 'role': 'user',\n",
       " 'run_id': None,\n",
       " 'thread_id': 'thread_zxVJj7FgIn9dJz04tH5RCPGg'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id, \n",
    "    role=\"user\",\n",
    "    content=\"\"\"Show me the Ray meetup membership growth over the years as linear chart. Save \n",
    "    it as ray_growth_meeetup.png\". Create two wide bar chartsfor the RSVPs and Attended respectively. \n",
    "    Use the x-axis as meetup dates and y-axis as meetup members. Plot bar charts in a stack manner into a single file. \n",
    "    Save it as rsvp_attended.png. Finally, generate the Python code to accomplish this task, and save as code_gen.py\"\"\",\n",
    ")\n",
    "message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340f9f2c-ed45-4f03-9b69-676981ed5031",
   "metadata": {},
   "source": [
    "### Step 5: Create a Run for the Assistant\n",
    "A Run is an invocation of an Assistant on a Thread. The Assistant uses its configuration and the Threadâ€™s Messages to perform tasks by calling models and tools. As part of a Run, the Assistant appends Messages to the Thread.\n",
    "\n",
    "Note that Assistance will run asychronously: the run has the following\n",
    "lifecycle and states: [*expired, completed, failed, cancelled*]. Run objects can have multiple statuses.\n",
    "\n",
    "<img src=\"https://cdn.openai.com/API/docs/images/diagram-1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5af62473-7808-4358-9d76-8fe3c69b7606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"run_v560iZmnBYorxRE0RT7M9GzY\",\n",
      "  \"assistant_id\": \"asst_1CyCdjnO7cKACqcv15BMlwUA\",\n",
      "  \"cancelled_at\": null,\n",
      "  \"completed_at\": null,\n",
      "  \"created_at\": 1706048276,\n",
      "  \"expires_at\": 1706048876,\n",
      "  \"failed_at\": null,\n",
      "  \"file_ids\": [\n",
      "    \"file-GNARwRd3gCXpZrzx7t0UbGSA\"\n",
      "  ],\n",
      "  \"instructions\": \"Please address the user as Jules Dmatrix.\",\n",
      "  \"last_error\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4-1106-preview\",\n",
      "  \"object\": \"thread.run\",\n",
      "  \"required_action\": null,\n",
      "  \"started_at\": null,\n",
      "  \"status\": \"queued\",\n",
      "  \"thread_id\": \"thread_zxVJj7FgIn9dJz04tH5RCPGg\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"code_interpreter\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "instruction_msg = \"\"\"Please address the user as Jules Dmatrix.\"\"\"\n",
    "run = create_assistant_run(client, assistant, thread, instruction_msg)\n",
    "print(run.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bc9f98-2bb8-419f-b3a8-cf43011e5854",
   "metadata": {},
   "source": [
    "### Step 6: Retrieve the status and loop until the Assistant run status is `completed.`\n",
    "\n",
    "Loop until run status is **required_action**, which is a trigger notification to extract arguments generated by the LLM model and carry onto the next step: invoke the function with the generated arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "717eddf1-4477-4498-b812-b9fb742f14ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "completed\n",
      "\n",
      "Final output from the Assistant run:\n",
      "ThreadMessage(id='msg_vcbnlO1i4f0BQbFI6IhH06MK', assistant_id='asst_1CyCdjnO7cKACqcv15BMlwUA', content=[MessageContentText(text=Text(annotations=[TextAnnotationFilePath(end_index=383, file_path=TextAnnotationFilePathFilePath(file_id='file-qrjhiwrnF7a7JpYGXR3KU5wK'), start_index=344, text='sandbox:/mnt/data/ray_growth_meetup.png', type='file_path'), TextAnnotationFilePath(end_index=472, file_path=TextAnnotationFilePathFilePath(file_id='file-5vOK69ABuzoQ7VS8BPIzizEU'), start_index=437, text='sandbox:/mnt/data/rsvp_attended.png', type='file_path')], value='The stacked bar charts showing RSVPs and Attended for Ray meetups have been created and saved as `rsvp_attended.png`, despite a font-related warning during the saving process which should not affect the outcome of the image.\\n\\nYou can download the images from the following links:\\n\\n- [Ray Meetup Membership Growth Chart (ray_growth_meetup.png)](sandbox:/mnt/data/ray_growth_meetup.png)\\n- [RSVP vs Attended Bar Charts (rsvp_attended.png)](sandbox:/mnt/data/rsvp_attended.png)\\n\\nThe final step is to generate the Python code that accomplishes these tasks and save it as `code_gen.py`. I will create this file next.'), type='text')], created_at=1706048510, file_ids=['file-5vOK69ABuzoQ7VS8BPIzizEU', 'file-qrjhiwrnF7a7JpYGXR3KU5wK'], metadata={}, object='thread.message', role='assistant', run_id='run_v560iZmnBYorxRE0RT7M9GzY', thread_id='thread_zxVJj7FgIn9dJz04tH5RCPGg')\n",
      "ThreadMessage(id='msg_crYNFNwb6heKDw6yZOo98ze5', assistant_id='asst_1CyCdjnO7cKACqcv15BMlwUA', content=[MessageContentText(text=Text(annotations=[], value=\"The issue is now clear: the 'Attended' column has a carriage return character (`\\\\r`) at the end of its name. This is likely due to how the CSV was read and the line terminators that were encountered. We need to clean the column names to remove any trailing whitespace or special characters.\\n\\nI will now correct the column name and recreate the stacked bar charts.\"), type='text')], created_at=1706048473, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_v560iZmnBYorxRE0RT7M9GzY', thread_id='thread_zxVJj7FgIn9dJz04tH5RCPGg')\n",
      "ThreadMessage(id='msg_y0HMupoolc9XPYs5vNS5uDCe', assistant_id='asst_1CyCdjnO7cKACqcv15BMlwUA', content=[MessageContentText(text=Text(annotations=[], value=\"It appears that there was an error with the 'Attended' column when attempting to fill NaN values: the column might not exist or it could have a different name. I will examine the dataset to see if there's an issue with the column names and then proceed to correct the error. Let's check the column names to ensure we are referencing the correct columns.\"), type='text')], created_at=1706048463, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_v560iZmnBYorxRE0RT7M9GzY', thread_id='thread_zxVJj7FgIn9dJz04tH5RCPGg')\n",
      "ThreadMessage(id='msg_qS0Po7SahMS2QXqmR26v393Y', assistant_id='asst_1CyCdjnO7cKACqcv15BMlwUA', content=[MessageContentText(text=Text(annotations=[], value=\"The linear chart showing the Ray meetup membership growth over time has been created and saved as `ray_growth_meetup.png`.\\n\\nNow, let's proceed to create the two wide bar charts for the 'RSVPs' and 'Attended' data, stack them in a single figure, and save the resulting chart as `rsvp_attended.png`.\"), type='text')], created_at=1706048426, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_v560iZmnBYorxRE0RT7M9GzY', thread_id='thread_zxVJj7FgIn9dJz04tH5RCPGg')\n",
      "ThreadMessage(id='msg_MN55H9zIs2jPuaFDSVhdWGCL', assistant_id='asst_1CyCdjnO7cKACqcv15BMlwUA', content=[MessageContentText(text=Text(annotations=[], value=\"The CSV file has been successfully read this time. Now that we have access to the data, I will proceed to clean and prepare it for chart creation, and then generate the plots and Python code as requested.\\n\\nNext, I will:\\n\\n- Create the linear chart depicting the membership growth of the Ray meetup over time.\\n- Create the stacked wide bar charts for RSVPs and Attended.\\n- Save the charts to the specified image files.\\n- Generate and save the Python code that would create these charts to a .py file.\\n\\nLet's start by visualizing the membership growth over time.\"), type='text')], created_at=1706048399, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_v560iZmnBYorxRE0RT7M9GzY', thread_id='thread_zxVJj7FgIn9dJz04tH5RCPGg')\n",
      "ThreadMessage(id='msg_zl7UYg93h9UbMwUJDIO4dTSD', assistant_id='asst_1CyCdjnO7cKACqcv15BMlwUA', content=[MessageContentText(text=Text(annotations=[], value='The file appears to be a CSV file, as the header suggests it contains columns for \"Meetup Date\", \"RSVP\", \"Members\", and \"Attended\", separated by commas. The initial attempt to read it as a CSV might have failed due to some specific formatting issues or other anomalies.\\n\\nNow that we know it\\'s a CSV-like format, I\\'ll try reading the file again as a CSV, and this time we\\'ll be mindful of potential issues that could cause problems, such as a nonstandard delimiter or line terminator. Let\\'s attempt to read the file once more.'), type='text')], created_at=1706048377, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_v560iZmnBYorxRE0RT7M9GzY', thread_id='thread_zxVJj7FgIn9dJz04tH5RCPGg')\n",
      "ThreadMessage(id='msg_LXl4t2d9s1TbyWFIhAAP2VFT', assistant_id='asst_1CyCdjnO7cKACqcv15BMlwUA', content=[MessageContentText(text=Text(annotations=[], value=\"It seems that I'm unable to identify the file format and read the contents using the standard methods for CSV, Excel, or JSON files. Since there's no output indicating either success or failure, I will try another approach to determine the file type by examining the contents in binary mode to get an idea of how to proceed with reading it. Let's do that.\"), type='text')], created_at=1706048363, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_v560iZmnBYorxRE0RT7M9GzY', thread_id='thread_zxVJj7FgIn9dJz04tH5RCPGg')\n",
      "ThreadMessage(id='msg_BOElAPet6S9ZP08xglQEoOdN', assistant_id='asst_1CyCdjnO7cKACqcv15BMlwUA', content=[MessageContentText(text=Text(annotations=[], value=\"It appears that the uploaded file has no extension, which makes it difficult to determine the file type automatically. Without knowing the file format, it's challenging to read and interpret the data correctly. However, I can try reading the file as a CSV, Excel, or even a JSON since these are common file types for data.\\n\\nLet's start by attempting to read the file as a CSV, and if that doesn't work, we can try other file formats.\"), type='text')], created_at=1706048332, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_v560iZmnBYorxRE0RT7M9GzY', thread_id='thread_zxVJj7FgIn9dJz04tH5RCPGg')\n",
      "ThreadMessage(id='msg_krW1E6iQNEjNz6qvlnPvRpf5', assistant_id='asst_1CyCdjnO7cKACqcv15BMlwUA', content=[MessageContentText(text=Text(annotations=[], value=\"It seems that the file may not be in CSV format or it may have a different structure than expected. Unfortunately, I do not have the output to determine the exact issue encountered. Let's try a different approach to inspect the file.\\n\\nWe will attempt to read the file using a more general function that can handle various formats and then proceed with the steps mentioned previously.\"), type='text')], created_at=1706048322, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_v560iZmnBYorxRE0RT7M9GzY', thread_id='thread_zxVJj7FgIn9dJz04tH5RCPGg')\n",
      "ThreadMessage(id='msg_ZI1301ybWfoug5OHtNlfSzAm', assistant_id='asst_1CyCdjnO7cKACqcv15BMlwUA', content=[MessageContentText(text=Text(annotations=[], value=\"To generate the charts you have requested and the Python code file, I will need to perform the following steps:\\n\\n1. Examine the contents of your uploaded file to understand the data structure.\\n2. Clean and prepare the data for plotting the charts.\\n3. Create the linear chart showing Ray meetup membership growth over the years.\\n4. Create two wide bar charts in a stacked manner for RSVPs and Attended, respectively, using meetup dates as the x-axis and members as the y-axis.\\n5. Save the charts as 'ray_growth_meetup.png' and 'rsvp_attended.png'.\\n6. Generate the Python code to accomplish this task and save it as 'code_gen.py'.\\n\\nLet's start by examining the contents of your uploaded file to understand the data structure.\"), type='text')], created_at=1706048277, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_v560iZmnBYorxRE0RT7M9GzY', thread_id='thread_zxVJj7FgIn9dJz04tH5RCPGg')\n",
      "ThreadMessage(id='msg_dau1qvCMR2SR9IPYqPPBFMbY', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Show me the Ray meetup membership growth over the years as linear chart. Save \\n    it as ray_growth_meeetup.png\". Create two wide bar chartsfor the RSVPs and Attended respectively. \\n    Use the x-axis as meetup dates and y-axis as meetup members. Plot bar charts in a stack manner into a single file. \\n    Save it as rsvp_attended.png. Finally, generate the Python code to accomplish this task, and save as code_gen.py'), type='text')], created_at=1706048268, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_zxVJj7FgIn9dJz04tH5RCPGg')\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    time.sleep(5)\n",
    "    # Retrieve the run status\n",
    "    run_status = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "    print(run_status.status)\n",
    "    \n",
    "    # If run is completed, get all the messages\n",
    "    # on the thread, inserted by the Assistant's run\n",
    "    if run_status.status == 'completed':\n",
    "        messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id)\n",
    "\n",
    "        # Loop through messages and print content based on role\n",
    "        # and break out of the while loop\n",
    "        print(\"\\nFinal output from the Assistant run:\")\n",
    "        print_thread_messages(client, thread, content_value=False)        \n",
    "        break\n",
    "    else:\n",
    "        print(f\"Assistant run state: '{run_status.status}' ...\")\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eead0f-4db3-4d05-8507-77aade1ba21d",
   "metadata": {},
   "source": [
    "### Step 7: Extract generated files from the Code Interpreter\n",
    "\n",
    "Partial code for iterating over messages and extracting files borrowed from [here](https://www.youtube.com/watch?v=vW4RSEB4Zzo&t=22s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e2bbfed-f674-4d10-adb4-4a291d0f6d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Role: assistant\n",
      "The stacked bar charts showing RSVPs and Attended for Ray meetups have been created and saved as `rsvp_attended.png`, despite a font-related warning during the saving process which should not affect the outcome of the image.\n",
      "\n",
      "You can download the images from the following links:\n",
      "\n",
      "- [Ray Meetup Membership Growth Chart (ray_growth_meetup.png)](sandbox:/mnt/data/ray_growth_meetup.png)\n",
      "- [RSVP vs Attended Bar Charts (rsvp_attended.png)](sandbox:/mnt/data/rsvp_attended.png)\n",
      "\n",
      "The final step is to generate the Python code that accomplishes these tasks and save it as `code_gen.py`. I will create this file next.\n",
      "Annotation Text: sandbox:/mnt/data/ray_growth_meetup.png\n",
      "File_Id: file-qrjhiwrnF7a7JpYGXR3KU5wK\n",
      "Annotation Text: sandbox:/mnt/data/rsvp_attended.png\n",
      "File_Id: file-5vOK69ABuzoQ7VS8BPIzizEU\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Role: assistant\n",
      "The issue is now clear: the 'Attended' column has a carriage return character (`\\r`) at the end of its name. This is likely due to how the CSV was read and the line terminators that were encountered. We need to clean the column names to remove any trailing whitespace or special characters.\n",
      "\n",
      "I will now correct the column name and recreate the stacked bar charts.\n",
      "No annotations found\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Role: assistant\n",
      "It appears that there was an error with the 'Attended' column when attempting to fill NaN values: the column might not exist or it could have a different name. I will examine the dataset to see if there's an issue with the column names and then proceed to correct the error. Let's check the column names to ensure we are referencing the correct columns.\n",
      "No annotations found\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Role: assistant\n",
      "The linear chart showing the Ray meetup membership growth over time has been created and saved as `ray_growth_meetup.png`.\n",
      "\n",
      "Now, let's proceed to create the two wide bar charts for the 'RSVPs' and 'Attended' data, stack them in a single figure, and save the resulting chart as `rsvp_attended.png`.\n",
      "No annotations found\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Role: assistant\n",
      "The CSV file has been successfully read this time. Now that we have access to the data, I will proceed to clean and prepare it for chart creation, and then generate the plots and Python code as requested.\n",
      "\n",
      "Next, I will:\n",
      "\n",
      "- Create the linear chart depicting the membership growth of the Ray meetup over time.\n",
      "- Create the stacked wide bar charts for RSVPs and Attended.\n",
      "- Save the charts to the specified image files.\n",
      "- Generate and save the Python code that would create these charts to a .py file.\n",
      "\n",
      "Let's start by visualizing the membership growth over time.\n",
      "No annotations found\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Role: assistant\n",
      "The file appears to be a CSV file, as the header suggests it contains columns for \"Meetup Date\", \"RSVP\", \"Members\", and \"Attended\", separated by commas. The initial attempt to read it as a CSV might have failed due to some specific formatting issues or other anomalies.\n",
      "\n",
      "Now that we know it's a CSV-like format, I'll try reading the file again as a CSV, and this time we'll be mindful of potential issues that could cause problems, such as a nonstandard delimiter or line terminator. Let's attempt to read the file once more.\n",
      "No annotations found\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Role: assistant\n",
      "It seems that I'm unable to identify the file format and read the contents using the standard methods for CSV, Excel, or JSON files. Since there's no output indicating either success or failure, I will try another approach to determine the file type by examining the contents in binary mode to get an idea of how to proceed with reading it. Let's do that.\n",
      "No annotations found\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Role: assistant\n",
      "It appears that the uploaded file has no extension, which makes it difficult to determine the file type automatically. Without knowing the file format, it's challenging to read and interpret the data correctly. However, I can try reading the file as a CSV, Excel, or even a JSON since these are common file types for data.\n",
      "\n",
      "Let's start by attempting to read the file as a CSV, and if that doesn't work, we can try other file formats.\n",
      "No annotations found\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Role: assistant\n",
      "It seems that the file may not be in CSV format or it may have a different structure than expected. Unfortunately, I do not have the output to determine the exact issue encountered. Let's try a different approach to inspect the file.\n",
      "\n",
      "We will attempt to read the file using a more general function that can handle various formats and then proceed with the steps mentioned previously.\n",
      "No annotations found\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Role: assistant\n",
      "To generate the charts you have requested and the Python code file, I will need to perform the following steps:\n",
      "\n",
      "1. Examine the contents of your uploaded file to understand the data structure.\n",
      "2. Clean and prepare the data for plotting the charts.\n",
      "3. Create the linear chart showing Ray meetup membership growth over the years.\n",
      "4. Create two wide bar charts in a stacked manner for RSVPs and Attended, respectively, using meetup dates as the x-axis and members as the y-axis.\n",
      "5. Save the charts as 'ray_growth_meetup.png' and 'rsvp_attended.png'.\n",
      "6. Generate the Python code to accomplish this task and save it as 'code_gen.py'.\n",
      "\n",
      "Let's start by examining the contents of your uploaded file to understand the data structure.\n",
      "No annotations found\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Role: user\n",
      "Show me the Ray meetup membership growth over the years as linear chart. Save \n",
      "    it as ray_growth_meeetup.png\". Create two wide bar chartsfor the RSVPs and Attended respectively. \n",
      "    Use the x-axis as meetup dates and y-axis as meetup members. Plot bar charts in a stack manner into a single file. \n",
      "    Save it as rsvp_attended.png. Finally, generate the Python code to accomplish this task, and save as code_gen.py\n",
      "No annotations found\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id)\n",
    "\n",
    "for message in messages:\n",
    "    print(\"-\" * 50)\n",
    "    # Print the role of the sender\n",
    "    print(f\"Role: {message.role}\")\n",
    "\n",
    "    # Process each content item in the message\n",
    "    for content in message.content:\n",
    "        # Check if the content is text\n",
    "        if content.type == 'text':\n",
    "            print(content.text.value)\n",
    "\n",
    "            # Check and print details about annotations if they exist\n",
    "            if content.text.annotations:\n",
    "                for annotation in content.text.annotations:\n",
    "                    print(f\"Annotation Text: {annotation.text}\")\n",
    "                    print(f\"File_Id: {annotation.file_path.file_id}\")\n",
    "                    annotation_data = client.files.content(annotation.file_path.file_id)\n",
    "                    annotation_data_bytes = annotation_data.read()\n",
    "\n",
    "                    # file_extension = annotation.text.split('.')[-1]\n",
    "                    filename = annotation.text.split('/')[-1]\n",
    "\n",
    "                    with open(f\"{filename}\", \"wb\") as file:\n",
    "                        file.write(annotation_data_bytes)\n",
    "            else:\n",
    "                print(\"No annotations found\")\n",
    "\n",
    "        # Check if the content is an image file and print its file ID and name\n",
    "        elif content.type == 'image_file':\n",
    "            print(f\"Image File ID: {content.image_file.file_id}\")\n",
    "            image_data = client.files.content(content.image_file.file_id)\n",
    "            image_data_bytes = image_data.read()\n",
    "\n",
    "            with open(f\"{content.image_file.file_id}.png\", \"wb\") as file:\n",
    "                file.write(image_data_bytes)\n",
    "\n",
    "    # Print a horizontal line for separation between messages\n",
    "    print(\"-\" * 50)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6777131-d028-40bc-8b7c-6ea691e5d085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssistantDeleted(id='asst_1CyCdjnO7cKACqcv15BMlwUA', deleted=True, object='assistant.deleted')\n",
      "deleting file id: file-GNARwRd3gCXpZrzx7t0UbGSA...\n",
      "FileDeleted(id='file-GNARwRd3gCXpZrzx7t0UbGSA', deleted=True, object='file')\n"
     ]
    }
   ],
   "source": [
    "# Delete the assistant. Optionally, you can delete any files\n",
    "# associated with it that you have uploaded onto the OpenAI platform\n",
    "\n",
    "response = client.beta.assistants.delete(assistant.id)\n",
    "print(response)\n",
    "\n",
    "for file_id in file_obj_ids:\n",
    "    print(f\"deleting file id: {file_id}...\")\n",
    "    response = client.files.delete(file_id)\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
