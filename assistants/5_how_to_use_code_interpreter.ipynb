{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "826ff3ac-4219-46f9-831e-96127fad305c",
   "metadata": {},
   "source": [
    "# OpenAI Assistants APIs\n",
    "\n",
    "The Assistants' API lets you create AI assistants in your applications. These assistants follow instructions and use models, tools, and knowledge to answer user questions. In this notebook we are going to use one of the tools, retriever,\n",
    "to query against two pdf documents we will upload.\n",
    "\n",
    "The architeture and data flow diagram below depicts the interaction among all components that comprise OpenAI Assistant APIs. Central to understand is the Threads and Runtime that executes anyschronously, adding and reading messages to the Threads.\n",
    "\n",
    "For integrating the Assistants API:\n",
    "\n",
    "1. Creat an Assistant with custom instructions and select a model. Optionally, enable tools like Code Interpreter, Retrieval, and Function Calling.\n",
    "\n",
    "2. Initiate a Thread for each user conversation.\n",
    "    \n",
    "3. Add user queries as Messages to the Thread.\n",
    "\n",
    "4.  Run the Assistant on the Thread for responses, which automatically utilizes the enabled tools\n",
    "\n",
    "Below we follow those steps to demonstrate how to integrate Assistants API, using function tool, to ask our Assistant to interact with an external web services, such\n",
    "as Google Search, Weather Stacks, and OpenAI too.\n",
    "\n",
    "This external service could be any external [API Webserivce](https://apilayer.com/)\n",
    "\n",
    "The OpenAI documentation describes in details [how Assistants work](https://platform.openai.com/docs/assistants/how-it-works).\n",
    "\n",
    "<img src=\"images/assistant_ai_tools_code_interpreter.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eb4198-3419-4168-a4d8-07a23abfb875",
   "metadata": {},
   "source": [
    "## How to use Assistant API using Tools: Python code interpreter\n",
    "In this example, we will use Python Code interpreter. That is,\n",
    "our Assistant will be asked to analyse an uploaded file, generate an image,\n",
    "and a python script. We can ask Assistant questions about the data file loaded, and it will generate a Python script to run it.\n",
    "\n",
    "This is an example of how an Assistant can employ an external tool, such as a Python code interpreter.  Our query could be part of a larger application using LLM and Assitant to respond to user queries to generate Python scripts \n",
    "that can be used downstream.\n",
    "\n",
    "Let's see how we can do it. The steps are not dissimilar to our\n",
    "previous notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab6d5b5-a637-4533-a043-6f363448dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import List, Dict, Any\n",
    "from assistant_utils import print_thread_messages, upload_files, \\\n",
    "                            create_assistant_run "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727bebb5-1ddb-4bca-8a01-857f8b875e42",
   "metadata": {},
   "source": [
    "Load our .env file with respective API keys and base url endpoints. Here you can either use OpenAI or Anyscale Endpoints. **Note**: Assistant API calling for Anyscale Endpoints (which serves only OS models) is not yet aviable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a7eac9-705d-47cf-adac-fc99f0510cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a9cc10-4e3d-4c10-9a5f-8a780167f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24be959d-6808-4ffb-bf9e-a7812a7510ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS_TO_LOAD = [\"docs/ray_meetups_data.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1864f3d-3ff3-45a5-a401-c68e574158d4",
   "metadata": {},
   "source": [
    "### Step 1: Create our knowledgebase\n",
    "This entails uploading your files for the Assistant to use.\n",
    "\n",
    "The Python interpreter will use these files to answer your user \n",
    "queries regarding the darta in the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24db1c1-e763-4ee2-891b-ffbcb4addf99",
   "metadata": {},
   "source": [
    "Upload the data file from your storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddbe8e7a-82d2-4ad5-ba73-cf718d3d342b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FileObject(id='file-NvpyZyVwrFT2IGKPUvoIKz0x', bytes=612, created_at=1703886366, filename='ray_meetups_data.csv', object='file', purpose='assistants', status='processed', status_details=None)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_objects = upload_files(client, DOCS_TO_LOAD)\n",
    "file_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baf6ca1c-a382-46b8-a34e-293b61862c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file-NvpyZyVwrFT2IGKPUvoIKz0x']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract file ids \n",
    "file_obj_ids = []\n",
    "for f_obj in file_objects:\n",
    "    file_obj_ids.append(file_objects[0].id)\n",
    "file_obj_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3a7399-da99-4ae2-aabd-fa572600828a",
   "metadata": {},
   "source": [
    "### Step 2: Create an Assistant \n",
    "Before you can start interacting with the Assistant to carry out any tasks, you need an AI assistant object. Supply the Assistant with a model to use, tools, i.e., Code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b32910b-e5d8-44ab-b2fa-9fe80aecdd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assistant(id='asst_jQDnJlKpUxc0NpJru3BnhCfP', created_at=1703886366, description=None, file_ids=['file-NvpyZyVwrFT2IGKPUvoIKz0x'], instructions=\"You are a knowledgeable chatbot trained to respond \\n                                               inquires on documents CSV data files.\\n                                               Use a neutral, professional advisory tone, and only respond by consulting the \\n                                               knowledge base or files you are granted access to. \\n                                               Do not make up answers. If you don't know answer, respond with 'Sorry, I'm afraid\\n                                               I don't have access to that information.'\", metadata={}, model='gpt-4-1106-preview', name='Data Analyst', object='assistant', tools=[ToolCodeInterpreter(type='code_interpreter')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant = client.beta.assistants.create(name=\"Data Analyst\",\n",
    "                                           instructions=\"\"\"You are a knowledgeable chatbot trained to respond \n",
    "                                               inquires on documents CSV data files.\n",
    "                                               Use a neutral, professional advisory tone, and only respond by consulting the \n",
    "                                               knowledge base or files you are granted access to. \n",
    "                                               Do not make up answers. If you don't know answer, respond with 'Sorry, I'm afraid\n",
    "                                               I don't have access to that information.'\"\"\",\n",
    "                                           model=MODEL,\n",
    "                                           tools = [{\"type\": \"code_interpreter\"}],  # use the Code Interpreter tool\n",
    "                                           file_ids=file_obj_ids # use these CSV files uploaded as part of your knowledge base\n",
    ")                                        \n",
    "assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c4a1a5-da10-4abb-822d-f6964010f369",
   "metadata": {},
   "source": [
    "### Step 3: Create a thread \n",
    "As the diagram above shows, the Thread is the conversational object with which the Assistant runs will interact with, by fetching messages (queries) and putting messages (responses) to it. Think of a thread as a \"conversation session\" between an Assistant and a user. Threads store Messages and automatically handle truncation to fit content into a modelâ€™s context window.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca2ffd4-fe2b-4077-90e9-400c4f72cb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thread(id='thread_sXIZbavYkmRqpHvTGwKfjpyk', created_at=1703886367, metadata={}, object='thread')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8c45f-37d9-4530-8946-f5166c525e20",
   "metadata": {},
   "source": [
    "### Step 4: Add your message query to the thread for the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0a2409d-5b55-4654-88c4-ad93a2a0ebf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_oCJxZ7kGjSCg3JoH3M53A5gl',\n",
       " 'assistant_id': None,\n",
       " 'content': [{'text': {'annotations': [],\n",
       "    'value': 'Show me the Ray meetup membership growth over the years as linear chart. Save \\n    it as ray_growth_meeetup.png\". Create two wide bar charts for the RSVPs and Attended respectively. \\n    Use the x-axis as meetup dates and y-axis as meetup members. Plot bar charts in a stack manner into a single file. \\n    Save it as rsvp_attended.png. Finally, generate the Python code to accomplish this task, and save as code_gen.py'},\n",
       "   'type': 'text'}],\n",
       " 'created_at': 1703886367,\n",
       " 'file_ids': [],\n",
       " 'metadata': {},\n",
       " 'object': 'thread.message',\n",
       " 'role': 'user',\n",
       " 'run_id': None,\n",
       " 'thread_id': 'thread_sXIZbavYkmRqpHvTGwKfjpyk'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id, \n",
    "    role=\"user\",\n",
    "    content=\"\"\"Show me the Ray meetup membership growth over the years as linear chart. Save \n",
    "    it as ray_growth_meeetup.png\". Create two wide bar chartsfor the RSVPs and Attended respectively. \n",
    "    Use the x-axis as meetup dates and y-axis as meetup members. Plot bar charts in a stack manner into a single file. \n",
    "    Save it as rsvp_attended.png. Finally, generate the Python code to accomplish this task, and save as code_gen.py\"\"\",\n",
    ")\n",
    "message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340f9f2c-ed45-4f03-9b69-676981ed5031",
   "metadata": {},
   "source": [
    "### Step 5: Create a Run for the Assistant\n",
    "A Run is an invocation of an Assistant on a Thread. The Assistant uses its configuration and the Threadâ€™s Messages to perform tasks by calling models and tools. As part of a Run, the Assistant appends Messages to the Thread.\n",
    "\n",
    "Note that Assistance will run asychronously: the run has the following\n",
    "lifecycle and states: [*expired, completed, failed, cancelled*]. Run objects can have multiple statuses.\n",
    "\n",
    "<img src=\"https://cdn.openai.com/API/docs/images/diagram-1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5af62473-7808-4358-9d76-8fe3c69b7606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"run_VySRlRoQPHgqvUkvvKzh29lo\",\n",
      "  \"assistant_id\": \"asst_jQDnJlKpUxc0NpJru3BnhCfP\",\n",
      "  \"cancelled_at\": null,\n",
      "  \"completed_at\": null,\n",
      "  \"created_at\": 1703886367,\n",
      "  \"expires_at\": 1703886967,\n",
      "  \"failed_at\": null,\n",
      "  \"file_ids\": [\n",
      "    \"file-NvpyZyVwrFT2IGKPUvoIKz0x\"\n",
      "  ],\n",
      "  \"instructions\": \"Please address the user as Jules Dmatrix.\",\n",
      "  \"last_error\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4-1106-preview\",\n",
      "  \"object\": \"thread.run\",\n",
      "  \"required_action\": null,\n",
      "  \"started_at\": null,\n",
      "  \"status\": \"queued\",\n",
      "  \"thread_id\": \"thread_sXIZbavYkmRqpHvTGwKfjpyk\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"code_interpreter\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "instruction_msg = \"\"\"Please address the user as Jules Dmatrix.\"\"\"\n",
    "run = create_assistant_run(client, assistant, thread, instruction_msg)\n",
    "print(run.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bc9f98-2bb8-419f-b3a8-cf43011e5854",
   "metadata": {},
   "source": [
    "### Step 6: Retrieve the status and loop until the Assistant run status is `completed.`\n",
    "\n",
    "Loop until run status is **required_action**, which is a trigger notification to extract arguments generated by the LLM model and carry onto the next step: invoke the function with the generated arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "717eddf1-4477-4498-b812-b9fb742f14ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "completed\n",
      "\n",
      "Final output from the Assistant run:\n",
      "ThreadMessage(id='msg_oE1a5ywQvASIMr5PyeZrrBwI', assistant_id='asst_jQDnJlKpUxc0NpJru3BnhCfP', content=[MessageContentText(text=Text(annotations=[TextAnnotationFilePath(end_index=198, file_path=TextAnnotationFilePathFilePath(file_id='file-VuzJreEVfhLC8BxWSgJI0mpg'), start_index=169, text='sandbox:/mnt/data/code_gen.py', type='file_path')], value='The Python code has been generated to accomplish the visualization task and saved as \"code_gen.py\". You can download the code using the following link:\\n\\n- [code_gen.py](sandbox:/mnt/data/code_gen.py)\\n\\nIn this code, replace `\\'path_to_your_file.csv\\'` with the actual path to your data file when running it in your environment. If you have any further questions or need assistance with anything else, let me know!'), type='text')], created_at=1703886510, file_ids=['file-VuzJreEVfhLC8BxWSgJI0mpg'], metadata={}, object='thread.message', role='assistant', run_id='run_VySRlRoQPHgqvUkvvKzh29lo', thread_id='thread_sXIZbavYkmRqpHvTGwKfjpyk')\n",
      "ThreadMessage(id='msg_EyLNPU0QWpv69KCpoelJVNI3', assistant_id='asst_jQDnJlKpUxc0NpJru3BnhCfP', content=[MessageContentText(text=Text(annotations=[TextAnnotationFilePath(end_index=210, file_path=TextAnnotationFilePathFilePath(file_id='file-lYQPEvyT6UCEOXcbujriy5XE'), start_index=171, text='sandbox:/mnt/data/ray_growth_meetup.png', type='file_path'), TextAnnotationFilePath(end_index=312, file_path=TextAnnotationFilePathFilePath(file_id='file-zksJOgtMviVZPPc5GQKaQQWE'), start_index=277, text='sandbox:/mnt/data/rsvp_attended.png', type='file_path')], value='The visualizations have been created and saved as requested. Here are the links to download the images:\\n\\n- **Ray Meetup Membership Growth Chart**: [ray_growth_meetup.png](sandbox:/mnt/data/ray_growth_meetup.png)\\n- **RSVPs and Attended Stacked Bar Charts**: [rsvp_attended.png](sandbox:/mnt/data/rsvp_attended.png)\\n\\nNext, I will generate the Python code to accomplish this visualization task and save it as \"code_gen.py\".'), type='text')], created_at=1703886455, file_ids=['file-zksJOgtMviVZPPc5GQKaQQWE', 'file-lYQPEvyT6UCEOXcbujriy5XE'], metadata={}, object='thread.message', role='assistant', run_id='run_VySRlRoQPHgqvUkvvKzh29lo', thread_id='thread_sXIZbavYkmRqpHvTGwKfjpyk')\n",
      "ThreadMessage(id='msg_6QZ98U0qbHepG1xr1hxosGKH', assistant_id='asst_jQDnJlKpUxc0NpJru3BnhCfP', content=[MessageContentText(text=Text(annotations=[], value='The data contains the following columns: \\'Meetup Date\\', \\'RSVP\\', \\'Members\\', and \\'Attended\\'. To create the linear chart showing Ray meetup membership growth over the years, we need to use the \\'Meetup Date\\' as the x-axis and \\'Members\\' as the y-axis.\\n\\nFor the bar charts of RSVPs and Attended, we can use \\'Meetup Date\\' for the x-axis and both \\'RSVP\\' and \\'Attended\\' for the y-axis. Since some \\'Attended\\' data points are missing (NaN), it would be appropriate to fill in these missing values with zeros for the purpose of the bar chart, assuming no attendance was recorded on those dates.\\n\\nLet\\'s proceed with creating these visualizations, starting with the linear chart for Ray meetup membership growth and then creating the stacked bar charts for RSVPs and Attended. We\\'ll save the images as \"ray_growth_meetup.png\" and \"rsvp_attended.png\", and finally, we\\'ll generate the Python code and save it as \"code_gen.py\".'), type='text')], created_at=1703886385, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_VySRlRoQPHgqvUkvvKzh29lo', thread_id='thread_sXIZbavYkmRqpHvTGwKfjpyk')\n",
      "ThreadMessage(id='msg_SWWiaarccdkm1QTsYGVQVpoY', assistant_id='asst_jQDnJlKpUxc0NpJru3BnhCfP', content=[MessageContentText(text=Text(annotations=[], value=\"First, I'll inspect the uploaded file to understand its structure and ascertain if it contains the necessary data to create the linear chart for Ray meetup membership growth and the bar charts for RSVPs and Attended. After reviewing the file contents, I will proceed with creating the visualizations and saving them as requested.\\n\\nLet's start by examining the contents of the file you uploaded.\"), type='text')], created_at=1703886369, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_VySRlRoQPHgqvUkvvKzh29lo', thread_id='thread_sXIZbavYkmRqpHvTGwKfjpyk')\n",
      "ThreadMessage(id='msg_oCJxZ7kGjSCg3JoH3M53A5gl', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Show me the Ray meetup membership growth over the years as linear chart. Save \\n    it as ray_growth_meeetup.png\". Create two wide bar charts for the RSVPs and Attended respectively. \\n    Use the x-axis as meetup dates and y-axis as meetup members. Plot bar charts in a stack manner into a single file. \\n    Save it as rsvp_attended.png. Finally, generate the Python code to accomplish this task, and save as code_gen.py'), type='text')], created_at=1703886367, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_sXIZbavYkmRqpHvTGwKfjpyk')\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    time.sleep(5)\n",
    "    # Retrieve the run status\n",
    "    run_status = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "    print(run_status.status)\n",
    "    \n",
    "    # If run is completed, get all the messages\n",
    "    # on the thread, inserted by the Assistant's run\n",
    "    if run_status.status == 'completed':\n",
    "        messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id)\n",
    "\n",
    "        # Loop through messages and print content based on role\n",
    "        # and break out of the while loop\n",
    "        print(\"\\nFinal output from the Assistant run:\")\n",
    "        print_thread_messages(client, thread, content_value=False)        \n",
    "        break\n",
    "    else:\n",
    "        print(f\"Assistant run state: '{run_status.status}' ...\")\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eead0f-4db3-4d05-8507-77aade1ba21d",
   "metadata": {},
   "source": [
    "### Step 7: Extract generated files from the Code Interpreter\n",
    "\n",
    "Partial code for iterating over messages and extracting files borrowed from [here](https://www.youtube.com/watch?v=vW4RSEB4Zzo&t=22s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e2bbfed-f674-4d10-adb4-4a291d0f6d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Role: assistant\n",
      "The Python code has been generated to accomplish the visualization task and saved as \"code_gen.py\". You can download the code using the following link:\n",
      "\n",
      "- [code_gen.py](sandbox:/mnt/data/code_gen.py)\n",
      "\n",
      "In this code, replace `'path_to_your_file.csv'` with the actual path to your data file when running it in your environment. If you have any further questions or need assistance with anything else, let me know!\n",
      "Annotation Text: sandbox:/mnt/data/code_gen.py\n",
      "File_Id: file-VuzJreEVfhLC8BxWSgJI0mpg\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Role: assistant\n",
      "The visualizations have been created and saved as requested. Here are the links to download the images:\n",
      "\n",
      "- **Ray Meetup Membership Growth Chart**: [ray_growth_meetup.png](sandbox:/mnt/data/ray_growth_meetup.png)\n",
      "- **RSVPs and Attended Stacked Bar Charts**: [rsvp_attended.png](sandbox:/mnt/data/rsvp_attended.png)\n",
      "\n",
      "Next, I will generate the Python code to accomplish this visualization task and save it as \"code_gen.py\".\n",
      "Annotation Text: sandbox:/mnt/data/ray_growth_meetup.png\n",
      "File_Id: file-lYQPEvyT6UCEOXcbujriy5XE\n",
      "Annotation Text: sandbox:/mnt/data/rsvp_attended.png\n",
      "File_Id: file-zksJOgtMviVZPPc5GQKaQQWE\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Role: assistant\n",
      "The data contains the following columns: 'Meetup Date', 'RSVP', 'Members', and 'Attended'. To create the linear chart showing Ray meetup membership growth over the years, we need to use the 'Meetup Date' as the x-axis and 'Members' as the y-axis.\n",
      "\n",
      "For the bar charts of RSVPs and Attended, we can use 'Meetup Date' for the x-axis and both 'RSVP' and 'Attended' for the y-axis. Since some 'Attended' data points are missing (NaN), it would be appropriate to fill in these missing values with zeros for the purpose of the bar chart, assuming no attendance was recorded on those dates.\n",
      "\n",
      "Let's proceed with creating these visualizations, starting with the linear chart for Ray meetup membership growth and then creating the stacked bar charts for RSVPs and Attended. We'll save the images as \"ray_growth_meetup.png\" and \"rsvp_attended.png\", and finally, we'll generate the Python code and save it as \"code_gen.py\".\n",
      "No annotations found\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Role: assistant\n",
      "First, I'll inspect the uploaded file to understand its structure and ascertain if it contains the necessary data to create the linear chart for Ray meetup membership growth and the bar charts for RSVPs and Attended. After reviewing the file contents, I will proceed with creating the visualizations and saving them as requested.\n",
      "\n",
      "Let's start by examining the contents of the file you uploaded.\n",
      "No annotations found\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Role: user\n",
      "Show me the Ray meetup membership growth over the years as linear chart. Save \n",
      "    it as ray_growth_meeetup.png\". Create two wide bar charts for the RSVPs and Attended respectively. \n",
      "    Use the x-axis as meetup dates and y-axis as meetup members. Plot bar charts in a stack manner into a single file. \n",
      "    Save it as rsvp_attended.png. Finally, generate the Python code to accomplish this task, and save as code_gen.py\n",
      "No annotations found\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id)\n",
    "\n",
    "for message in messages:\n",
    "    print(\"-\" * 50)\n",
    "    # Print the role of the sender\n",
    "    print(f\"Role: {message.role}\")\n",
    "\n",
    "    # Process each content item in the message\n",
    "    for content in message.content:\n",
    "        # Check if the content is text\n",
    "        if content.type == 'text':\n",
    "            print(content.text.value)\n",
    "\n",
    "            # Check and print details about annotations if they exist\n",
    "            if content.text.annotations:\n",
    "                for annotation in content.text.annotations:\n",
    "                    print(f\"Annotation Text: {annotation.text}\")\n",
    "                    print(f\"File_Id: {annotation.file_path.file_id}\")\n",
    "                    annotation_data = client.files.content(annotation.file_path.file_id)\n",
    "                    annotation_data_bytes = annotation_data.read()\n",
    "\n",
    "                    # file_extension = annotation.text.split('.')[-1]\n",
    "                    filename = annotation.text.split('/')[-1]\n",
    "\n",
    "                    with open(f\"{filename}\", \"wb\") as file:\n",
    "                        file.write(annotation_data_bytes)\n",
    "            else:\n",
    "                print(\"No annotations found\")\n",
    "\n",
    "        # Check if the content is an image file and print its file ID and name\n",
    "        elif content.type == 'image_file':\n",
    "            print(f\"Image File ID: {content.image_file.file_id}\")\n",
    "            image_data = client.files.content(content.image_file.file_id)\n",
    "            image_data_bytes = image_data.read()\n",
    "\n",
    "            with open(f\"{content.image_file.file_id}.png\", \"wb\") as file:\n",
    "                file.write(image_data_bytes)\n",
    "\n",
    "    # Print a horizontal line for separation between messages\n",
    "    print(\"-\" * 50)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6777131-d028-40bc-8b7c-6ea691e5d085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssistantDeleted(id='asst_jQDnJlKpUxc0NpJru3BnhCfP', deleted=True, object='assistant.deleted')\n",
      "deleting file id: file-NvpyZyVwrFT2IGKPUvoIKz0x...\n",
      "FileDeleted(id='file-NvpyZyVwrFT2IGKPUvoIKz0x', deleted=True, object='file')\n"
     ]
    }
   ],
   "source": [
    "# Delete the assistant. Optionally, you can delete any files\n",
    "# associated with it that you have uploaded onto the OpenAI platform\n",
    "\n",
    "response = client.beta.assistants.delete(assistant.id)\n",
    "print(response)\n",
    "\n",
    "for file_id in file_obj_ids:\n",
    "    print(f\"deleting file id: {file_id}...\")\n",
    "    response = client.files.delete(file_id)\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
