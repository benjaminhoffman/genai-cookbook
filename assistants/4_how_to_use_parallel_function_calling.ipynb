{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c14522-634f-4ab8-bc33-2bd31c30b7f0",
   "metadata": {},
   "source": [
    "# OpenAI Assistants APIs\n",
    "\n",
    "The Assistants' API lets you create AI assistants in your applications. These assistants follow instructions and use models, tools, and knowledge to answer user questions. In this notebook we are going to use one of the tools, retriever,\n",
    "to query against two pdf documents we will upload.\n",
    "\n",
    "The architeture and data flow diagram below depicts the interaction among all components that comprise OpenAI Assistant APIs. Central to understand is the Threads and Runtime that executes anyschronously, adding and reading messages to the Threads.\n",
    "\n",
    "For integrating the Assistants API:\n",
    "\n",
    "1. Creat an Assistant with custom instructions and select a model. Optionally, enable tools like Code Interpreter, Retrieval, and Function Calling.\n",
    "\n",
    "2. Initiate a Thread for each user conversation.\n",
    "    \n",
    "3. Add user queries as Messages to the Thread.\n",
    "\n",
    "4.  Run the Assistant on the Thread for responses, which automatically utilizes the enabled tools\n",
    "\n",
    "Below we follow those steps to demonstrate how to integrate Assistants API, using function tool, to ask our Assistant to interact with an external web services, such\n",
    "as Google Search, Weather Stacks, and OpenAI too.\n",
    "\n",
    "This external service could be any external [API Webserivce](https://apilayer.com/)\n",
    "\n",
    "The OpenAI documentation describes in details [how Assistants work](https://platform.openai.com/docs/assistants/how-it-works).\n",
    "\n",
    "<img src=\"images/assistant_ai_tools_parallel_functions.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5236eddb-6f57-4fdf-9ebb-a51be1a96bb0",
   "metadata": {},
   "source": [
    "## How to use Assistant API using Tools: Parallel Function calling\n",
    "In this example, we will use couple of external services. That is,\n",
    "our function will call an external web services: Google Search API\n",
    "to fetch the results of the query requested and query a weather.\n",
    "\n",
    "This is an example of how an Assistant can employ an external tool, such as a webservices, but in a parallel fashion.  Our query could be part of a larger application using LLM and Assitant to respond to user queries to more than one web service, and then using the aggregated results to fetched to use downstream.\n",
    "\n",
    "Let's see how we can do it. The steps are not dissimilar to our\n",
    "previous notebook. The only difference here is that our function is makes an external webservice call to mulitple web services and we have a different function JSON definition to match the the arguments to our function call, which it can use to pass to an external respective webservice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc4b433-215a-4eb1-aa48-f7fec735be5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import List, Dict, Any\n",
    "from assistant_utils import print_thread_messages, \\\n",
    "                            loop_until_completed, \\\n",
    "                            create_assistant_run \n",
    "from function_utils import get_weather_data, create_dalle_image\n",
    "from google_search_utils import google_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe04850-43f1-48a4-af2f-0bcf8d357d10",
   "metadata": {},
   "source": [
    "Load our .env file with respective API keys and base url endpoints. Here you can either use OpenAI or Anyscale Endpoints. **Note**: Assistant API calling for Anyscale Endpoints (which serves only OS modles) is not yet aviable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a617d35e-a426-46b1-8294-5939cbabaf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\", \"\")\n",
    "weather_api_key = os.getenv(\"WEATHER_API_KEY\", \"\")\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f4745f-7571-4e27-bdf4-f27ee3c9935b",
   "metadata": {},
   "source": [
    "Create our OpenAI client, and use this in all subsequent Assistant API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b5e28ff-6ffc-4fca-897c-969096d5b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f442063-0eec-4a9d-9938-fbcef036cf4c",
   "metadata": {},
   "source": [
    "### Step 1: Create all our custom function definitions\n",
    "This our JSON object definiton for all our functions:\n",
    "* name of the function\n",
    "* parameters for the funtion\n",
    "* type of arguments\n",
    "* descriptions for function and each parameter type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ceaa978-270d-45fe-866f-58a5dcb2a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all the descriptions of functions the Assistant can \n",
    "# use to satisfy our request.\n",
    "tools_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba85d34-d303-4e0e-9ad7-ffa16545724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_google_query = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"google_search\",\n",
    "        \"description\": \"A function takes in a search query, api key, and optionly num of results specified. \",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\" : {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\" : \"The search query to send to the Google Search Engine\"\n",
    "                },\n",
    "                \"api_key\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\" : \"Google Search API key\"\n",
    "    \n",
    "                },\n",
    "                \"num_results\" : {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\" : \"number of results. This is a optional one, default is 1\"\n",
    "    \n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"query\", \"api_key\"]\n",
    "}\n",
    "tools_list.append(search_google_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f005fd60-7521-4ed3-88de-3c38884361e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_info_query = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather_data\",\n",
    "        \"description\": \"A function takes in a city, api key, and optionly a api base URL. \",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\" : {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\" : \"The name of the city  in the US\"\n",
    "                },\n",
    "                \"access_key\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\" : \"Weatherstack API key\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"query\", \"access_key\"]\n",
    "}\n",
    "tools_list.append(weather_info_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "203479a1-922e-46bc-a8c7-a8293dc00d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dalle_3_image_query = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"create_dalle_image\",\n",
    "        \"description\": \"A function takes in a description to create a Dalle-3 image. \",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\" : {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\" : \"Vivid description of the desired image\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"query\"]\n",
    "}\n",
    "tools_list.append(dalle_3_image_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22a82034-0a3b-4555-92ed-958860a43514",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_function_dispatch_table = {\n",
    "    \"google_search\": google_search,\n",
    "    \"get_weather_data\": get_weather_data,\n",
    "    \"create_dalle_image\": create_dalle_image\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a1756f-7c2f-4da6-8d53-37a1181dea16",
   "metadata": {},
   "source": [
    "### Step 2: Create an Assistant \n",
    "Before you can start interacting with the Assistant to carry out any tasks, you need an AI assistant object. Supply the Assistant with a model to use, tools, i.e., all the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97015f97-9044-4aab-845f-bf35b6251781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assistant(id='asst_c13nHOhNC5eY2rEsPGn0UFJD', created_at=1703738021, description=None, file_ids=[], instructions='You are a knowledgeable and helpful chatbot trained to\\ninteract with multiple external webservices such as Google, Weatherstack, and even\\ncall into OpenAI vision model, via help of function calls.\\n', metadata={}, model='gpt-4-1106-preview', name='AI Assistant for Multiple Web services', object='assistant', tools=[ToolFunction(function=FunctionDefinition(name='google_search', description='A function takes in a search query, api key, and optionly num of results specified. ', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query to send to the Google Search Engine'}, 'api_key': {'type': 'string', 'description': 'Google Search API key'}, 'num_results': {'type': 'integer', 'description': 'number of results. This is a optional one, default is 1'}}}), type='function'), ToolFunction(function=FunctionDefinition(name='get_weather_data', description='A function takes in a city, api key, and optionly a api base URL. ', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The name of the city  in the US'}, 'access_key': {'type': 'string', 'description': 'Weatherstack API key'}}}), type='function'), ToolFunction(function=FunctionDefinition(name='create_dalle_image', description='A function takes in a description to create a Dalle-3 image. ', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Vivid description of the desired image'}}}), type='function')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = \"\"\"You are a knowledgeable and helpful chatbot trained to\n",
    "interact with multiple external webservices such as Google, Weatherstack, and even\n",
    "call into OpenAI vision model, via help of function calls.\n",
    "\"\"\"\n",
    "assistant = client.beta.assistants.create(name=\"AI Assistant for Multiple Web services\",\n",
    "                                           instructions=instructions,\n",
    "                                           model=MODEL,\n",
    "                                           tools=tools_list)\n",
    "assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62acfb2f-dc5e-474c-9be7-9cc1db7d531b",
   "metadata": {},
   "source": [
    "### Step 3: Create an empty thread \n",
    "As the diagram above shows, the Thread is the object with which the AI Assistant runs will interact with, by fetching messages and putting messages to it. Think of a thread as a \"conversation session between an Assistant and a user. Threads store Messages and automatically handle truncation to fit content into a model’s context window.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bdd2356-e3f7-469c-bd4f-7cc2964b51ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thread(id='thread_4ySSTFG1jUTXtobplWo10g1C', created_at=1703738021, metadata={}, object='thread')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ab11d-1188-4a8a-86ac-eda7057869af",
   "metadata": {},
   "source": [
    "### Step 4: Add your message query to the thread for the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a87e2b2-2811-4430-a2b7-013ba300cf44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreadMessage(id='msg_WY6Mjxm7MYOvhtjmUB0lJXOp', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Search the Google for top 5 coffe houses or cafes in\\nSan Francisco, get weather information for the city, and generate an image\\nof a young attractive couple of mixed african and east-indian \\nracial heritage, both of them wearing a matching light fabric summer scarve, sitting \\nat an outside cafe table having a cup of coffee together with the San Francisco Golden \\nGate Bridge in the background while the sun is setting in the west. The sunset lights \\nup the sky with a beautiful orange glow, partly reflecting on the body of water under the bridge.\\nTo the right of the couple on the wall is a hanging sign with the name of the Caffe Golden Gate\\n.'), type='text')], created_at=1703738021, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_4ySSTFG1jUTXtobplWo10g1C')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = \"\"\"Search the Google for top 5 coffe houses or cafes in\n",
    "San Francisco, get weather information for the city, and generate an image\n",
    "of a young attractive couple of mixed african and east-indian \n",
    "racial heritage, both of them wearing a matching light fabric summer scarve, sitting \n",
    "at an outside cafe table having a cup of coffee together with the San Francisco Golden \n",
    "Gate Bridge in the background while the sun is setting in the west. The sunset lights \n",
    "up the sky with a beautiful orange glow, partly reflecting on the body of water under the bridge.\n",
    "To the right of the couple on the wall is a hanging sign with the name of the Caffe Golden Gate\n",
    ".\"\"\"\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id, \n",
    "    role=\"user\",\n",
    "    content=content\n",
    ")\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c032a81d-3e1d-4e2d-b283-123f5b92a147",
   "metadata": {},
   "source": [
    "### Step 5: Create a Run for the Assistant\n",
    "A Run is an invocation of an Assistant on a Thread. The Assistant uses it’s configuration and the Thread’s Messages to perform tasks by calling models and tools. As part of a Run, the Assistant appends Messages to the Thread.\n",
    "\n",
    "Note that Assistance will run asychronously: the run has the following\n",
    "lifecycle and states: [*expired, completed, requires, failed, cancelled*]. Run objects can have multiple statuses.\n",
    "\n",
    "<img src=\"https://cdn.openai.com/API/docs/images/diagram-1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccd48e0b-a073-47fe-8c5d-c4af74f5244d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"run_AS1TRzC8A4AW2dL9pR8fROau\",\n",
      "  \"assistant_id\": \"asst_c13nHOhNC5eY2rEsPGn0UFJD\",\n",
      "  \"cancelled_at\": null,\n",
      "  \"completed_at\": null,\n",
      "  \"created_at\": 1703738022,\n",
      "  \"expires_at\": 1703738622,\n",
      "  \"failed_at\": null,\n",
      "  \"file_ids\": [],\n",
      "  \"instructions\": \"Please address the user as Jules Dmatrix.\",\n",
      "  \"last_error\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4-1106-preview\",\n",
      "  \"object\": \"thread.run\",\n",
      "  \"required_action\": null,\n",
      "  \"started_at\": null,\n",
      "  \"status\": \"queued\",\n",
      "  \"thread_id\": \"thread_4ySSTFG1jUTXtobplWo10g1C\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"function\": {\n",
      "        \"name\": \"google_search\",\n",
      "        \"description\": \"A function takes in a search query, api key, and optionly num of results specified. \",\n",
      "        \"parameters\": {\n",
      "          \"type\": \"object\",\n",
      "          \"properties\": {\n",
      "            \"query\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"The search query to send to the Google Search Engine\"\n",
      "            },\n",
      "            \"api_key\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"Google Search API key\"\n",
      "            },\n",
      "            \"num_results\": {\n",
      "              \"type\": \"integer\",\n",
      "              \"description\": \"number of results. This is a optional one, default is 1\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"type\": \"function\"\n",
      "    },\n",
      "    {\n",
      "      \"function\": {\n",
      "        \"name\": \"get_weather_data\",\n",
      "        \"description\": \"A function takes in a city, api key, and optionly a api base URL. \",\n",
      "        \"parameters\": {\n",
      "          \"type\": \"object\",\n",
      "          \"properties\": {\n",
      "            \"query\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"The name of the city  in the US\"\n",
      "            },\n",
      "            \"access_key\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"Weatherstack API key\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"type\": \"function\"\n",
      "    },\n",
      "    {\n",
      "      \"function\": {\n",
      "        \"name\": \"create_dalle_image\",\n",
      "        \"description\": \"A function takes in a description to create a Dalle-3 image. \",\n",
      "        \"parameters\": {\n",
      "          \"type\": \"object\",\n",
      "          \"properties\": {\n",
      "            \"query\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"Vivid description of the desired image\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"type\": \"function\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "instruction_msg = \"\"\"Please address the user as Jules Dmatrix.\"\"\"\n",
    "run = create_assistant_run(client, assistant, thread, instruction_msg)\n",
    "print(run.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9c9fbc-f0f0-4e1c-a758-7894875c8a75",
   "metadata": {},
   "source": [
    "### Step 6: Retrieve the status and loop until the Assistant run status is `completed`\n",
    "Loop until run status is **required_action**, which is a trigger notification to extract arguments generated by the LLM model and carry onto the next step: invoke the function with the generated arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74d7a6aa-84c0-4112-99e9-bdc9e9410b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "in_progress\n",
      "Assistant run state: 'in_progress' ...\n",
      "requires_action\n",
      "Assistant taking required action: Function calling...\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': '1 validation error for Request\\nbody -> tool_outputs -> 0 -> output\\n  str type expected (type=type_error.str)', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m             tool_outputs\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_call_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: action[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: func_results})\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# Sending outputs from the function call back to the Assistant\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_tool_outputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssistant run state: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_status\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/genai-cookbook-env/lib/python3.10/site-packages/openai/resources/beta/threads/runs/runs.py:309\u001b[0m, in \u001b[0;36mRuns.submit_tool_outputs\u001b[0;34m(self, run_id, thread_id, tool_outputs, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03mWhen a run has the `status: \"requires_action\"` and `required_action.type` is\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m`submit_tool_outputs`, this endpoint can be used to submit the outputs from the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    308\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI-Beta\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistants=v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/threads/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mthread_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/runs/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/submit_tool_outputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_outputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_outputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_submit_tool_outputs_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRunSubmitToolOutputsParams\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/genai-cookbook-env/lib/python3.10/site-packages/openai/_base_client.py:1088\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1075\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1076\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1083\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1084\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1085\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1086\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1087\u001b[0m     )\n\u001b[0;32m-> 1088\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/genai-cookbook-env/lib/python3.10/site-packages/openai/_base_client.py:853\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    846\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    851\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    852\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/genai-cookbook-env/lib/python3.10/site-packages/openai/_base_client.py:930\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m    928\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 930\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    933\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    934\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    937\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    938\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': '1 validation error for Request\\nbody -> tool_outputs -> 0 -> output\\n  str type expected (type=type_error.str)', 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    time.sleep(3)\n",
    "    # Retrieve the run status\n",
    "    run_status = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "    print(run_status.status)\n",
    "    \n",
    "    # If run is completed, get all the messages\n",
    "    # on the thread, inserted by the Assistant's run\n",
    "    if run_status.status == 'completed':\n",
    "        messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id)\n",
    "\n",
    "        # Loop through messages and print content based on role\n",
    "        # and break out of the while loop\n",
    "        print(\"\\nFinal output from the Assistant run:\")\n",
    "        print_thread_messages(client, thread)        \n",
    "        break\n",
    "    elif run_status.status == 'requires_action':\n",
    "        print(\"Assistant taking required action: Function calling...\")\n",
    "        required_actions = run_status.required_action.submit_tool_outputs.model_dump()\n",
    "        \n",
    "        # Aggregate output from any function\n",
    "        tool_outputs = []\n",
    "        \n",
    "        import json\n",
    "        for action in required_actions[\"tool_calls\"]:\n",
    "            func_name = action['function']['name']\n",
    "            func_args = json.loads(action['function']['arguments'])\n",
    "            if func_name == \"get_weather_data\":\n",
    "                func_args[\"access_key\"] = weather_api_key\n",
    "            elif func_name == \"google_search\":\n",
    "                func_args[\"api_key\"] = google_api_key\n",
    "\n",
    "            # Use the dispatch function table to invoke\n",
    "            # our function\n",
    "            func = tools_function_dispatch_table[func_name]\n",
    "            func_results = func(func_args)\n",
    "            if func_name == \"get_weather_data\":\n",
    "                output = f\"The temperature in {func_results['location']['name']} is {func_results['current']['temperature']}, with {func_results['current']['weather_descriptions'][0]}\"\n",
    "                tool_outputs.append({\"tool_call_id\": action['id'], \"output\": output})\n",
    "            else:\n",
    "                tool_outputs.append({\"tool_call_id\": action['id'], \"output\": func_results})\n",
    "        \n",
    "        # Sending outputs from the function call back to the Assistant\n",
    "        client.beta.threads.runs.submit_tool_outputs(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "            tool_outputs=tool_outputs)\n",
    "    else:\n",
    "        print(f\"Assistant run state: '{run_status.status}' ...\")\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587b4dea-b60d-4c9b-99aa-9e5d29c755ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the assistant. \n",
    "response = client.beta.assistants.delete(assistant.id)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
