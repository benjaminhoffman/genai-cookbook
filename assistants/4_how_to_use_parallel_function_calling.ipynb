{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c14522-634f-4ab8-bc33-2bd31c30b7f0",
   "metadata": {},
   "source": [
    "# OpenAI Assistants APIs\n",
    "\n",
    "The Assistants' API lets you create AI assistants in your applications. These assistants follow instructions and use models, tools, and knowledge to answer user questions. In this notebook we are going to use one of the tools, retriever,\n",
    "to query against two pdf documents we will upload.\n",
    "\n",
    "The architecture and data flow diagram below depicts the interaction among all components that comprise OpenAI Assistant APIs. Central to understand is the Threads and Runtime that executes asynchronously, adding and reading messages to the Threads.\n",
    "\n",
    "For integrating the Assistants API:\n",
    "\n",
    "1. Creat an Assistant with custom instructions and select a model. Optionally, enable tools like Code Interpreter, Retrieval, and Function Calling.\n",
    "\n",
    "2. Initiate a Thread for each user conversation.\n",
    "    \n",
    "3. Add user queries as Messages to the Thread.\n",
    "\n",
    "4.  Run the Assistant on the Thread for responses, which automatically utilizes the enabled tools\n",
    "\n",
    "Below we follow those steps to demonstrate how to integrate Assistants API, using function tool, to ask our Assistant to interact with an external web services, such\n",
    "as Google Search, Weather Stacks, and OpenAI too.\n",
    "\n",
    "This external service could be any external [API Webserivce](https://apilayer.com/)\n",
    "\n",
    "The OpenAI documentation describes in details [how Assistants work](https://platform.openai.com/docs/assistants/how-it-works).\n",
    "\n",
    "<img src=\"images/assistant_ai_tools_parallel_functions.png\">\n",
    "\n",
    "**Note**: Much of the code and diagrams are inspired from  Randy Michak of [Empowerment AI](https://www.youtube.com/watch?v=yzNG3NnF0YE) and OpenAI guide examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5236eddb-6f57-4fdf-9ebb-a51be1a96bb0",
   "metadata": {},
   "source": [
    "## How to use Assistant API using Tools: Parallel Function calling\n",
    "In this example, we will use couple of external services. That is,\n",
    "our function will call an external web services: Google Search API\n",
    "to fetch the results of the query requested and query a weather web service.\n",
    "\n",
    "This is an example of how an Assistant can employ an external tool, such as a web services, but in a parallel fashion. Our query could be part of a larger application using LLM and Assitant to respond to user queries to more than one web service, and then using the aggregated results fetched to use downstream.\n",
    "\n",
    "Let's see how we can do it. The steps are not dissimilar to our\n",
    "previous notebooks. The only difference here is that our function makes an external web service call to mulitple web services and we have a different function JSON definition to match the the arguments to our function call, which it can use to pass to an external respective web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc4b433-215a-4eb1-aa48-f7fec735be5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import List, Dict, Any\n",
    "from assistant_utils import print_thread_messages, \\\n",
    "                            loop_until_completed, \\\n",
    "                            create_assistant_run \n",
    "from function_utils import get_weather_data, create_dalle_image\n",
    "from google_search_utils import google_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe04850-43f1-48a4-af2f-0bcf8d357d10",
   "metadata": {},
   "source": [
    "Load our .env file with respective API keys and base url endpoints. Here you can either use OpenAI or Anyscale Endpoints. **Note**: Assistant API calling for Anyscale Endpoints (which serves only OS modles) is not yet aviable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a617d35e-a426-46b1-8294-5939cbabaf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\", \"\")\n",
    "weather_api_key = os.getenv(\"WEATHER_API_KEY\", \"\")\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f4745f-7571-4e27-bdf4-f27ee3c9935b",
   "metadata": {},
   "source": [
    "Create our OpenAI client, and use this in all subsequent Assistant API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b5e28ff-6ffc-4fca-897c-969096d5b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f442063-0eec-4a9d-9938-fbcef036cf4c",
   "metadata": {},
   "source": [
    "### Step 1: Create all our custom function definitions\n",
    "This our JSON object definiton for all our functions:\n",
    "* name of the function\n",
    "* parameters for the funtion\n",
    "* type of arguments\n",
    "* descriptions for function and each parameter type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ceaa978-270d-45fe-866f-58a5dcb2a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all the descriptions of functions the Assistant can \n",
    "# use to satisfy our request.\n",
    "tools_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba85d34-d303-4e0e-9ad7-ffa16545724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_google_query = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"google_search\",\n",
    "        \"description\": \"A function takes in a search query, api key, and optionly num of results specified. \",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\" : {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\" : \"The search query to send to the Google Search Engine\"\n",
    "                },\n",
    "                \"api_key\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\" : \"Google Search API key\"\n",
    "    \n",
    "                },\n",
    "                \"num_results\" : {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\" : \"number of results. This is a optional one, default is 1\"\n",
    "    \n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"query\", \"api_key\"]\n",
    "}\n",
    "tools_list.append(search_google_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f005fd60-7521-4ed3-88de-3c38884361e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_info_query = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather_data\",\n",
    "        \"description\": \"A function takes in a city, api key, and optionly a api base URL. \",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\" : {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\" : \"The name of the city  in the US\"\n",
    "                },\n",
    "                \"access_key\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\" : \"Weatherstack API key\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"query\", \"access_key\"]\n",
    "}\n",
    "tools_list.append(weather_info_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "203479a1-922e-46bc-a8c7-a8293dc00d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dalle_3_image_query = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"create_dalle_image\",\n",
    "        \"description\": \"A function takes in a description to create a Dalle-3 image. \",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\" : {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\" : \"Vivid description of the desired image\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"query\"]\n",
    "}\n",
    "tools_list.append(dalle_3_image_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0aed93-3d6f-4052-8adf-266f5c1b821e",
   "metadata": {},
   "source": [
    "Our dispatch function table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22a82034-0a3b-4555-92ed-958860a43514",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_function_dispatch_table = {\n",
    "    \"google_search\": google_search,\n",
    "    \"get_weather_data\": get_weather_data,\n",
    "    \"create_dalle_image\": create_dalle_image\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a1756f-7c2f-4da6-8d53-37a1181dea16",
   "metadata": {},
   "source": [
    "### Step 2: Create an Assistant \n",
    "Before you can start interacting with the Assistant to carry out any tasks, you need an AI assistant object. Supply the Assistant with a model to use, tools, i.e., all the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97015f97-9044-4aab-845f-bf35b6251781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assistant(id='asst_mbLJ1t0MajpjhhtO57zGyiQ2', created_at=1706048071, description=None, file_ids=[], instructions='You are a knowledgeable and helpful chatbot trained to\\ninteract with multiple external webservices such as Google, Weatherstack, and even\\ncall into OpenAI vision model, via help of function calls.\\n', metadata={}, model='gpt-4-1106-preview', name='AI Assistant for Multiple Web services', object='assistant', tools=[ToolFunction(function=FunctionDefinition(name='google_search', description='A function takes in a search query, api key, and optionly num of results specified. ', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query to send to the Google Search Engine'}, 'api_key': {'type': 'string', 'description': 'Google Search API key'}, 'num_results': {'type': 'integer', 'description': 'number of results. This is a optional one, default is 1'}}}), type='function'), ToolFunction(function=FunctionDefinition(name='get_weather_data', description='A function takes in a city, api key, and optionly a api base URL. ', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The name of the city  in the US'}, 'access_key': {'type': 'string', 'description': 'Weatherstack API key'}}}), type='function'), ToolFunction(function=FunctionDefinition(name='create_dalle_image', description='A function takes in a description to create a Dalle-3 image. ', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Vivid description of the desired image'}}}), type='function')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = \"\"\"You are a knowledgeable and helpful chatbot trained to\n",
    "interact with multiple external webservices such as Google, Weatherstack, and even\n",
    "call into OpenAI vision model, via help of function calls.\n",
    "\"\"\"\n",
    "assistant = client.beta.assistants.create(name=\"AI Assistant for Multiple Web services\",\n",
    "                                           instructions=instructions,\n",
    "                                           model=MODEL,\n",
    "                                           tools=tools_list)  # list of functions for the Assistant\n",
    "assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62acfb2f-dc5e-474c-9be7-9cc1db7d531b",
   "metadata": {},
   "source": [
    "### Step 3: Create an empty thread \n",
    "As the diagram above shows, the Thread is the object with which the AI Assistant runs will interact with, by fetching messages and putting messages to it. Think of a thread as a \"conversation session between an Assistant and a user. Threads store Messages and automatically handle truncation to fit content into a model’s context window.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bdd2356-e3f7-469c-bd4f-7cc2964b51ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thread(id='thread_iokRRWQvTG02XDaH0kPCCM0Y', created_at=1706048077, metadata={}, object='thread')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ab11d-1188-4a8a-86ac-eda7057869af",
   "metadata": {},
   "source": [
    "### Step 4: Add your message query to the thread for the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a87e2b2-2811-4430-a2b7-013ba300cf44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreadMessage(id='msg_6YCmgjdgp2URVhgvMG85I3Gs', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Search the Google for top 5 coffe houses or cafes in\\nSan Francisco, get weather information for the city, and generate an image\\nof a young attractive couple of mixed african and east-indian \\nracial heritage, both of them wearing a matching light fabric summer scarve, sitting \\nat an outside cafe table having a cup of coffee together with the San Francisco Golden \\nGate Bridge in the background while the sun is setting in the west. The sunset lights \\nup the sky with a beautiful orange glow, partly reflecting on the body of water under the bridge.\\nTo the right of the couple on the wall is a hanging sign with the name of the Caffe Golden Gate\\n.'), type='text')], created_at=1706048086, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_iokRRWQvTG02XDaH0kPCCM0Y')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = \"\"\"Search Google for top 5 coffe houses or cafes in\n",
    "San Francisco, get weather information for the city, and generate an image\n",
    "of a young attractive couple of mixed african and east-indian \n",
    "racial heritage, both of them wearing a matching light fabric summer scarve, sitting \n",
    "at an outside cafe table having a cup of coffee together, with the San Francisco Golden \n",
    "Gate Bridge in the background while the sun is setting in the west. The sunset lights \n",
    "up the sky with a beautiful orange glow, partly reflecting on the body of water under the bridge.\n",
    "To the right of the couple on the wall is a hanging sign with the name of the Caffe Golden Gate.\n",
    ".\"\"\"\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id, \n",
    "    role=\"user\",\n",
    "    content=content\n",
    ")\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c032a81d-3e1d-4e2d-b283-123f5b92a147",
   "metadata": {},
   "source": [
    "### Step 5: Create a Run for the Assistant\n",
    "A Run is an invocation of an Assistant on a Thread. The Assistant uses its configuration and the Thread’s Messages to perform tasks by calling models and tools. As part of a Run, the Assistant appends Messages to the Thread.\n",
    "\n",
    "Note that Assistance will run asychronously: the run has the following\n",
    "lifecycle and states: [*expired, completed, requires, failed, cancelled*]. Run objects can have multiple statuses.\n",
    "\n",
    "<img src=\"https://cdn.openai.com/API/docs/images/diagram-1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccd48e0b-a073-47fe-8c5d-c4af74f5244d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"run_xMb8lrYlZqN0Gh7maOENOa46\",\n",
      "  \"assistant_id\": \"asst_mbLJ1t0MajpjhhtO57zGyiQ2\",\n",
      "  \"cancelled_at\": null,\n",
      "  \"completed_at\": null,\n",
      "  \"created_at\": 1706048090,\n",
      "  \"expires_at\": 1706048690,\n",
      "  \"failed_at\": null,\n",
      "  \"file_ids\": [],\n",
      "  \"instructions\": \"Please address the user as Jules Dmatrix.\",\n",
      "  \"last_error\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4-1106-preview\",\n",
      "  \"object\": \"thread.run\",\n",
      "  \"required_action\": null,\n",
      "  \"started_at\": null,\n",
      "  \"status\": \"queued\",\n",
      "  \"thread_id\": \"thread_iokRRWQvTG02XDaH0kPCCM0Y\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"function\": {\n",
      "        \"name\": \"google_search\",\n",
      "        \"description\": \"A function takes in a search query, api key, and optionly num of results specified. \",\n",
      "        \"parameters\": {\n",
      "          \"type\": \"object\",\n",
      "          \"properties\": {\n",
      "            \"query\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"The search query to send to the Google Search Engine\"\n",
      "            },\n",
      "            \"api_key\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"Google Search API key\"\n",
      "            },\n",
      "            \"num_results\": {\n",
      "              \"type\": \"integer\",\n",
      "              \"description\": \"number of results. This is a optional one, default is 1\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"type\": \"function\"\n",
      "    },\n",
      "    {\n",
      "      \"function\": {\n",
      "        \"name\": \"get_weather_data\",\n",
      "        \"description\": \"A function takes in a city, api key, and optionly a api base URL. \",\n",
      "        \"parameters\": {\n",
      "          \"type\": \"object\",\n",
      "          \"properties\": {\n",
      "            \"query\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"The name of the city  in the US\"\n",
      "            },\n",
      "            \"access_key\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"Weatherstack API key\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"type\": \"function\"\n",
      "    },\n",
      "    {\n",
      "      \"function\": {\n",
      "        \"name\": \"create_dalle_image\",\n",
      "        \"description\": \"A function takes in a description to create a Dalle-3 image. \",\n",
      "        \"parameters\": {\n",
      "          \"type\": \"object\",\n",
      "          \"properties\": {\n",
      "            \"query\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"Vivid description of the desired image\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"type\": \"function\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "instruction_msg = \"\"\"Please address the user as Jules Dmatrix.\"\"\"\n",
    "run = create_assistant_run(client, assistant, thread, instruction_msg)\n",
    "print(run.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9c9fbc-f0f0-4e1c-a758-7894875c8a75",
   "metadata": {},
   "source": [
    "### Step 6: Retrieve the status and loop until the Assistant run status is `completed`\n",
    "Loop until run status is **required_action**, which is a trigger notification to extract arguments generated by the LLM model and carry onto the next step: invoke the function with the generated arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74d7a6aa-84c0-4112-99e9-bdc9e9410b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "\n",
      "Final output from the Assistant run:\n",
      "('assistant:Jules Dmatrix, here are the results of your queries:\\n'\n",
      " '\\n'\n",
      " '**Top Coffee Houses or Cafes in San Francisco:**\\n'\n",
      " '1. Wrecking Ball Coffee Roasters: [Visit '\n",
      " 'Website](https://sf.eater.com/maps/best-coffee-shops-san-francisco)\\n'\n",
      " '2. York Street Cafe: [Visit '\n",
      " 'Website](https://sf.eater.com/maps/best-coffee-shops-san-francisco)\\n'\n",
      " '3. Andytown Coffee Roasters: [Read '\n",
      " 'More](https://www.sfgate.com/food/article/best-coffee-san-francisco-18163638.php)\\n'\n",
      " '4. Grand Coffee: [Read '\n",
      " 'More](https://www.sfgate.com/food/article/best-coffee-san-francisco-18163638.php)\\n'\n",
      " '5. Saint Frank (along with others mentioned): [Visit Reddit '\n",
      " 'discussion](https://www.reddit.com/r/sanfrancisco/comments/13hg993/great_local_coffee_shops/)\\n'\n",
      " '\\n'\n",
      " '**Weather Information for San Francisco:**\\n'\n",
      " 'The temperature in San Francisco is currently 15°C with partly cloudy '\n",
      " 'conditions.\\n'\n",
      " '\\n'\n",
      " '**Generated Image:**\\n'\n",
      " 'An image has been created according to your description. You can view it by '\n",
      " 'clicking on the link below:\\n'\n",
      " '![Couples at '\n",
      " 'Cafe](https://oaidalleapiprodscus.blob.core.windows.net/private/org-qzeI10umC5EtiLO3PNBCtvem/user-lAhLkDUug18HotjQS5xs6Nan/img-n0xrVuYtLnQagLY9KsACdG7s.png?st=2024-01-23T21%3A15%3A40Z&se=2024-01-23T23%3A15%3A40Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-01-23T22%3A05%3A51Z&ske=2024-01-24T22%3A05%3A51Z&sks=b&skv=2021-08-06&sig=Qdtr7R49ib0I1HFNo7LOIZWx4V6oP/oCcrwul2aBp2s%3D)\\n'\n",
      " '\\n'\n",
      " 'Please click on the relevant links for further information and viewing the '\n",
      " 'image. Enjoy your virtual San Francisco experience!')\n",
      "('user:Search the Google for top 5 coffe houses or cafes in\\n'\n",
      " 'San Francisco, get weather information for the city, and generate an image\\n'\n",
      " 'of a young attractive couple of mixed african and east-indian \\n'\n",
      " 'racial heritage, both of them wearing a matching light fabric summer scarve, '\n",
      " 'sitting \\n'\n",
      " 'at an outside cafe table having a cup of coffee together with the San '\n",
      " 'Francisco Golden \\n'\n",
      " 'Gate Bridge in the background while the sun is setting in the west. The '\n",
      " 'sunset lights \\n'\n",
      " 'up the sky with a beautiful orange glow, partly reflecting on the body of '\n",
      " 'water under the bridge.\\n'\n",
      " 'To the right of the couple on the wall is a hanging sign with the name of '\n",
      " 'the Caffe Golden Gate\\n'\n",
      " '.')\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    time.sleep(3)\n",
    "    # Retrieve the run status\n",
    "    run_status = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "    print(run_status.status)\n",
    "    \n",
    "    # If run is completed, get all the messages\n",
    "    # on the thread, inserted by the Assistant's run\n",
    "    if run_status.status == 'completed':\n",
    "        messages = client.beta.threads.messages.list(\n",
    "            thread_id=thread.id)\n",
    "\n",
    "        # Loop through messages and print content based on role\n",
    "        # and break out of the while loop\n",
    "        print(\"\\nFinal output from the Assistant run:\")\n",
    "        print_thread_messages(client, thread)        \n",
    "        break\n",
    "    elif run_status.status == 'requires_action':\n",
    "        print(\"Assistant taking required action: Function calling...\")\n",
    "        required_actions = run_status.required_action.submit_tool_outputs.model_dump()\n",
    "        \n",
    "        # Aggregate output from any function\n",
    "        tool_outputs = []\n",
    "        \n",
    "        import json\n",
    "        for action in required_actions[\"tool_calls\"]:\n",
    "            func_name = action['function']['name']\n",
    "            func_args = json.loads(action['function']['arguments'])\n",
    "            if func_name == \"get_weather_data\":\n",
    "                func_args[\"access_key\"] = weather_api_key\n",
    "            elif func_name == \"google_search\":\n",
    "                func_args[\"api_key\"] = google_api_key\n",
    "\n",
    "            # Use the dispatch function table to invoke\n",
    "            # our function\n",
    "            func = tools_function_dispatch_table[func_name]\n",
    "            func_results = func(func_args)\n",
    "            if func_name == \"get_weather_data\":\n",
    "                output = f\"The temperature in {func_results['location']['name']} is {func_results['current']['temperature']}, with {func_results['current']['weather_descriptions'][0]}\"\n",
    "                tool_outputs.append({\"tool_call_id\": action['id'], \"output\": output})\n",
    "            elif func_name == \"create_dalle_image\":\n",
    "                output = f\"The generated image of the couple at the cafe is at url: {func_results}\"\n",
    "                tool_outputs.append({\"tool_call_id\": action['id'], \"output\": output})\n",
    "            elif func_name == \"google_search\":\n",
    "                output = f\"Top Coffee houses in San Francisco: {func_results}\"\n",
    "                tool_outputs.append({\"tool_call_id\": action['id'], \"output\": output})\n",
    "            else: \n",
    "                raise ValueError(f\"Unknown function encountered: {func_name}\")\n",
    "\n",
    "        # Sending outputs from the function call back to the Assistant\n",
    "        client.beta.threads.runs.submit_tool_outputs(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "            tool_outputs=tool_outputs)\n",
    "    else:\n",
    "        print(f\"Assistant run state: '{run_status.status}' ...\")\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "587b4dea-b60d-4c9b-99aa-9e5d29c755ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssistantDeleted(id='asst_mbLJ1t0MajpjhhtO57zGyiQ2', deleted=True, object='assistant.deleted')\n"
     ]
    }
   ],
   "source": [
    "# Delete the assistant. \n",
    "response = client.beta.assistants.delete(assistant.id)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
