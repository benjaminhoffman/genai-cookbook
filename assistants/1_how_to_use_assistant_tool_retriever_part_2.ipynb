{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9af9925b-503d-4a27-96a7-eb8a19d03895",
   "metadata": {},
   "source": [
    "# OpenAI Assistants APIs\n",
    "\n",
    "The Assistants' API lets you create AI assistants in your applications. These assistants follow instruction. They use models, tools, and knowledge to answer user questions. In this notebook we are going to use one of the tools, retriever, to query against two pdf documents we will upload.\n",
    "\n",
    "The architecture and data flow diagram below depicts the interaction among all components that comprise OpenAI Assistant APIs. Central to understand is the Threads and Runtime that executes asynchronously, adding and reading messages to the Threads.\n",
    "\n",
    "For integrating the Assistants API:\n",
    "\n",
    "1. Creat an Assistant with custom instructions and select a model. Optionally, enable tools like Code Interpreter, Retrieval, and Function Calling.\n",
    "\n",
    "2. Initiate a Thread for each user conversation.\n",
    "    \n",
    "3. Add user queries as Messages to the Thread.\n",
    "\n",
    "4.  Run the Assistant on the Thread for responses, which automatically utilizes the enabled tools\n",
    "\n",
    "Below we follow those steps to demonstrate how to integrate Assistants API, using Retrieval tool, to a) upload a couple of pdf documents and b) use Assistant to query the contents of the document. Consider this as a mini Retrieval Augmented Generation (RAG). \n",
    "\n",
    "The OpenAI documentation describes in details [how Assistants work](https://platform.openai.com/docs/assistants/how-it-works).\n",
    "\n",
    "<img src=\"./images/assistant_ai_tools_retriever.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be6985d-73b5-451f-8553-35b5c7722aa1",
   "metadata": {},
   "source": [
    "## How to use Assistant API using Tools: Retriever using multiple documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee73f00-842b-4f78-9329-37cac4ce7649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import time\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import List\n",
    "from assistant_utils import print_thread_messages, upload_files, \\\n",
    "                            loop_until_completed, create_assistant_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31b3da3-749a-493f-a096-d421bb8d5a3a",
   "metadata": {},
   "source": [
    "Load our *.env* file with respective API keys and base url endpoints. Here you can either use OpenAI or Anyscale Endpoints. \n",
    "\n",
    "**Note**: Assistant API calling for Anyscale Endpoints (which serves only OS modles) is not yet aviable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f59de24-3cfd-49c7-a12d-6a63adc42c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MODEL=gpt-4-1106-preview; base=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_base = os.getenv(\"ANYSCALE_API_BASE\", os.getenv(\"OPENAI_API_BASE\"))\n",
    "openai.api_key = os.getenv(\"ANYSCALE_API_KEY\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "MODEL = os.getenv(\"MODEL\")\n",
    "print(f\"Using MODEL={MODEL}; base={openai.api_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211325a3-e2d2-47ec-9c4f-8edde762c816",
   "metadata": {},
   "source": [
    "Upload two pdfs. OpenAI allows up twenty files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5290173-5866-495a-9817-2aaeb46dd001",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS_TO_LOAD = [\"docs/llm_survey_halluciantions.pdf\",\n",
    "                \"docs/1001-math-problems-2nd.pdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23640811-8909-471c-a6ce-2bc7be35f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = openai.api_key,\n",
    "    base_url = openai.api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbca03f5-0fca-4d7d-b2b5-89594b145fa0",
   "metadata": {},
   "source": [
    "### Step 1: Create our knowledgebase\n",
    "This entails uploading your pdfs as your knowledgebase for the retrievers to use. Once you upload a file, the Assistant from OpenAI will break it into smaller chuncks, sort and save these chuncks, index and store the embeddings as vectors. \n",
    "\n",
    "The retrievers use your query to retrieve the best semantic matches on vectors in the knowledgebase, and then feed the LLM, along with the original query, to generate the consolidated and comprehesive answer, similarly to how a large-scale RAG retriever operates.\n",
    "\n",
    "Upload the data files from your storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "081abd6a-fcef-4b7c-acc9-4398853f89f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FileObject(id='file-5BgVZhmHgOvNFwLZl3NJhK6s', bytes=1870663, created_at=1704922137, filename='llm_survey_halluciantions.pdf', object='file', purpose='assistants', status='processed', status_details=None),\n",
       " FileObject(id='file-K4ztRDmVvqem23JNYpZDiTdY', bytes=1857163, created_at=1704922138, filename='1001-math-problems-2nd.pdf', object='file', purpose='assistants', status='processed', status_details=None)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_objects = upload_files(client, DOCS_TO_LOAD)\n",
    "file_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27ee0183-2491-4183-a14d-35d6d4a03258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file-5BgVZhmHgOvNFwLZl3NJhK6s', 'file-K4ztRDmVvqem23JNYpZDiTdY']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract file ids \n",
    "file_obj_ids = []\n",
    "for idx, f_obj in enumerate(file_objects):\n",
    "    file_obj_ids.append(file_objects[idx].id)\n",
    "file_obj_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ed87a4-be83-4cbc-b4a1-7e494d7240c1",
   "metadata": {},
   "source": [
    "### Step 2: Create an Assistant \n",
    "Before you can start interacting with the Assistant to carry out any tasks, you need an AI assistant object. Supply the Assistant with a model to use, tools, and file ids to use for its knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c992db14-d667-4146-96cd-a021f285272c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assistant(id='asst_dGpV5uEoPqiK9oZF37JBAzAv', created_at=1704922151, description=None, file_ids=['file-5BgVZhmHgOvNFwLZl3NJhK6s', 'file-K4ztRDmVvqem23JNYpZDiTdY'], instructions=\"You are a knowledgeable chatbot trained to respond \\n                                               inquires on documents accessible to you. \\n                                               Use a professional advisory tone, \\n                                               and only respond by consulting the \\n                                               two files you are granted access to. \\n                                               Do not make up answers. If you don't know answer, respond with 'Sorry, I'm afraid\\n                                               I don't have access to that information.'\", metadata={}, model='gpt-4-1106-preview', name='AI Math and LLM survey Chatbot', object='assistant', tools=[ToolRetrieval(type='retrieval')])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant = client.beta.assistants.create(name=\"AI Math and LLM survey Chatbot\",\n",
    "                                           instructions=\"\"\"You are a knowledgeable chatbot trained to respond \n",
    "                                               inquires on documents accessible to you. \n",
    "                                               Use a professional advisory tone, \n",
    "                                               and only respond by consulting the \n",
    "                                               two files you are granted access to. \n",
    "                                               Do not make up answers. If you don't know answer, respond with 'Sorry, I'm afraid\n",
    "                                               I don't have access to that information.'\"\"\",\n",
    "                                           model=MODEL,\n",
    "                                           tools = [{'type': 'retrieval'}],  # use the retrieval tool\n",
    "                                           file_ids=file_obj_ids # use these files uploaded as part of your knowledge base\n",
    ")                                        \n",
    "assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f61be56-7e39-46db-a95e-e63f9e17115e",
   "metadata": {},
   "source": [
    "### Step 3: Create a thread \n",
    "As the diagram above shows, the Thread is the object with which the AI Assistant runs will interact with, by fetching messages and putting messages to it. Think of a thread as a \"conversation session between an Assistant and a user. Threads store Messages and automatically handle truncation to fit content into a model’s context window.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d7d7a40-4845-4940-9732-be5a163cdc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thread(id='thread_eP6P7EeIhFHFpaGMCS5ysCI9', created_at=1704922156, metadata={}, object='thread')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577bf171-aca4-4d7d-9424-e87e97a88eff",
   "metadata": {},
   "source": [
    "### Step 4: Add your message query to the thread for the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc8a1215-c72e-4aa9-bada-f0ac6228b733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_2C3NfhUqUFTTrkTJvhDTgaX7',\n",
       " 'assistant_id': None,\n",
       " 'content': [{'text': {'annotations': [],\n",
       "    'value': '\\n    # OBJECTIVE#\\n    Use \"llm_survey_halluciantions\" document for this \\n    query. Give me a three paragraph overview of the \\n    document.\\n    \\n    # STYLE #\\n    Use simple and compound-complex sentences for each paragraph. \\n    '},\n",
       "   'type': 'text'}],\n",
       " 'created_at': 1704922157,\n",
       " 'file_ids': [],\n",
       " 'metadata': {},\n",
       " 'object': 'thread.message',\n",
       " 'role': 'user',\n",
       " 'run_id': None,\n",
       " 'thread_id': 'thread_eP6P7EeIhFHFpaGMCS5ysCI9'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id, \n",
    "    role=\"user\",\n",
    "    content=\"\"\"\n",
    "    # OBJECTIVE#\n",
    "    Use \"llm_survey_halluciantions\" document for this \n",
    "    query. Give me a three paragraph overview of the \n",
    "    document.\n",
    "    \n",
    "    # STYLE #\n",
    "    Use simple and compound-complex sentences for each paragraph. \n",
    "    \"\"\",\n",
    ")\n",
    "message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b779a37b-f530-4207-83ba-e990bba3f32d",
   "metadata": {},
   "source": [
    "### Step 5: Create a Run for the Assistant\n",
    "A Run is an invocation of an Assistant on a Thread. The Assistant uses its configuration and the Thread’s Messages to perform tasks by calling models and tools. As part of a Run, the Assistant appends Messages to the Thread.\n",
    "\n",
    "Note that Assistance will run asychronously: the run has the following\n",
    "lifecycle and states: [*expired, completed, failed, cancelled*]. Run objects can have multiple statuses.\n",
    "\n",
    "<img src=\"https://cdn.openai.com/API/docs/images/diagram-1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2d296c8-4ba4-4233-8e82-772762298a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"run_FwKWtCqM7e3Jlcpm5sNPAVIN\",\n",
      "  \"assistant_id\": \"asst_dGpV5uEoPqiK9oZF37JBAzAv\",\n",
      "  \"cancelled_at\": null,\n",
      "  \"completed_at\": null,\n",
      "  \"created_at\": 1704922157,\n",
      "  \"expires_at\": 1704922757,\n",
      "  \"failed_at\": null,\n",
      "  \"file_ids\": [\n",
      "    \"file-5BgVZhmHgOvNFwLZl3NJhK6s\",\n",
      "    \"file-K4ztRDmVvqem23JNYpZDiTdY\"\n",
      "  ],\n",
      "  \"instructions\": \"Please address the user as Jules Dmatrix.  \\n    Do not provide an answer to the question if the information was not retrieved from \\n    the knowledge base.\\n\",\n",
      "  \"last_error\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4-1106-preview\",\n",
      "  \"object\": \"thread.run\",\n",
      "  \"required_action\": null,\n",
      "  \"started_at\": null,\n",
      "  \"status\": \"queued\",\n",
      "  \"thread_id\": \"thread_eP6P7EeIhFHFpaGMCS5ysCI9\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"retrieval\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "instruction_msg = \"\"\"Please address the user as Jules Dmatrix.  \n",
    "    Do not provide an answer to the question if the information was not retrieved from \n",
    "    the knowledge base.\n",
    "\"\"\"\n",
    "run = create_assistant_run(client, assistant, thread, instruction_msg)\n",
    "print(run.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce860b7-030a-49cb-b926-5bfee09f6de4",
   "metadata": {},
   "source": [
    "### Step 6: Loop through the Assistant run until status is 'completed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd811a5c-982e-4623-943e-0265717ffa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"run_FwKWtCqM7e3Jlcpm5sNPAVIN\",\n",
      "    \"assistant_id\": \"asst_dGpV5uEoPqiK9oZF37JBAzAv\",\n",
      "    \"cancelled_at\": null,\n",
      "    \"completed_at\": null,\n",
      "    \"created_at\": 1704922157,\n",
      "    \"expires_at\": 1704922757,\n",
      "    \"failed_at\": null,\n",
      "    \"file_ids\": [\n",
      "        \"file-5BgVZhmHgOvNFwLZl3NJhK6s\",\n",
      "        \"file-K4ztRDmVvqem23JNYpZDiTdY\"\n",
      "    ],\n",
      "    \"instructions\": \"Please address the user as Jules Dmatrix.  \\n    Do not provide an answer to the question if the information was not retrieved from \\n    the knowledge base.\\n\",\n",
      "    \"last_error\": null,\n",
      "    \"metadata\": {},\n",
      "    \"model\": \"gpt-4-1106-preview\",\n",
      "    \"object\": \"thread.run\",\n",
      "    \"required_action\": null,\n",
      "    \"started_at\": 1704922157,\n",
      "    \"status\": \"in_progress\",\n",
      "    \"thread_id\": \"thread_eP6P7EeIhFHFpaGMCS5ysCI9\",\n",
      "    \"tools\": [\n",
      "        {\n",
      "            \"type\": \"retrieval\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "run_status = client.beta.threads.runs.retrieve(\n",
    "    thread_id = thread.id,\n",
    "    run_id = run.id\n",
    ")\n",
    "print(run_status.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b241e17-f6e6-4d7f-930b-e673163ccb8f",
   "metadata": {},
   "source": [
    "#### Poll until Assistant run is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e11a1109-4918-42e5-94dc-366a8f30e2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "loop_until_completed(client, thread, run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619f220c-1b7a-49e7-8afe-e8ff9bc2eef4",
   "metadata": {},
   "source": [
    "### Step 7: Retrieve the message returned by the assistance\n",
    "Only when the run is **completed** can you fetch the messages from the Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63ee0d97-492b-4d4b-a8be-c8a4ff95bcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('assistant:The survey on hallucinations in Large Language Models (LLMs) '\n",
      " 'delves into the phenomenon where state-of-the-art models in natural language '\n",
      " 'processing generate content that, while seemingly plausible, is not '\n",
      " 'supported by facts or user inputs. As the capability of LLMs to comprehend, '\n",
      " 'generate, and reason with language has grown, so too has the tendency for '\n",
      " 'these models to produce these so-called \"hallucinations.\" The paper provides '\n",
      " 'a novel taxonomy for categorizing hallucinations and examines the factors '\n",
      " 'leading to their occurrence. By offering a cohesive overview of methods for '\n",
      " 'detection and mitigation, alongside an evaluation of existing challenges and '\n",
      " 'prospective pathways for future research, the survey endeavors to provide '\n",
      " 'clarity and direction in the ongoing discussion surrounding LLM reliability '\n",
      " 'and practical applicability.\\n'\n",
      " '\\n'\n",
      " 'The introduction of a refined taxonomy distinguishes between \"factuality '\n",
      " 'hallucination,\" which involves discrepancies between generated content and '\n",
      " 'verifiable facts, and \"faithfulness hallucination,\" which pertains to '\n",
      " 'deviations from user instructions or internal consistency within the '\n",
      " 'generated content. Factuality hallucinations manifest as assertions that '\n",
      " 'contradict known facts, such as incorrectly identifying the first person to '\n",
      " 'walk on the moon. In contrast, faithfulness hallucinations may incorrectly '\n",
      " 'assert dates or details that diverge from the provided context, as in '\n",
      " 'summarizing news articles. By focusing on the practical applications of '\n",
      " 'LLMs, the survey aligns its categories better with the real-world use of '\n",
      " 'these models, dividing the phenomenon based on whether it involves '\n",
      " 'inconsistency with verifiable sources or the generation of entirely '\n",
      " 'fabricated information.\\n'\n",
      " '\\n'\n",
      " 'The survey highlights that hallucinations stem from a range of contributing '\n",
      " 'factors spanning from data sourcing and model training to inference '\n",
      " 'processes. It emphasizes the need for in-depth exploration into the origins '\n",
      " 'of hallucinations specific to LLMs, evaluating challenges from each stage of '\n",
      " 'model development and operation. This comprehensive analysis calls attention '\n",
      " 'to the potential pitfalls such as reliance on flawed data sources, '\n",
      " 'suboptimal training practices, and inadequate inference strategies that can '\n",
      " 'lead to the production of hallucinations. Through its careful examination, '\n",
      " 'the survey informs efforts to develop more faithful and accurate language '\n",
      " 'models, signaling the shift toward a deeper understanding of and improved '\n",
      " 'methodologies for handling hallucinations in LLMs.')\n",
      "('user:\\n'\n",
      " '    # OBJECTIVE#\\n'\n",
      " '    Use \"llm_survey_halluciantions\" document for this \\n'\n",
      " '    query. Give me a three paragraph overview of the \\n'\n",
      " '    document.\\n'\n",
      " '    \\n'\n",
      " '    # STYLE #\\n'\n",
      " '    Use simple and compound-complex sentences for each paragraph. \\n'\n",
      " '    ')\n"
     ]
    }
   ],
   "source": [
    "print_thread_messages(client, thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33571e29-5dc4-47a3-8436-0ca3e9e1961b",
   "metadata": {},
   "source": [
    "### Repeat the process for any additional messages\n",
    "To add more query messages to the thread for the Assistant,\n",
    "repeat steps 5 - 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c200530f-619c-4e2e-a4e1-699cad169fdf",
   "metadata": {},
   "source": [
    "### Add another message to for the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "15e013af-cc89-4d9c-a213-824ee3c87204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreadMessage(id='msg_otx6Z4OMEx0etXLbnRwDQr40', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Use 1001-math-problems-2nd document for \\n    this query.\\n    \\n    Select three random math problems from sections 2 on fractions).\\n    '), type='text')], created_at=1704922532, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_eP6P7EeIhFHFpaGMCS5ysCI9')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id, \n",
    "    role=\"user\",\n",
    "    content=\"\"\"Use 1001-math-problems-2nd document for \n",
    "    this query.\n",
    "    \n",
    "    Select three random math problems from sections 2 on fractions).\n",
    "    \"\"\",\n",
    ")\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b65ca2-295d-41e4-a7c4-e7edfd7ab2eb",
   "metadata": {},
   "source": [
    "### Create another run for the Assistant for the second message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8658a56f-90c5-478a-a920-021f5677ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = create_assistant_run(client, assistant, thread, instruction_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dadc82a8-6947-4870-87f7-358ce245f4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_progress\n"
     ]
    }
   ],
   "source": [
    "run_status = client.beta.threads.runs.retrieve(\n",
    "    thread_id = thread.id,\n",
    "    run_id = run.id\n",
    ")\n",
    "\n",
    "print(run_status.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe9b096f-f3fd-4bc7-b2d7-c4ac99a38846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "loop_until_completed(client, thread, run_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "73ededf9-2772-4300-b55d-881d34fc5765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('assistant:Here are three random math problems from Section 2 on fractions in '\n",
      " 'the \"1001-math-problems-2nd\" document:\\n'\n",
      " '\\n'\n",
      " '1. **Problem 118:** In the music department at a school, a music teacher '\n",
      " 'counted the musical instruments and supplies in storage. There was:\\n'\n",
      " '   - 1 violin valued at \\\\$1200\\n'\n",
      " '   - 2 violin bows each valued at \\\\$350\\n'\n",
      " '   - 3 music stands each valued at \\\\$55\\n'\n",
      " '   - 1 trumpet valued at \\\\$235\\n'\n",
      " '\\n'\n",
      " '   In addition, there were a number of supplies totaling \\\\$125 and some '\n",
      " 'sheet music worth \\\\$75. What was the total value of the musical supplies '\n",
      " 'and instruments in storage?\\n'\n",
      " '   - a. \\\\$2040\\n'\n",
      " '   - b. \\\\$2500\\n'\n",
      " '   - c. \\\\$3040【60†source】.\\n'\n",
      " '\\n'\n",
      " '2. **Problem 119:** What is the value of the expression 5(40)?\\n'\n",
      " '   - a. 0\\n'\n",
      " '   - b. 1\\n'\n",
      " '   - c. 5\\n'\n",
      " '   - d. 20【62†source】.\\n'\n",
      " '\\n'\n",
      " '3. **Problem 120:** If a population of yeast cells grows from 10 to 320 in a '\n",
      " 'period of 5 hours, what is the rate of growth?\\n'\n",
      " '   - a. It doubles its numbers every hour.\\n'\n",
      " '   - b. It triples its numbers every hour.\\n'\n",
      " '   - c. It doubles its numbers every two hours.\\n'\n",
      " '   - d. It triples its numbers every two hours【64†source】.')\n",
      "('user:Use 1001-math-problems-2nd document for \\n'\n",
      " '    this query.\\n'\n",
      " '    \\n'\n",
      " '    Select three random math problems from sections 2 on fractions).\\n'\n",
      " '    ')\n",
      "('assistant:My attempts to locate the specific Set 11 Fractions problems in '\n",
      " 'the \"1001-math-problems-2nd\" document have been unsuccessful thus far, with '\n",
      " 'the relevant information not readily accessible through the searches. Would '\n",
      " 'you like me to continue searching in another manner, or is there something '\n",
      " 'else I can assist you with?')\n",
      "('user:Use 1001-math-problems-2nd document for \\n'\n",
      " '    this query.\\n'\n",
      " '    \\n'\n",
      " '    Select three random math problems from sections 2 \\n'\n",
      " '    (fractions and set 11 ).\\n'\n",
      " '    ')\n",
      "(\"assistant:I apologize, but I wasn't able to find the specific math problems \"\n",
      " 'from sections 2 (fractions), section 4 (percentages), and section 6 '\n",
      " '(geometry) in the \"1001-math-problems-2nd\" document. While I tried to locate '\n",
      " 'them, the relevant sections were not retrieved. If there is any other way I '\n",
      " 'can assist you with the document, please let me know.')\n",
      "('user:Use 1001-math-problems-2nd document for \\n'\n",
      " '    this query.\\n'\n",
      " '    \\n'\n",
      " '    Select three random math problems from sections 2 \\n'\n",
      " '    (fractions), section 4 (percentages) and section 6 (geometry).\\n'\n",
      " '    ')\n",
      "('assistant:The survey on hallucinations in Large Language Models (LLMs) '\n",
      " 'delves into the phenomenon where state-of-the-art models in natural language '\n",
      " 'processing generate content that, while seemingly plausible, is not '\n",
      " 'supported by facts or user inputs. As the capability of LLMs to comprehend, '\n",
      " 'generate, and reason with language has grown, so too has the tendency for '\n",
      " 'these models to produce these so-called \"hallucinations.\" The paper provides '\n",
      " 'a novel taxonomy for categorizing hallucinations and examines the factors '\n",
      " 'leading to their occurrence. By offering a cohesive overview of methods for '\n",
      " 'detection and mitigation, alongside an evaluation of existing challenges and '\n",
      " 'prospective pathways for future research, the survey endeavors to provide '\n",
      " 'clarity and direction in the ongoing discussion surrounding LLM reliability '\n",
      " 'and practical applicability.\\n'\n",
      " '\\n'\n",
      " 'The introduction of a refined taxonomy distinguishes between \"factuality '\n",
      " 'hallucination,\" which involves discrepancies between generated content and '\n",
      " 'verifiable facts, and \"faithfulness hallucination,\" which pertains to '\n",
      " 'deviations from user instructions or internal consistency within the '\n",
      " 'generated content. Factuality hallucinations manifest as assertions that '\n",
      " 'contradict known facts, such as incorrectly identifying the first person to '\n",
      " 'walk on the moon. In contrast, faithfulness hallucinations may incorrectly '\n",
      " 'assert dates or details that diverge from the provided context, as in '\n",
      " 'summarizing news articles. By focusing on the practical applications of '\n",
      " 'LLMs, the survey aligns its categories better with the real-world use of '\n",
      " 'these models, dividing the phenomenon based on whether it involves '\n",
      " 'inconsistency with verifiable sources or the generation of entirely '\n",
      " 'fabricated information.\\n'\n",
      " '\\n'\n",
      " 'The survey highlights that hallucinations stem from a range of contributing '\n",
      " 'factors spanning from data sourcing and model training to inference '\n",
      " 'processes. It emphasizes the need for in-depth exploration into the origins '\n",
      " 'of hallucinations specific to LLMs, evaluating challenges from each stage of '\n",
      " 'model development and operation. This comprehensive analysis calls attention '\n",
      " 'to the potential pitfalls such as reliance on flawed data sources, '\n",
      " 'suboptimal training practices, and inadequate inference strategies that can '\n",
      " 'lead to the production of hallucinations. Through its careful examination, '\n",
      " 'the survey informs efforts to develop more faithful and accurate language '\n",
      " 'models, signaling the shift toward a deeper understanding of and improved '\n",
      " 'methodologies for handling hallucinations in LLMs.')\n",
      "('user:\\n'\n",
      " '    # OBJECTIVE#\\n'\n",
      " '    Use \"llm_survey_halluciantions\" document for this \\n'\n",
      " '    query. Give me a three paragraph overview of the \\n'\n",
      " '    document.\\n'\n",
      " '    \\n'\n",
      " '    # STYLE #\\n'\n",
      " '    Use simple and compound-complex sentences for each paragraph. \\n'\n",
      " '    ')\n"
     ]
    }
   ],
   "source": [
    "print_thread_messages(client, thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "daad40a3-523c-44cc-8136-b6d254b73374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssistantDeleted(id='asst_dGpV5uEoPqiK9oZF37JBAzAv', deleted=True, object='assistant.deleted')\n",
      "deleting file id: file-5BgVZhmHgOvNFwLZl3NJhK6s...\n",
      "FileDeleted(id='file-5BgVZhmHgOvNFwLZl3NJhK6s', deleted=True, object='file')\n",
      "deleting file id: file-K4ztRDmVvqem23JNYpZDiTdY...\n",
      "FileDeleted(id='file-K4ztRDmVvqem23JNYpZDiTdY', deleted=True, object='file')\n"
     ]
    }
   ],
   "source": [
    "# Delete the assistant. Optionally, you can delete any files\n",
    "# associated with it that you have uploaded onto the OpenAI platform\n",
    "\n",
    "response = client.beta.assistants.delete(assistant.id)\n",
    "print(response)\n",
    "\n",
    "for file_id in file_obj_ids:\n",
    "    print(f\"deleting file id: {file_id}...\")\n",
    "    response = client.files.delete(file_id)\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
